{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7e3119baa3584b0a8a3d5a9aff2408bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_13ef5c7e968d4b07b9887b5f84ac4cc9",
              "IPY_MODEL_e1e40b865ab64cf29f2eaf8a9fbf8b9d",
              "IPY_MODEL_f6cf4b3385854cada6e3debe2758920b"
            ],
            "layout": "IPY_MODEL_f07005198c064aca8c9cdeee5d0d483c"
          }
        },
        "13ef5c7e968d4b07b9887b5f84ac4cc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ba1c185679544a2a95c0b20dc244e73",
            "placeholder": "​",
            "style": "IPY_MODEL_511abc370cee48efa17687ba17889b54",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "e1e40b865ab64cf29f2eaf8a9fbf8b9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc9c34d72bfc46ccb5dd41b8cd84efa8",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e369018cc9b2499e96f1610eb9546dda",
            "value": 2
          }
        },
        "f6cf4b3385854cada6e3debe2758920b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7d7e0154f69440a9ce66927e904c825",
            "placeholder": "​",
            "style": "IPY_MODEL_c511c089a81e42dab248a461898bd189",
            "value": " 2/2 [00:04&lt;00:00,  2.05s/it]"
          }
        },
        "f07005198c064aca8c9cdeee5d0d483c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ba1c185679544a2a95c0b20dc244e73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "511abc370cee48efa17687ba17889b54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc9c34d72bfc46ccb5dd41b8cd84efa8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e369018cc9b2499e96f1610eb9546dda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b7d7e0154f69440a9ce66927e904c825": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c511c089a81e42dab248a461898bd189": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "367f21e176564755b43ae0ea0218dab1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c599d174e7d445ee851b6d17b9275ae2",
              "IPY_MODEL_1bd0683af6394ad48ffc650e08b03f60",
              "IPY_MODEL_b3a986b67f6a478285bfe3869ed33511"
            ],
            "layout": "IPY_MODEL_d36b335fa0204ba38f9c690da2ee2dca"
          }
        },
        "c599d174e7d445ee851b6d17b9275ae2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ad123b305cf4f11a4c40e85d185d33f",
            "placeholder": "​",
            "style": "IPY_MODEL_935c54c2fbbf47b08682de3e482467a6",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "1bd0683af6394ad48ffc650e08b03f60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b6927fab93146bf83eeb1458cf4219c",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_753989190a0c47ddb5b75d879fac9226",
            "value": 2
          }
        },
        "b3a986b67f6a478285bfe3869ed33511": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a3acf7ab6ba45b8814276053ed4e86d",
            "placeholder": "​",
            "style": "IPY_MODEL_0ee7aebd00c64ea0b7018a8759b980f8",
            "value": " 2/2 [00:04&lt;00:00,  2.06s/it]"
          }
        },
        "d36b335fa0204ba38f9c690da2ee2dca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ad123b305cf4f11a4c40e85d185d33f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "935c54c2fbbf47b08682de3e482467a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b6927fab93146bf83eeb1458cf4219c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "753989190a0c47ddb5b75d879fac9226": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9a3acf7ab6ba45b8814276053ed4e86d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ee7aebd00c64ea0b7018a8759b980f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "05b4bb36cd7c4f3da7986cb1fca0d6fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eeed9cb8a0df4bdaabe4aa8be54af9cb",
              "IPY_MODEL_8b676329d5194430b963897cb6d7d052",
              "IPY_MODEL_93e736f3a7894bbd9f8c3eff2c64ee8c"
            ],
            "layout": "IPY_MODEL_db63b60c2668462c97af5ee9e8ac2aa0"
          }
        },
        "eeed9cb8a0df4bdaabe4aa8be54af9cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8edf1a38147e41518ce2152e167c14a1",
            "placeholder": "​",
            "style": "IPY_MODEL_d1ecfdb87fcc4a3ba5ca4e148027f0a8",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "8b676329d5194430b963897cb6d7d052": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5337ac765b86446ebd049a81d881d9d6",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2ee4671949d44b3da6b5d05ea585d7b5",
            "value": 2
          }
        },
        "93e736f3a7894bbd9f8c3eff2c64ee8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d6c495c840b48dc885c2af611df13bd",
            "placeholder": "​",
            "style": "IPY_MODEL_769d771691114da68dd275993af2e844",
            "value": " 2/2 [00:04&lt;00:00,  2.09s/it]"
          }
        },
        "db63b60c2668462c97af5ee9e8ac2aa0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8edf1a38147e41518ce2152e167c14a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1ecfdb87fcc4a3ba5ca4e148027f0a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5337ac765b86446ebd049a81d881d9d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ee4671949d44b3da6b5d05ea585d7b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1d6c495c840b48dc885c2af611df13bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "769d771691114da68dd275993af2e844": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2efaf26f2c14450bc9f62eb0d4eb3a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_91b2627c06c34d03b9b3600c1867926e",
              "IPY_MODEL_685f588152654cf5a41c8cd36523cf15",
              "IPY_MODEL_585418a07d89427d860e2562ec5a08e1"
            ],
            "layout": "IPY_MODEL_4e19b80c469b4ef0b7124829ceea7ea3"
          }
        },
        "91b2627c06c34d03b9b3600c1867926e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39c5fb962c314a61ba69910e0e090665",
            "placeholder": "​",
            "style": "IPY_MODEL_9271487f667b4258909cd2231f24ddef",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "685f588152654cf5a41c8cd36523cf15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc0cdc0b567c4e2b8760b985f9677de3",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fdcd57690d5441d4b5db2ae1b9de9d4e",
            "value": 2
          }
        },
        "585418a07d89427d860e2562ec5a08e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e28e6638f8204199bf56012adf4e3288",
            "placeholder": "​",
            "style": "IPY_MODEL_66a497a637784a33a889074e0dcb790b",
            "value": " 2/2 [00:02&lt;00:00,  1.20s/it]"
          }
        },
        "4e19b80c469b4ef0b7124829ceea7ea3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39c5fb962c314a61ba69910e0e090665": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9271487f667b4258909cd2231f24ddef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc0cdc0b567c4e2b8760b985f9677de3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdcd57690d5441d4b5db2ae1b9de9d4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e28e6638f8204199bf56012adf4e3288": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66a497a637784a33a889074e0dcb790b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "694753b1a526465b92b97c0dba2fb175": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d56b048f3a834f14aa7da8e23ec305ba",
              "IPY_MODEL_c487748be04e4491a550a7c53a8135d1",
              "IPY_MODEL_ced6aa064d9047b5a672a066e774782c"
            ],
            "layout": "IPY_MODEL_2498de1e5d514c789ca318ab50a9ea41"
          }
        },
        "d56b048f3a834f14aa7da8e23ec305ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa923992f62d4b5fa60eed74a1e392a6",
            "placeholder": "​",
            "style": "IPY_MODEL_4048bf73839c4382ae82c188b0ff4249",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "c487748be04e4491a550a7c53a8135d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1177935ee2a4401ca136a08a9fe0f78f",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e49a785df626458eb5fceee1bb2d64a6",
            "value": 2
          }
        },
        "ced6aa064d9047b5a672a066e774782c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7aa12c00edee49699cc040374baa5025",
            "placeholder": "​",
            "style": "IPY_MODEL_6333230e875c4f92b2530d495ea2690d",
            "value": " 2/2 [00:04&lt;00:00,  2.09s/it]"
          }
        },
        "2498de1e5d514c789ca318ab50a9ea41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa923992f62d4b5fa60eed74a1e392a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4048bf73839c4382ae82c188b0ff4249": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1177935ee2a4401ca136a08a9fe0f78f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e49a785df626458eb5fceee1bb2d64a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7aa12c00edee49699cc040374baa5025": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6333230e875c4f92b2530d495ea2690d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d183549305b24d8e8a2102e48f41634a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_888507435b154d889d32cbb34cd3bfd1",
              "IPY_MODEL_bf201068cfd949ee868a58a4b4a6e680",
              "IPY_MODEL_a3770f78343743918c8f9e2decae1c29"
            ],
            "layout": "IPY_MODEL_8d0ae06996ea4676b1119ae681576e35"
          }
        },
        "888507435b154d889d32cbb34cd3bfd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c86fcfe79973473ca97431699dd0c602",
            "placeholder": "​",
            "style": "IPY_MODEL_f8f37abbe2f9414797d324bee4f16a14",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "bf201068cfd949ee868a58a4b4a6e680": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f22c4ecafd08496fb7391b2de773ee01",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fc43db2c082040dfbaa2bb12219fb0f2",
            "value": 2
          }
        },
        "a3770f78343743918c8f9e2decae1c29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1238f62b6e0c4439bac7e05a1deb272f",
            "placeholder": "​",
            "style": "IPY_MODEL_f85aa9e38c7f441fbe707f0934acf1d2",
            "value": " 2/2 [00:04&lt;00:00,  2.09s/it]"
          }
        },
        "8d0ae06996ea4676b1119ae681576e35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c86fcfe79973473ca97431699dd0c602": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8f37abbe2f9414797d324bee4f16a14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f22c4ecafd08496fb7391b2de773ee01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc43db2c082040dfbaa2bb12219fb0f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1238f62b6e0c4439bac7e05a1deb272f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f85aa9e38c7f441fbe707f0934acf1d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45a7dbec79d14b35af3fffee3fd9963b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6cdbaf49edfc40449f784b1ebb28804c",
              "IPY_MODEL_b339cf1ec20b4fc8a4d715ff3208bc19",
              "IPY_MODEL_46f7bab2228843439c2663355f881001"
            ],
            "layout": "IPY_MODEL_d615e36c928d41488838852d43b10135"
          }
        },
        "6cdbaf49edfc40449f784b1ebb28804c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76f3461c799540a78686b94ad7d0d28f",
            "placeholder": "​",
            "style": "IPY_MODEL_5cec799b16dc47bca79bac17cb945a5a",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "b339cf1ec20b4fc8a4d715ff3208bc19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30bf9882eb2246e5b601761de7963ff5",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f2b33eae2266495fa1ab8c9d0fdb7b54",
            "value": 2
          }
        },
        "46f7bab2228843439c2663355f881001": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c8e1bc2ba2f4677a558f99c53d228bf",
            "placeholder": "​",
            "style": "IPY_MODEL_fc1f138e4f6a417588031ac920b35883",
            "value": " 2/2 [00:04&lt;00:00,  2.09s/it]"
          }
        },
        "d615e36c928d41488838852d43b10135": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76f3461c799540a78686b94ad7d0d28f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cec799b16dc47bca79bac17cb945a5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30bf9882eb2246e5b601761de7963ff5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2b33eae2266495fa1ab8c9d0fdb7b54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9c8e1bc2ba2f4677a558f99c53d228bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc1f138e4f6a417588031ac920b35883": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44199e6077f340d8bb735e0faf41f422": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ceda22be829a4ea7bc8b0676f83afea3",
              "IPY_MODEL_7a102e47f5d543749dbd5ce0e9871d6d",
              "IPY_MODEL_ba64b5c256114b608186aa624d59c929"
            ],
            "layout": "IPY_MODEL_c3cc230ad03446fba403378f12268de9"
          }
        },
        "ceda22be829a4ea7bc8b0676f83afea3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04f04b2937844240916a110bf505492c",
            "placeholder": "​",
            "style": "IPY_MODEL_5905d93b7c114ac5a8db0452532bb58c",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "7a102e47f5d543749dbd5ce0e9871d6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa12eb71bd334d468959dbb15dd86ffb",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e799a17f09904e439cb337a445703eb9",
            "value": 2
          }
        },
        "ba64b5c256114b608186aa624d59c929": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_065201d7aab144838adc38a06415237b",
            "placeholder": "​",
            "style": "IPY_MODEL_03abe832bffc4631a114026b35cdedfd",
            "value": " 2/2 [00:04&lt;00:00,  2.07s/it]"
          }
        },
        "c3cc230ad03446fba403378f12268de9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04f04b2937844240916a110bf505492c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5905d93b7c114ac5a8db0452532bb58c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa12eb71bd334d468959dbb15dd86ffb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e799a17f09904e439cb337a445703eb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "065201d7aab144838adc38a06415237b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03abe832bffc4631a114026b35cdedfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c43cf26f2cd8433088b2a585792b59f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3d91ae018c264622be1b031ba3ff5c16",
              "IPY_MODEL_b2162355217a4397a63f85d6712b1626",
              "IPY_MODEL_cae574b1db34450dbce803417c82af1d"
            ],
            "layout": "IPY_MODEL_1b6d7e2d75a64e84a3a3a39a25645a74"
          }
        },
        "3d91ae018c264622be1b031ba3ff5c16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1a0ed6884da4345a84257e875f23838",
            "placeholder": "​",
            "style": "IPY_MODEL_a0aab0cece4141a5b680f5e73c39ec79",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "b2162355217a4397a63f85d6712b1626": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f5d7a004cba402b93a95fd855c6e211",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a98a393fc3c14f43baf31c982de3107c",
            "value": 2
          }
        },
        "cae574b1db34450dbce803417c82af1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6004cb32aeb6424798d4008df2eab104",
            "placeholder": "​",
            "style": "IPY_MODEL_c8085311a90441bbbaee7846e9dd2c95",
            "value": " 2/2 [00:04&lt;00:00,  2.10s/it]"
          }
        },
        "1b6d7e2d75a64e84a3a3a39a25645a74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1a0ed6884da4345a84257e875f23838": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0aab0cece4141a5b680f5e73c39ec79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f5d7a004cba402b93a95fd855c6e211": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a98a393fc3c14f43baf31c982de3107c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6004cb32aeb6424798d4008df2eab104": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8085311a90441bbbaee7846e9dd2c95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6312d6a148454792923f3bf920500a74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d49016de2dee4f83ae409e9adc06f4f0",
              "IPY_MODEL_db13b7f11cd94336ab95a896bc6e98f2",
              "IPY_MODEL_0caf6d8fbace4cc79d3aabf859c53604"
            ],
            "layout": "IPY_MODEL_54c325c5102e45ffa9e01989767ad344"
          }
        },
        "d49016de2dee4f83ae409e9adc06f4f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_518bd2f7afee47f8b4ed8345b6d4a876",
            "placeholder": "​",
            "style": "IPY_MODEL_89171230da5e43708be54dc1bb52b905",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "db13b7f11cd94336ab95a896bc6e98f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6232de5414b4770ba9a7c1940081da4",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cad5707b8b104bb3998d47758d419740",
            "value": 2
          }
        },
        "0caf6d8fbace4cc79d3aabf859c53604": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd9b18a9e4f145209d3d3328787da053",
            "placeholder": "​",
            "style": "IPY_MODEL_c8d7409fad2f4a7cb020bc6d4de21fd7",
            "value": " 2/2 [00:04&lt;00:00,  2.08s/it]"
          }
        },
        "54c325c5102e45ffa9e01989767ad344": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "518bd2f7afee47f8b4ed8345b6d4a876": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89171230da5e43708be54dc1bb52b905": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6232de5414b4770ba9a7c1940081da4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cad5707b8b104bb3998d47758d419740": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bd9b18a9e4f145209d3d3328787da053": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8d7409fad2f4a7cb020bc6d4de21fd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7403f297ee934881b7801839c63227a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_de85b1538da24de4a0ae957fdc26f91e",
              "IPY_MODEL_83c69baf7594438e8d2ba48fc284618c",
              "IPY_MODEL_b149b269ad3b493c8690a592b46b3156"
            ],
            "layout": "IPY_MODEL_76009e40c9c645abb18126e8ad51c978"
          }
        },
        "de85b1538da24de4a0ae957fdc26f91e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40300759e9ed433f9ea59021795ce2c9",
            "placeholder": "​",
            "style": "IPY_MODEL_4b1f7249a6dd4a2db7dd9fc6ad78592f",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "83c69baf7594438e8d2ba48fc284618c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c834838d0ebc4e0fbbd90ed1c62ba333",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_27147d3116734345aafec9d1d9f06533",
            "value": 2
          }
        },
        "b149b269ad3b493c8690a592b46b3156": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11e5406f915140d0b3e928b8282e62d1",
            "placeholder": "​",
            "style": "IPY_MODEL_2911759612f14d878c9e3787b32ade9e",
            "value": " 2/2 [00:04&lt;00:00,  2.08s/it]"
          }
        },
        "76009e40c9c645abb18126e8ad51c978": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40300759e9ed433f9ea59021795ce2c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b1f7249a6dd4a2db7dd9fc6ad78592f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c834838d0ebc4e0fbbd90ed1c62ba333": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27147d3116734345aafec9d1d9f06533": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "11e5406f915140d0b3e928b8282e62d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2911759612f14d878c9e3787b32ade9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01fcaabc3e2f401b9909fcc14bb05021": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4be8e6537e5d4e07bfffc17a37b84bf2",
              "IPY_MODEL_900df2c3260c4b63b48b097c3351627d",
              "IPY_MODEL_bd7e39f4468a45c49f70232c95520cb9"
            ],
            "layout": "IPY_MODEL_4b1e94517b37421a900a7b563f8f0195"
          }
        },
        "4be8e6537e5d4e07bfffc17a37b84bf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c82dc08916594a8e81278b0c4f450186",
            "placeholder": "​",
            "style": "IPY_MODEL_cef9420db0a14d3d954587a7ea7d0a03",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "900df2c3260c4b63b48b097c3351627d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80b9cd6100054eba995491d3b0d89521",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5aac023bb5c3476cb43c89356f56c6c4",
            "value": 2
          }
        },
        "bd7e39f4468a45c49f70232c95520cb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8d880f83c604351a2dbec5f6751fc49",
            "placeholder": "​",
            "style": "IPY_MODEL_f8e92fe7ffc641b9b4f082bfa09b15ac",
            "value": " 2/2 [00:04&lt;00:00,  2.09s/it]"
          }
        },
        "4b1e94517b37421a900a7b563f8f0195": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c82dc08916594a8e81278b0c4f450186": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cef9420db0a14d3d954587a7ea7d0a03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80b9cd6100054eba995491d3b0d89521": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5aac023bb5c3476cb43c89356f56c6c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a8d880f83c604351a2dbec5f6751fc49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8e92fe7ffc641b9b4f082bfa09b15ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "26b7e3efbb504a69a496a06a57cf33d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e2067030c0d14b96b15d6bdcbf7fb66e",
              "IPY_MODEL_47c376349d7b4d8491bb478b67b67211",
              "IPY_MODEL_4489f631d51641519f3df56492d3f971"
            ],
            "layout": "IPY_MODEL_aaf0b86a53be4062a61dd4d988c925ee"
          }
        },
        "e2067030c0d14b96b15d6bdcbf7fb66e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6137328df379470b96644ce9b5460bcb",
            "placeholder": "​",
            "style": "IPY_MODEL_e318c9abcf4444af90be6ee2c22edeb0",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "47c376349d7b4d8491bb478b67b67211": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5bd04c7cdd794f018ef3b1388a3dd7ad",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7d78c03aa1ce4362b805f099c811818a",
            "value": 2
          }
        },
        "4489f631d51641519f3df56492d3f971": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e30d690d91b44f18b9f1b33d68c4908a",
            "placeholder": "​",
            "style": "IPY_MODEL_39320e4c58474e7dad39033bf2cc7467",
            "value": " 2/2 [00:04&lt;00:00,  2.08s/it]"
          }
        },
        "aaf0b86a53be4062a61dd4d988c925ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6137328df379470b96644ce9b5460bcb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e318c9abcf4444af90be6ee2c22edeb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5bd04c7cdd794f018ef3b1388a3dd7ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d78c03aa1ce4362b805f099c811818a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e30d690d91b44f18b9f1b33d68c4908a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39320e4c58474e7dad39033bf2cc7467": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9a46af7338942f884dbaf79c44e3755": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3450f3abbed343d389e1de078bed94bf",
              "IPY_MODEL_b6a688fdaa62413cb7a0a71282136870",
              "IPY_MODEL_029268b433724ac9bc00fe480c09937d"
            ],
            "layout": "IPY_MODEL_3a3cad9dffdd44a1a7e82adc99ae41d6"
          }
        },
        "3450f3abbed343d389e1de078bed94bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7208276659d54fe48b576163171d2f1d",
            "placeholder": "​",
            "style": "IPY_MODEL_d0ef5804261d41eea9abdd97eb885b7b",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "b6a688fdaa62413cb7a0a71282136870": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2affc36abef488c903e97b55e97877d",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6a7cc46a9352463587f28598e0f73a44",
            "value": 2
          }
        },
        "029268b433724ac9bc00fe480c09937d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6f0bc2e935848889806dcef6711abff",
            "placeholder": "​",
            "style": "IPY_MODEL_5786825e1258403ebc5b196c9c5fbac6",
            "value": " 2/2 [00:04&lt;00:00,  2.09s/it]"
          }
        },
        "3a3cad9dffdd44a1a7e82adc99ae41d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7208276659d54fe48b576163171d2f1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0ef5804261d41eea9abdd97eb885b7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2affc36abef488c903e97b55e97877d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a7cc46a9352463587f28598e0f73a44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e6f0bc2e935848889806dcef6711abff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5786825e1258403ebc5b196c9c5fbac6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "50ea6f6c644b4b3a87a30f548cc7797b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_23b6a8ab93744f1e905717e111fea839",
              "IPY_MODEL_e8862d6ead4d4b8bb5dc379dfac4e813",
              "IPY_MODEL_293ece75b7dd47ccba82641480c09893"
            ],
            "layout": "IPY_MODEL_3d6be6eadcbf4c989a357f48ea4471c9"
          }
        },
        "23b6a8ab93744f1e905717e111fea839": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_409f141c34364dbe90489be455af3845",
            "placeholder": "​",
            "style": "IPY_MODEL_cfe3c234607545c680bea721ffb95ec6",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "e8862d6ead4d4b8bb5dc379dfac4e813": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8368502122b8432cb9c1826810268cf5",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8eab252bfcb2453f82b4788d8a04065e",
            "value": 2
          }
        },
        "293ece75b7dd47ccba82641480c09893": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebc26994c3914e42b2ae7deea15a9608",
            "placeholder": "​",
            "style": "IPY_MODEL_e1f8c3f585d14765ad0dfb8a7668adba",
            "value": " 2/2 [00:04&lt;00:00,  2.08s/it]"
          }
        },
        "3d6be6eadcbf4c989a357f48ea4471c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "409f141c34364dbe90489be455af3845": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfe3c234607545c680bea721ffb95ec6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8368502122b8432cb9c1826810268cf5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8eab252bfcb2453f82b4788d8a04065e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ebc26994c3914e42b2ae7deea15a9608": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1f8c3f585d14765ad0dfb8a7668adba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c60c8661aac42909d9da88fc8189a18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7058c73bf49b4609b51f6699712d1195",
              "IPY_MODEL_72d9a6fb2e9d4abb9145daeac34948e0",
              "IPY_MODEL_eba45bf75d5d4891a2b001348cc1d076"
            ],
            "layout": "IPY_MODEL_85b14f3a5c884bea92c993d3054c7300"
          }
        },
        "7058c73bf49b4609b51f6699712d1195": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_934d8531b84349599aa118b34716cef5",
            "placeholder": "​",
            "style": "IPY_MODEL_d25f1a3c719243aaac2065639da792b9",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "72d9a6fb2e9d4abb9145daeac34948e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05d7732405f14dfc9284a4a8566e6ceb",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5e391f0284ec43e0bf0874424fafe335",
            "value": 2
          }
        },
        "eba45bf75d5d4891a2b001348cc1d076": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4f43217147c49bc9110d8a955bbfad4",
            "placeholder": "​",
            "style": "IPY_MODEL_a914677a8ba24f14962b121c39d68ff2",
            "value": " 2/2 [00:04&lt;00:00,  2.09s/it]"
          }
        },
        "85b14f3a5c884bea92c993d3054c7300": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "934d8531b84349599aa118b34716cef5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d25f1a3c719243aaac2065639da792b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "05d7732405f14dfc9284a4a8566e6ceb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e391f0284ec43e0bf0874424fafe335": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b4f43217147c49bc9110d8a955bbfad4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a914677a8ba24f14962b121c39d68ff2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ddc989f96dc460da600ba332e523183": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2b49e422d8a54e8e9b390ce82c299ff2",
              "IPY_MODEL_f3677bff29c64d49832984cf86f039ad",
              "IPY_MODEL_bdcffe04a1134905a530634930925357"
            ],
            "layout": "IPY_MODEL_2dc68791177a44608afeb40a8cb03f87"
          }
        },
        "2b49e422d8a54e8e9b390ce82c299ff2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7782ab8e44641c2bdb0b0c1bf9398e6",
            "placeholder": "​",
            "style": "IPY_MODEL_34ad3d0e19dc405ebdad651769ddf0c2",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "f3677bff29c64d49832984cf86f039ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a497db51eba4be7b35ae2d1b585a85e",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b81f26e5376947d6889bf60bb79752df",
            "value": 2
          }
        },
        "bdcffe04a1134905a530634930925357": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7aa45f22b37e4e70a5b41a77807b8094",
            "placeholder": "​",
            "style": "IPY_MODEL_1f9aec43537348488a45a5e1259d035c",
            "value": " 2/2 [00:04&lt;00:00,  2.09s/it]"
          }
        },
        "2dc68791177a44608afeb40a8cb03f87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7782ab8e44641c2bdb0b0c1bf9398e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34ad3d0e19dc405ebdad651769ddf0c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a497db51eba4be7b35ae2d1b585a85e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b81f26e5376947d6889bf60bb79752df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7aa45f22b37e4e70a5b41a77807b8094": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f9aec43537348488a45a5e1259d035c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07838cf616de42ada51bee105f6854da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1adf1293f6e74534be8567e78d2466bb",
              "IPY_MODEL_335a3d9142804faca0e68f2b789a96e0",
              "IPY_MODEL_88e37ba5b24a4e409aa43d0fb13835ae"
            ],
            "layout": "IPY_MODEL_6c6b056482b2436bb35d531c0528f709"
          }
        },
        "1adf1293f6e74534be8567e78d2466bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11104f8d642640fdacae367084907adc",
            "placeholder": "​",
            "style": "IPY_MODEL_289df14d43354206ba8d8aa685b09606",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "335a3d9142804faca0e68f2b789a96e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcc5e31de77b495991538bc83ae5d56f",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_351c6072d012456aa06c0084fc0a7225",
            "value": 2
          }
        },
        "88e37ba5b24a4e409aa43d0fb13835ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25cbc3bd9fed4659ad6d803bf1bb733c",
            "placeholder": "​",
            "style": "IPY_MODEL_9173dc91e2d744d995b1c348a8a54c8e",
            "value": " 2/2 [00:04&lt;00:00,  2.14s/it]"
          }
        },
        "6c6b056482b2436bb35d531c0528f709": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11104f8d642640fdacae367084907adc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "289df14d43354206ba8d8aa685b09606": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bcc5e31de77b495991538bc83ae5d56f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "351c6072d012456aa06c0084fc0a7225": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "25cbc3bd9fed4659ad6d803bf1bb733c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9173dc91e2d744d995b1c348a8a54c8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a421f3007e5442d88b9be8c6f60e75d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_81d03c8badc0462ba05df14fb65480ea",
              "IPY_MODEL_4510cf2269504dddb33b21a1fc38bb7d",
              "IPY_MODEL_2b3f10b3904141f2ba13de3af1f371c9"
            ],
            "layout": "IPY_MODEL_e525423f2a774480a34d55bd64d548a5"
          }
        },
        "81d03c8badc0462ba05df14fb65480ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9138f064f49542e3978152a2e6980c7d",
            "placeholder": "​",
            "style": "IPY_MODEL_040bf773d3df4a9786403dcf961b1039",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "4510cf2269504dddb33b21a1fc38bb7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6c4f10407004000a8d47d3c03a38282",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b059be3bf7e84fdeae02e3c83e626a7c",
            "value": 2
          }
        },
        "2b3f10b3904141f2ba13de3af1f371c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9cc453ae6f2d4993b44a72ce752a3ed9",
            "placeholder": "​",
            "style": "IPY_MODEL_0d74d33778764d5893b6d4c7001aa07d",
            "value": " 2/2 [00:04&lt;00:00,  2.14s/it]"
          }
        },
        "e525423f2a774480a34d55bd64d548a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9138f064f49542e3978152a2e6980c7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "040bf773d3df4a9786403dcf961b1039": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6c4f10407004000a8d47d3c03a38282": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b059be3bf7e84fdeae02e3c83e626a7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9cc453ae6f2d4993b44a72ce752a3ed9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d74d33778764d5893b6d4c7001aa07d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c84713de63e04176aa66dfeba1e4ada8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e96e14cda0784b188b15445bde1ee9c7",
              "IPY_MODEL_65e6f957819742e0aee41f1585d7ea3b",
              "IPY_MODEL_acfdb3a5cee64c37a6e2913b23f09160"
            ],
            "layout": "IPY_MODEL_d447e452c7e744d5841163c4e7f8699f"
          }
        },
        "e96e14cda0784b188b15445bde1ee9c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c857c014832a4d8bac771b44fc9668f8",
            "placeholder": "​",
            "style": "IPY_MODEL_9cf20a796ff14ad2bf30a601cc23514e",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "65e6f957819742e0aee41f1585d7ea3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb4f9a356a5540acb75f59408b800ae0",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_697624615c3d4a6e87489429528b8ac4",
            "value": 2
          }
        },
        "acfdb3a5cee64c37a6e2913b23f09160": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_126e7382c3ff469ba57e4c6fd244681a",
            "placeholder": "​",
            "style": "IPY_MODEL_d34b188f1db34a77b471ad53a066d817",
            "value": " 2/2 [00:04&lt;00:00,  2.14s/it]"
          }
        },
        "d447e452c7e744d5841163c4e7f8699f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c857c014832a4d8bac771b44fc9668f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cf20a796ff14ad2bf30a601cc23514e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb4f9a356a5540acb75f59408b800ae0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "697624615c3d4a6e87489429528b8ac4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "126e7382c3ff469ba57e4c6fd244681a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d34b188f1db34a77b471ad53a066d817": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBXXtWFsj3DH",
        "outputId": "32a388dd-8de4-4456-9972-ba6c6119c358"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/.shortcut-targets-by-id/1euUzSZa1IjWGSY7kHFLr2B_d6lpqAzvE/Genai Project/VLM\n",
            "/content/drive/.shortcut-targets-by-id/1euUzSZa1IjWGSY7kHFLr2B_d6lpqAzvE/Genai Project/VLM\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# %cd /content/drive/MyDrive/Genai Project/augmented images/train/images/\n",
        "%cd /content/drive/MyDrive/Genai Project/VLM\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "from skimage import io, transform\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils"
      ],
      "metadata": {
        "id": "TKHsEakPk602"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VLMDataset(Dataset):\n",
        "\n",
        "    def __init__(self, df, root_dir, transform=None):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            csv_file (string): Path to the csv file with annotations.\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.prompt_response_image = df\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.prompt_response_image)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        img_name = os.path.join(self.root_dir,\n",
        "                                self.prompt_response_image['Image_name'][idx])\n",
        "        image = Image.open(img_name)\n",
        "        prompt = self.prompt_response_image['Prompt'][idx]\n",
        "        response = self.prompt_response_image['Response'][idx]\n",
        "        sample = {'image': image, 'prompt': prompt, 'response': response}\n",
        "\n",
        "        if self.transform:\n",
        "            sample = {'image': self.transform(sample['image']), 'prompt': prompt, 'response': response}\n",
        "\n",
        "        return sample"
      ],
      "metadata": {
        "id": "dAepO95dj9GF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_response_image = pd.read_csv('response_prompt_vlm_jpg.csv')\n",
        "prompt_response_image_df =prompt_response_image.sample(frac=1,random_state = 1).reset_index(drop=True)\n",
        "print(prompt_response_image_df.head())\n",
        "vlm_dataset = VLMDataset(prompt_response_image_df, root_dir='images_jpg')\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "for i, sample in enumerate(vlm_dataset):\n",
        "    print(i, sample['image'], sample['prompt'], sample['response'])\n",
        "    # display(sample['image'])\n",
        "    if i == 3:\n",
        "        plt.show()\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Oy6qZEGykB_t",
        "outputId": "931050c4-e811-4949-a44b-bc09be2f41a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Sno                                             Prompt  \\\n",
            "0   15  Can you make a short description about the par...   \n",
            "1   99  You are an expert in IoT and hardware with ext...   \n",
            "2   76  You are an expert in IoT and hardware with ext...   \n",
            "3   17  Can you make a short description about the par...   \n",
            "4  132  You have been given an IoT kit component: 3-6V...   \n",
            "\n",
            "                                            Response  \\\n",
            "0  Description:\\nAn ultrasonic sensor is a device...   \n",
            "1  Description:\\r\\nThe 104 pF ceramic capacitor i...   \n",
            "2  Description:\\r\\nThe USA A to USB C adapter is ...   \n",
            "3  Description:\\r\\nA Rotary Encoder Module is a s...   \n",
            "4  Description:\\r\\nThe 3-6V motor is a compact, e...   \n",
            "\n",
            "                     Image_name  \n",
            "0         Ultrasonic_Sensor.jpg  \n",
            "1  104_pF_ceramic_capacitor.jpg  \n",
            "2            USB_A_to_USB_C.jpg  \n",
            "3     Rotary_Encoder_Module.jpg  \n",
            "4                3-6V_motor.jpg  \n",
            "0 <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA677B80> Can you make a short description about the part: Ultrasonic Sensor\n",
            "\n",
            "It should be divided into 3 sections as follows:\n",
            "1) Description\n",
            "2) Applications\n",
            "3) technical specification Description:\n",
            "An ultrasonic sensor is a device that measures the distance to an object by emitting ultrasonic sound waves and then detecting the waves that bounce back after hitting the object. It works on the principle of echolocation, similar to how bats navigate. The sensor typically consists of a transmitter, which emits ultrasonic waves, and a receiver, which detects the reflected waves. By measuring the time it takes for the waves to return, the sensor can calculate the distance to the object with high accuracy.\n",
            "Applications:\n",
            "Ultrasonic sensors find applications in various fields, including robotics, automotive industry, healthcare, and industrial automation. In robotics, they are used for obstacle avoidance and navigation. In the automotive industry, they play a crucial role in parking assistance systems and collision avoidance systems. In healthcare, ultrasonic sensors are utilized for medical imaging, such as ultrasound scans. In industrial automation, they are employed for level measurement, object detection, and quality control.\n",
            "Technical Specifications:\n",
            "Operating Principle: Ultrasonic echolocation\n",
            "Operating Range: Varies depending on the model, typically ranging from a few centimeters to several meters\n",
            "Frequency Range: Typically between 20 kHz to 200 kHz\n",
            "Accuracy: High accuracy in distance measurement, often within millimeters\n",
            "Output: Digital or analog signal indicating distance\n",
            "Power Supply: Typically operates on low voltage DC power supply\n",
            "Environmental Considerations: Can be affected by environmental factors such as temperature, humidity, and acoustic interference\n",
            "1 <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA5476A0> You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: 104 pF ceramic capacitor. Give a description of the component having 3 sections as follows:\r\n",
            "1) Description\r\n",
            "2) Applications\r\n",
            "3) Technical specifications Description:\r\n",
            "The 104 pF ceramic capacitor is a small, passive electronic component typically composed of ceramic material with conductive plates on either side. Its compact size and simple construction make it suitable for integration into various electronic circuits. This capacitor is marked with the numerical code \"104,\" where the first two digits represent the significant figures and the third digit indicates the number of zeros to follow, denoting its capacitance value in picofarads (pF).\r\n",
            "Applications:\r\n",
            "The 104 pF ceramic capacitor finds applications across a wide range of electronic devices and circuits. Some common uses include:\r\n",
            "Filtering: It can be employed in signal filtering circuits to remove unwanted noise or interference, ensuring the integrity of the transmitted signal.\r\n",
            "Timing: In conjunction with resistors, it forms a timing component in oscillators and timing circuits, crucial for generating precise clock signals in digital systems.\r\n",
            "Decoupling: Placed strategically near integrated circuits (ICs), it serves to decouple power supplies, stabilizing voltage levels and minimizing voltage fluctuations during operation.\r\n",
            "Coupling: Used to couple AC signals between stages of amplifiers and other electronic circuits, facilitating signal transmission while blocking DC components.\r\n",
            "Tuning: Integrated into radio frequency (RF) circuits, it aids in tuning the frequency response of resonant circuits, such as those found in radio receivers and transmitters.\r\n",
            "Technical specifications:\r\n",
            "Capacitance: 104 pF (10^4 picofarads)\r\n",
            "Tolerance: Typically ranges from ±5% to ±20%, indicating the acceptable deviation from the nominal capacitance value.\r\n",
            "Voltage rating: Capacitors are rated for a maximum voltage they can withstand without breakdown. The voltage rating for a 104 pF ceramic capacitor typically ranges from a few volts to tens or hundreds of volts, depending on the specific application and manufacturer.\r\n",
            "Dielectric material: Ceramic capacitors utilize ceramic materials as their dielectric, providing stability, reliability, and low losses across a wide frequency range.\r\n",
            "Package type: The 104 pF capacitor is commonly available in surface mount technology (SMT) packages, such as 0402 or 0603, for easy integration onto printed circuit boards (PCBs).\n",
            "2 <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA564250> You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: USA A to USB C. Give a description of the component having 3 sections as follows:\r\n",
            "1) Description\r\n",
            "2) Applications\r\n",
            "3) Technical specifications Description:\r\n",
            "The USA A to USB C adapter is a compact and versatile piece of hardware designed to bridge the gap between devices with different USB interfaces. It features a standard USB Type-A male connector on one end and a USB Type-C female port on the other. The adapter is typically small in size, making it portable and easy to carry around. It allows users to connect USB Type-A devices, such as flash drives, keyboards, or mice, to newer devices equipped with USB Type-C ports, including laptops, smartphones, and tablets.\r\n",
            "Applications:\r\n",
            "Device Compatibility: The adapter enables compatibility between legacy USB Type-A devices and modern USB Type-C devices, extending the lifespan and utility of older peripherals.\r\n",
            "Data Transfer: It facilitates data transfer between devices, allowing users to transfer files, documents, and multimedia content from USB Type-A devices to USB Type-C devices and vice versa.\r\n",
            "Charging: The adapter can also be used for charging purposes, enabling users to connect USB Type-A chargers or power banks to USB Type-C devices for charging and power delivery.\r\n",
            "Peripheral Connectivity: Users can connect a wide range of USB Type-A peripherals to USB Type-C devices, including external storage drives, printers, cameras, and more, expanding the functionality of modern devices.\r\n",
            "Technical Specifications:\r\n",
            "Connector Type: USB Type-A male to USB Type-C female\r\n",
            "Compatibility: Supports USB Type-A devices (USB 2.0/3.0) to USB Type-C devices\r\n",
            "Data Transfer Rate: Supports data transfer speeds up to 5 Gbps (USB 3.0)\r\n",
            "Power Delivery: Supports power delivery for charging and powering connected devices\r\n",
            "Dimensions: Compact and lightweight design for portability\r\n",
            "Material: Typically constructed with durable materials for long-term use\r\n",
            "Compatibility: Compatible with a wide range of devices, including laptops, smartphones, tablets, and more, supporting various operating systems such as Windows, macOS, Android, and Linux.\n",
            "\n",
            "3 <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA564D90> Can you make a short description about the part: Rotary Encoder Module\r\n",
            "\r\n",
            "It should be divided into 3 sections as follows:\r\n",
            "1) Description\r\n",
            "2) Applications\r\n",
            "3) technical specification Description:\r\n",
            "A Rotary Encoder Module is a sensor device used to detect rotational movement and convert it into digital signals. It typically consists of a rotating shaft and a stationary sensor. As the shaft turns, the sensor detects the changes in position and outputs corresponding electrical signals, which are then processed by a microcontroller or other electronic device.\r\n",
            "Applications:\r\n",
            "Rotary Encoder Modules are commonly used in various applications where precise rotational control or measurement is required. Some common applications include:\r\n",
            "Industrial automation: Used in machinery for position sensing, speed control, and motion detection.\r\n",
            "Robotics: Integrated into robotic arms and joints for precise movement control.\r\n",
            "CNC machines: Utilized for accurate positioning of cutting tools and components.\r\n",
            "Consumer electronics: Found in devices like computer mice, audio equipment, and volume controls for user input and adjustment.\r\n",
            "Automotive: Used in vehicle systems such as steering angle sensors and throttle position sensors.\r\n",
            "Technical Specifications:\r\n",
            "Resolution: Specifies the number of pulses generated per revolution, determining the encoder's precision.\r\n",
            "Output Interface: Describes the type of electrical signals outputted by the encoder, such as quadrature signals or digital pulses.\r\n",
            "Operating Voltage: Indicates the voltage range within which the encoder operates.\r\n",
            "Shaft Type: Specifies the type of shaft (e.g., hollow shaft, solid shaft) and its dimensions (diameter, length).\r\n",
            "Environmental Considerations: Includes factors such as operating temperature range, protection against dust and moisture (IP rating), and resistance to shock and vibration.\r\n",
            "Mounting Options: Describes the methods available for mounting the encoder onto a surface or device.\r\n",
            "Additional Features: May include built-in debouncing circuits, detents for tactile feedback, and customizable settings for specific applications.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I5nPSUTIornE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from datasets import load_dataset\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import requests\n",
        "import os\n",
        "import json\n",
        "import uuid\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def process_and_save(dataset, output_folder, subset_name):\n",
        "    # Define image subfolder within output folder\n",
        "    subset_folder = os.path.join(output_folder, subset_name)\n",
        "    image_subfolder = os.path.join(output_folder, 'images')\n",
        "\n",
        "\n",
        "    if not os.path.exists(image_subfolder):\n",
        "        os.makedirs(image_subfolder)\n",
        "\n",
        "\n",
        "    if not os.path.exists(subset_folder):\n",
        "        os.makedirs(subset_folder)\n",
        "\n",
        "\n",
        "    # Initialize list to hold all JSON data\n",
        "    json_data_list = []\n",
        "\n",
        "\n",
        "    # Process and save images and labels\n",
        "    for i,item in enumerate(dataset):\n",
        "        if subset_name == 'val' and i<140:\n",
        "          continue\n",
        "        print('i',i)\n",
        "        print('item: ',item)\n",
        "\n",
        "        image = item['image']  # Assuming it's a PIL.Image object\n",
        "\n",
        "\n",
        "        # Create a unique ID for each image\n",
        "        unique_id = str(uuid.uuid4())\n",
        "\n",
        "\n",
        "        # Define image path\n",
        "        image_path = os.path.join(image_subfolder, f\"{unique_id}.jpg\")\n",
        "\n",
        "\n",
        "        # Save image\n",
        "        image.save(image_path)\n",
        "\n",
        "\n",
        "        # Remove duplicates and format answers\n",
        "        # answers = item['answers']\n",
        "        answers = item['response']\n",
        "        # unique_answers = list(set(answers))\n",
        "        # formatted_answers = \", \".join(unique_answers)\n",
        "        formatted_answers = answers\n",
        "\n",
        "\n",
        "        # Structure for LLaVA JSON\n",
        "        json_data = {\n",
        "            \"id\": unique_id,\n",
        "            \"image\": f\"{unique_id}.jpg\",\n",
        "            \"conversations\": [\n",
        "                {\n",
        "                    \"from\": \"human\",\n",
        "                    \"value\": \"<image>\\n\" + item['prompt']\n",
        "                },\n",
        "                {\n",
        "                    \"from\": \"gpt\",\n",
        "                    \"value\": formatted_answers\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "\n",
        "\n",
        "        # Append to list\n",
        "        json_data_list.append(json_data)\n",
        "        if subset_name == 'train':\n",
        "          if i==139:\n",
        "            break\n",
        "        elif subset_name == 'val':\n",
        "          if i==149:\n",
        "            break\n",
        "\n",
        "\n",
        "    # Save the JSON data list to a file\n",
        "    json_output_path = os.path.join(output_folder, subset_name, 'dataset.json')\n",
        "    with open(json_output_path, 'w') as json_file:\n",
        "        json.dump(json_data_list, json_file, indent=4)\n",
        "\n",
        "\n",
        "def save_dataset(dataset_name, output_folder, subset_name):\n",
        "    # Load the dataset from Hugging Face\n",
        "    # dataset = load_dataset(dataset_name, split=subset_name)\n",
        "    dataset = dataset_name\n",
        "    # Process and save the datasets\n",
        "    for subset_name,data in [(subset_name,dataset)]:\n",
        "        if data:\n",
        "            process_and_save(data, output_folder, subset_name)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Usage example\n",
        "output_folder = 'dataset'\n",
        "save_dataset(vlm_dataset, output_folder, 'train')\n",
        "save_dataset(vlm_dataset, output_folder, 'val')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLUEmTLyoZ0Y",
        "outputId": "cc8f358a-c356-409a-e09f-35657b7a3b48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i 0\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA64BEB0>, 'prompt': 'Can you make a short description about the part: Ultrasonic Sensor\\n\\nIt should be divided into 3 sections as follows:\\n1) Description\\n2) Applications\\n3) technical specification', 'response': 'Description:\\nAn ultrasonic sensor is a device that measures the distance to an object by emitting ultrasonic sound waves and then detecting the waves that bounce back after hitting the object. It works on the principle of echolocation, similar to how bats navigate. The sensor typically consists of a transmitter, which emits ultrasonic waves, and a receiver, which detects the reflected waves. By measuring the time it takes for the waves to return, the sensor can calculate the distance to the object with high accuracy.\\nApplications:\\nUltrasonic sensors find applications in various fields, including robotics, automotive industry, healthcare, and industrial automation. In robotics, they are used for obstacle avoidance and navigation. In the automotive industry, they play a crucial role in parking assistance systems and collision avoidance systems. In healthcare, ultrasonic sensors are utilized for medical imaging, such as ultrasound scans. In industrial automation, they are employed for level measurement, object detection, and quality control.\\nTechnical Specifications:\\nOperating Principle: Ultrasonic echolocation\\nOperating Range: Varies depending on the model, typically ranging from a few centimeters to several meters\\nFrequency Range: Typically between 20 kHz to 200 kHz\\nAccuracy: High accuracy in distance measurement, often within millimeters\\nOutput: Digital or analog signal indicating distance\\nPower Supply: Typically operates on low voltage DC power supply\\nEnvironmental Considerations: Can be affected by environmental factors such as temperature, humidity, and acoustic interference'}\n",
            "i 1\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFF1DEEF0>, 'prompt': 'You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: 104 pF ceramic capacitor. Give a description of the component having 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) Technical specifications', 'response': 'Description:\\r\\nThe 104 pF ceramic capacitor is a small, passive electronic component typically composed of ceramic material with conductive plates on either side. Its compact size and simple construction make it suitable for integration into various electronic circuits. This capacitor is marked with the numerical code \"104,\" where the first two digits represent the significant figures and the third digit indicates the number of zeros to follow, denoting its capacitance value in picofarads (pF).\\r\\nApplications:\\r\\nThe 104 pF ceramic capacitor finds applications across a wide range of electronic devices and circuits. Some common uses include:\\r\\nFiltering: It can be employed in signal filtering circuits to remove unwanted noise or interference, ensuring the integrity of the transmitted signal.\\r\\nTiming: In conjunction with resistors, it forms a timing component in oscillators and timing circuits, crucial for generating precise clock signals in digital systems.\\r\\nDecoupling: Placed strategically near integrated circuits (ICs), it serves to decouple power supplies, stabilizing voltage levels and minimizing voltage fluctuations during operation.\\r\\nCoupling: Used to couple AC signals between stages of amplifiers and other electronic circuits, facilitating signal transmission while blocking DC components.\\r\\nTuning: Integrated into radio frequency (RF) circuits, it aids in tuning the frequency response of resonant circuits, such as those found in radio receivers and transmitters.\\r\\nTechnical specifications:\\r\\nCapacitance: 104 pF (10^4 picofarads)\\r\\nTolerance: Typically ranges from ±5% to ±20%, indicating the acceptable deviation from the nominal capacitance value.\\r\\nVoltage rating: Capacitors are rated for a maximum voltage they can withstand without breakdown. The voltage rating for a 104 pF ceramic capacitor typically ranges from a few volts to tens or hundreds of volts, depending on the specific application and manufacturer.\\r\\nDielectric material: Ceramic capacitors utilize ceramic materials as their dielectric, providing stability, reliability, and low losses across a wide frequency range.\\r\\nPackage type: The 104 pF capacitor is commonly available in surface mount technology (SMT) packages, such as 0402 or 0603, for easy integration onto printed circuit boards (PCBs).'}\n",
            "i 2\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA64BF40>, 'prompt': 'You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: USA A to USB C. Give a description of the component having 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) Technical specifications', 'response': 'Description:\\r\\nThe USA A to USB C adapter is a compact and versatile piece of hardware designed to bridge the gap between devices with different USB interfaces. It features a standard USB Type-A male connector on one end and a USB Type-C female port on the other. The adapter is typically small in size, making it portable and easy to carry around. It allows users to connect USB Type-A devices, such as flash drives, keyboards, or mice, to newer devices equipped with USB Type-C ports, including laptops, smartphones, and tablets.\\r\\nApplications:\\r\\nDevice Compatibility: The adapter enables compatibility between legacy USB Type-A devices and modern USB Type-C devices, extending the lifespan and utility of older peripherals.\\r\\nData Transfer: It facilitates data transfer between devices, allowing users to transfer files, documents, and multimedia content from USB Type-A devices to USB Type-C devices and vice versa.\\r\\nCharging: The adapter can also be used for charging purposes, enabling users to connect USB Type-A chargers or power banks to USB Type-C devices for charging and power delivery.\\r\\nPeripheral Connectivity: Users can connect a wide range of USB Type-A peripherals to USB Type-C devices, including external storage drives, printers, cameras, and more, expanding the functionality of modern devices.\\r\\nTechnical Specifications:\\r\\nConnector Type: USB Type-A male to USB Type-C female\\r\\nCompatibility: Supports USB Type-A devices (USB 2.0/3.0) to USB Type-C devices\\r\\nData Transfer Rate: Supports data transfer speeds up to 5 Gbps (USB 3.0)\\r\\nPower Delivery: Supports power delivery for charging and powering connected devices\\r\\nDimensions: Compact and lightweight design for portability\\r\\nMaterial: Typically constructed with durable materials for long-term use\\r\\nCompatibility: Compatible with a wide range of devices, including laptops, smartphones, tablets, and more, supporting various operating systems such as Windows, macOS, Android, and Linux.\\n'}\n",
            "i 3\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFF1DF5E0>, 'prompt': 'Can you make a short description about the part: Rotary Encoder Module\\r\\n\\r\\nIt should be divided into 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) technical specification', 'response': \"Description:\\r\\nA Rotary Encoder Module is a sensor device used to detect rotational movement and convert it into digital signals. It typically consists of a rotating shaft and a stationary sensor. As the shaft turns, the sensor detects the changes in position and outputs corresponding electrical signals, which are then processed by a microcontroller or other electronic device.\\r\\nApplications:\\r\\nRotary Encoder Modules are commonly used in various applications where precise rotational control or measurement is required. Some common applications include:\\r\\nIndustrial automation: Used in machinery for position sensing, speed control, and motion detection.\\r\\nRobotics: Integrated into robotic arms and joints for precise movement control.\\r\\nCNC machines: Utilized for accurate positioning of cutting tools and components.\\r\\nConsumer electronics: Found in devices like computer mice, audio equipment, and volume controls for user input and adjustment.\\r\\nAutomotive: Used in vehicle systems such as steering angle sensors and throttle position sensors.\\r\\nTechnical Specifications:\\r\\nResolution: Specifies the number of pulses generated per revolution, determining the encoder's precision.\\r\\nOutput Interface: Describes the type of electrical signals outputted by the encoder, such as quadrature signals or digital pulses.\\r\\nOperating Voltage: Indicates the voltage range within which the encoder operates.\\r\\nShaft Type: Specifies the type of shaft (e.g., hollow shaft, solid shaft) and its dimensions (diameter, length).\\r\\nEnvironmental Considerations: Includes factors such as operating temperature range, protection against dust and moisture (IP rating), and resistance to shock and vibration.\\r\\nMounting Options: Describes the methods available for mounting the encoder onto a surface or device.\\r\\nAdditional Features: May include built-in debouncing circuits, detents for tactile feedback, and customizable settings for specific applications.\"}\n",
            "i 4\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA64BE20>, 'prompt': 'You have been given an IoT kit component: 3-6V motor. Give a description of the component having 3 sections as follows:\\n1) Description\\n2) Applications\\n3) Technical specifications', 'response': \"Description:\\r\\nThe 3-6V motor is a compact, electric motor designed for low-voltage applications. It typically consists of a cylindrical body with two wires extending from one end for electrical connection. Inside the motor housing, there's a rotor (the rotating part) and a stator (the stationary part) that interact to produce rotational motion when electricity is supplied.\\r\\nApplications:\\r\\nRobotics: Used in small robotic projects for locomotion or actuation.\\r\\nDIY Electronics: Incorporated into hobbyist projects such as remote-controlled cars, boats, or planes.\\r\\nAutomation: Employed in various automated systems for tasks like opening/closing doors, controlling blinds, or moving objects along a conveyor belt.\\r\\nPrototyping: Integrated into prototype designs for proof of concept or testing of mechanical components.\\r\\nEducational purposes: Utilized in STEM education to teach principles of electricity, magnetism, and motion.\\r\\nTechnical Specifications:\\r\\nVoltage: Operates within the range of 3-6 volts DC (Direct Current), making it suitable for low-voltage applications.\\r\\nRPM (Rotations Per Minute): Depending on the specific model and load conditions, the motor's rotational speed can vary from a few hundred to a few thousand RPM.\\r\\nTorque: Provides a certain amount of rotational force, measured in Newton-meters (Nm) or ounce-inches (oz-in), which determines its ability to perform work against resistance.\\r\\nSize and Weight: Typically compact and lightweight, making it suitable for small-scale projects where space and weight are constraints.\\r\\nMounting: Often designed with mounting holes or brackets for easy installation onto a chassis or frame.\\r\\nMotor Type: Can be a brushed or brushless motor, with brushed motors being simpler and less expensive, while brushless motors offer higher efficiency and longer lifespan but are more complex and costly.\\r\\nControl: Can be controlled using various methods such as PWM (Pulse Width Modulation), H-bridge motor drivers, or motor controller modules, allowing for precise speed and direction control.\"}\n",
            "i 5\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA4C29E0>, 'prompt': 'You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: Servo Motor SG90. Give a description of the component having 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) Technical specifications', 'response': \"Description:\\r\\nThe Servo Motor SG90 is a small, lightweight, and precise motor commonly used in hobbyist and DIY electronics projects. It consists of a DC motor, gearbox, and control circuitry packaged in a compact housing. The motor's rotation angle can be controlled accurately by sending PWM (Pulse Width Modulation) signals to its control input, allowing for precise positioning.\\r\\nApplications:\\r\\nRobotics: SG90 servo motors are frequently used in small robotic projects for controlling robot arms, grippers, or movement of robotic platforms.\\r\\nRC Vehicles: They are employed in radio-controlled cars, planes, boats, and other vehicles to control steering mechanisms or other moving parts.\\r\\nCamera Gimbal Stabilization: Due to their precision and compact size, SG90 servos can be used in camera gimbals to stabilize cameras during movement.\\r\\nAutomation: SG90 servos find applications in various automated systems where precise control of movement is required, such as in automated door locks, blinds, or surveillance camera positioning.\\r\\nDIY Projects: Hobbyists often use SG90 servos in DIY projects like animatronics, model trains, or remote-controlled gadgets due to their affordability and ease of use.\\r\\nTechnical Specifications:\\r\\nOperating Voltage: Typically operates at 4.8V - 6V DC.\\r\\nTorque: Produces a torque of around 1.8 kg-cm at 4.8V.\\r\\nSpeed: Rotational speed varies depending on the voltage but typically around 0.1 sec/60 degrees at 4.8V.\\r\\nControl Signal: Accepts PWM signals with a pulse width ranging from 500 microseconds to 2500 microseconds.\\r\\nDimensions: Compact size, usually around 23mm x 12mm x 29mm.\\r\\nWeight: Lightweight, approximately 9 grams.\\r\\nGear Material: Metal or plastic gears, depending on the model.\\r\\nRotation Range: Can rotate up to 180 degrees, although some models may offer continuous rotation.\\r\\nOperating Temperature: Can operate within a temperature range of -30°C to 60°C, making it suitable for various environments.\"}\n",
            "i 6\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA64BF40>, 'prompt': 'You have been given an IoT kit component: Thermistor. Give a description of the component having 3 sections as follows:\\n1) Description\\n2) Applications\\n3) Technical specifications', 'response': \"Description:\\r\\nA thermistor is a type of resistor whose resistance varies significantly with temperature. It's made from semiconductor materials, usually metal oxides, and its resistance decreases as temperature increases (negative temperature coefficient - NTC) or increases as temperature increases (positive temperature coefficient - PTC). Thermistors are small, often bead-shaped components that are sensitive to changes in temperature, making them ideal for temperature sensing applications.\\r\\nApplications:\\r\\nTemperature Sensing: Thermistors are commonly used in temperature measurement and control systems. They are found in thermostats, HVAC systems, industrial equipment, and consumer electronics to monitor and regulate temperature.\\r\\nOverheat Protection: In devices like power supplies, battery chargers, and motor control circuits, thermistors are used to detect overheating and trigger protective measures such as shutdown or alarms.\\r\\nTemperature Compensation: Thermistors are employed in various electronic circuits to compensate for temperature-induced changes in component characteristics, ensuring stable performance over a wide temperature range.\\r\\nMedical Devices: Thermistors play a vital role in medical devices for measuring body temperature, monitoring patient temperature during surgeries, and controlling thermal treatments.\\r\\nAutomotive Applications: They are used in automotive systems for measuring coolant temperature, intake air temperature, and controlling climate systems.\\r\\nTechnical Specifications:\\r\\nResistance: The resistance of a thermistor varies with temperature according to its temperature-resistance curve. The resistance at a specified temperature (usually 25°C or 77°F) is typically provided in datasheets.\\r\\nTemperature Coefficient: This indicates the rate at which the resistance changes with temperature. NTC thermistors have a negative temperature coefficient, while PTC thermistors have a positive temperature coefficient.\\r\\nOperating Temperature Range: Specifies the range of temperatures over which the thermistor can accurately measure temperature.\\r\\nAccuracy: Describes how closely the thermistor's measured temperature matches the actual temperature.\\r\\nResponse Time: The time it takes for the thermistor to reach 63.2% (one time constant) or 95% (two time constants) of the temperature difference between its initial and final states in response to a step change in temperature.\\r\\nPackage Type: Thermistors come in various package types, including bead, surface mount, and axial lead, which determine their physical size and mounting options.\"}\n",
            "i 7\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA4C2C20>, 'prompt': 'Can you make a short description about the part: NPN transistor PN2222\\n\\nIt should be divided into 3 sections as follows:\\n1) Description\\n2) Applications\\n3) technical specification', 'response': 'Description:\\nThe PN2222 is a popular NPN bipolar junction transistor (BJT) widely used in electronic circuits. It is housed in a TO-92 package, making it compact and easy to handle. With its three terminals—Emitter (E), Base (B), and Collector (C)—the PN2222 facilitates amplification and switching of electrical signals in various applications.\\nApplications:\\nThe PN2222 transistor finds application in a multitude of electronic circuits, including but not limited to:\\nSignal amplification: Used in audio amplifiers, RF amplifiers, and sensor circuits to boost weak signals.\\nSwitching: Employed in digital logic circuits, relay drivers, motor control circuits, and LED drivers to control the flow of current.\\nOscillation: Integrated into oscillators and RF oscillator circuits for generating signals at specific frequencies.\\nTechnical Specifications:\\nMaximum Collector-Base Voltage (VCBO): 75V\\nMaximum Collector-Emitter Voltage (VCEO): 40V\\nMaximum Emitter-Base Voltage (VEBO): 6V\\nMaximum Collector Current (IC): 600mA\\nPower Dissipation (PD): 625mW\\nTransition Frequency (ft): 250MHz\\nOperating Temperature Range: -55°C to +150°C\\nPackage Type: TO-92'}\n",
            "i 8\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFB839FF0>, 'prompt': 'Can you make a short description about the part: 5V Relay\\n\\nIt should be divided into 3 sections as follows:\\n1) Description\\n2) Applications\\n3) technical specification', 'response': 'Description:\\nA 5V relay is an electromechanical switch that is activated by a small electrical signal, typically 5 volts. It consists of a coil, which when energized, generates a magnetic field that pulls a movable armature to make or break electrical contacts within the relay. This allows it to control higher voltage or current circuits with a low-voltage signal.\\nApplications:\\n5V relays find widespread use in various electronic and electrical applications, including home automation, robotics, automotive systems, and industrial control. They are commonly employed to switch power to appliances, lights, motors, and other devices based on signals from microcontrollers, sensors, or other control circuits. Additionally, they are utilized for safety interlocking, signal routing, and power distribution in complex systems.\\nTechnical Specification:\\nCoil Voltage: 5V DC\\nContact Rating: Typically ranging from a few volts to several hundred volts AC or DC, with current ratings from milliamps to tens of amps.\\nContact Configuration: Normally Open (NO), Normally Closed (NC), or Changeover (CO) configurations are available.\\nContact Material: Commonly made of silver alloy for good conductivity and durability.\\nSwitching Time: Typically in the range of milliseconds to microseconds, depending on the specific relay model.\\nSize and Mounting: Available in various sizes and mounting options, such as through-hole or surface-mount, to suit different applications.\\nOperating Temperature: Typically specified by the manufacturer, ranging from -40°C to 85°C or higher.\\nLifespan: Rated for a certain number of mechanical and electrical operations, which can range from thousands to millions depending on the relay quality and usage conditions.'}\n",
            "i 9\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA4C30A0>, 'prompt': 'You have been given an IoT kit component: ELEGOO Remote Control. Give a description of the component having 3 sections as follows:\\n1) Description\\n2) Applications\\n3) Technical specifications', 'response': \"Description:\\r\\nThe ELEGOO Remote Control is a wireless input device designed for interfacing with Internet of Things (IoT) projects. It consists of a handheld remote control unit and a corresponding receiver module. The remote control typically features various buttons or switches that can be used to send commands or signals wirelessly to the receiver, which in turn can trigger actions or control devices connected to an IoT system.\\r\\nApplications:\\r\\nThe ELEGOO Remote Control can be utilized in a wide range of IoT applications, including home automation, smart appliances, robotics, and remote monitoring systems. Some common applications include:\\r\\nControlling lights, fans, and other electrical appliances remotely.\\r\\nOperating robotic devices or drones wirelessly.\\r\\nAdjusting parameters or settings in IoT sensor networks.\\r\\nImplementing security systems with remote arming and disarming capabilities.\\r\\nInterfacing with multimedia devices such as TVs, stereos, and projectors for remote control functionality.\\r\\nTechnical Specifications:\\r\\nWireless Communication Protocol: Typically uses RF (Radio Frequency) or IR (Infrared) technology for communication between the remote control and the receiver module.\\r\\nOperating Range: The effective range between the remote control and the receiver module, which can vary depending on the specific model and environmental factors.\\r\\nPower Source: Both the remote control and the receiver module may require batteries or an external power source for operation.\\r\\nCompatibility: The remote control may come with compatibility for specific IoT platforms or microcontroller boards, such as Arduino, Raspberry Pi, or ESP8266/ESP32.\\r\\nInput Interface: The remote control unit typically features buttons, switches, or a combination of both for user input.\\r\\nDimensions and Form Factor: Physical dimensions and design of the remote control and receiver module, which may vary based on the manufacturer's specifications and intended use cases.\"}\n",
            "i 10\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFB839FF0>, 'prompt': 'You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: NPN transistor PN2222. Give a description of the component having 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) Technical specifications', 'response': 'Description:\\r\\nThe NPN transistor PN2222 is a versatile electronic component commonly used in various electronic circuits. It belongs to the bipolar junction transistor (BJT) family and is housed in a small TO-92 package, making it easy to handle and integrate into circuits. The PN2222 is designed with three terminals: the emitter (E), the base (B), and the collector (C). It operates as an amplifying device, controlling the flow of current between the collector and emitter terminals based on the current applied to the base terminal.\\r\\nApplications:\\r\\nThe PN2222 transistor finds extensive use in a wide range of electronic applications due to its reliability and versatility. Some common applications include:\\r\\nSwitching Circuits: The PN2222 can be used as a switch to control larger currents or voltages with a smaller input signal. It is commonly employed in relay drivers, motor control circuits, LED drivers, and other switching applications.\\r\\nAmplification: As a bipolar junction transistor, the PN2222 can amplify small signals. It is utilized in audio amplifiers, signal processing circuits, and sensor interfacing circuits where signal amplification is required.\\r\\nOscillator Circuits: PN2222 transistors can be used in oscillator circuits to generate clock signals or oscillatory waveforms, essential in timing applications and electronic devices such as clocks, timers, and pulse generators.\\r\\nVoltage Regulation: In voltage regulator circuits, PN2222 transistors can be used to regulate voltage levels, ensuring stable power supplies for various electronic systems.\\r\\nLogic Circuits: The PN2222 can also be incorporated into digital logic circuits, particularly in applications where low-power consumption and compact size are essential.\\r\\nTechnical Specifications:\\r\\nThe PN2222 transistor typically has the following technical specifications:\\r\\nMaximum Collector-Base Voltage (Vcb): 75V\\r\\nMaximum Collector-Emitter Voltage (Vce): 40V\\r\\nMaximum Emitter-Base Voltage (Veb): 6V\\r\\nMaximum Collector Current (Ic): 600mA\\r\\nMaximum Power Dissipation (Pd): 500mW\\r\\nTransition Frequency (ft): 300MHz (typical)\\r\\nDC Current Gain (hFE): 100 - 300\\r\\nOperating Temperature Range: -55°C to +150°C'}\n",
            "i 11\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA4C3100>, 'prompt': 'Can you make a short description about the part: HiLetgo GY-521 module\\n\\nIt should be divided into 3 sections as follows:\\n1) Description\\n2) Applications\\n3) technical specification', 'response': 'Description:\\r\\nThe HiLetgo GY-521 module is a compact and versatile sensor module designed for motion sensing and orientation tracking applications. It is based on the MPU-6050 sensor chip, which integrates a three-axis gyroscope and a three-axis accelerometer into a single package. This module also includes an onboard voltage regulator and I2C communication interface, making it easy to interface with microcontrollers and other devices.\\r\\nApplications:\\r\\nThe GY-521 module finds wide applications in various fields such as robotics, drones, virtual reality systems, motion-controlled gaming consoles, and wearable devices. It is commonly used for motion tracking, gesture recognition, stabilization, and orientation sensing tasks. Hobbyists and electronics enthusiasts often use it for prototyping and experimenting with motion-based projects.\\r\\nTechnical Specifications:\\r\\nSensor Chip: MPU-6050\\r\\nGyroscope Range: ±250, ±500, ±1000, or ±2000 degrees per second (dps)\\r\\nAccelerometer Range: ±2g, ±4g, ±8g, or ±16g\\r\\nCommunication Interface: I2C (Standard Mode: 100 kHz, Fast Mode: 400 kHz)\\r\\nOperating Voltage: 3.3V - 5V\\r\\nDimensions: 20mm x 16mm x 3mm\\r\\nOnboard Voltage Regulator: Yes\\r\\nOperating Temperature Range: -40°C to +85°C\\r\\nBuilt-in Motion Detection Interrupts: Yes\\r\\nProgrammable Digital Low Pass Filter: Yes\\r'}\n",
            "i 12\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFF30EB60>, 'prompt': 'You have been given an IoT kit component: RC522 RFID Module. Give a description of the component having 3 sections as follows:\\n1) Description\\n2) Applications\\n3) Technical specifications', 'response': 'Description:\\r\\nThe RC522 RFID Module is a compact electronic device designed for reading and writing Radio-Frequency Identification (RFID) tags. It utilizes electromagnetic fields to communicate with RFID tags and can be integrated into various projects for tracking, identification, and access control purposes. The module typically consists of an antenna coil, an RFID reader IC (such as the RC522), and supporting circuitry. It communicates with microcontrollers or other host devices via SPI (Serial Peripheral Interface) or UART (Universal Asynchronous Receiver-Transmitter) protocols.\\r\\nApplications:\\r\\nAccess Control Systems: The RC522 module can be used in access control systems to grant or restrict entry based on RFID tag authentication.\\r\\nInventory Management: It can be employed in inventory management systems to track and manage products or assets using RFID tags.\\r\\nAttendance Systems: The module can be integrated into attendance tracking systems for schools, offices, or events, allowing users to check in or out using RFID-enabled cards or tags.\\r\\nSmart Locks: RC522 can be utilized in smart lock systems for homes or offices, enabling keyless entry using RFID cards or tags.\\r\\nPayment Systems: It can be integrated into payment systems for contactless transactions using RFID-enabled cards or mobile devices.\\r\\nTechnical Specifications:\\r\\nOperating Voltage: Typically operates at 3.3V or 5V DC.\\r\\nCommunication Interface: Supports SPI (Serial Peripheral Interface) or UART (Universal Asynchronous Receiver-Transmitter) protocols for communication with microcontrollers or host devices.\\r\\nFrequency: Operates at 13.56 MHz frequency.\\r\\nReading Distance: Typically has a reading distance of a few centimeters to a few meters, depending on the antenna design and RFID tag type.\\r\\nSupported RFID Tags: Compatible with various RFID tags compliant with ISO/IEC 14443 Type A standards, including MIFARE cards.\\r\\nDimensions: Compact form factor, usually around 40mm x 60mm in size, depending on the specific module design.'}\n",
            "i 13\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA4C2C50>, 'prompt': 'You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: Elegoo UNO R3 controller board. Give a description of the component having 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) Technical specifications', 'response': 'Description:\\r\\nThe Elegoo UNO R3 controller board is a microcontroller board based on the ATmega328P. It is essentially a clone of the Arduino UNO R3 board, featuring the same form factor and compatibility with Arduino software and shields. The board is designed to be versatile, user-friendly, and suitable for beginners and experienced users alike in the realm of electronics and programming. It consists of a microcontroller unit (MCU), digital and analog input/output pins, USB interface for programming and power, power jack, reset button, and various onboard components to support its functionality.\\r\\nApplications:\\r\\nPrototyping: Ideal for prototyping various IoT (Internet of Things) projects and electronic gadgets.\\r\\nHome Automation: Can be used to build smart home devices such as automated lighting systems, temperature monitors, and security systems.\\r\\nData Logging: Capable of collecting data from sensors and logging it for analysis, useful in environmental monitoring or industrial applications.\\r\\nRobotics: Suitable for controlling motors and sensors in robotics projects, enabling the creation of autonomous or remote-controlled robots.\\r\\nEducation: Widely used in educational settings to teach electronics, programming, and IoT concepts due to its simplicity and compatibility with the Arduino platform.\\r\\nTechnical Specifications:\\r\\nMicrocontroller: ATmega328P\\r\\nOperating Voltage: 5V\\r\\nInput Voltage (recommended): 7-12V\\r\\nDigital I/O Pins: 14 (of which 6 provide PWM output)\\r\\nAnalog Input Pins: 6\\r\\nDC Current per I/O Pin: 20 mA\\r\\nDC Current for 3.3V Pin: 50 mA\\r\\nFlash Memory: 32 KB (0.5 KB used by bootloader)\\r\\nSRAM: 2 KB\\r\\nEEPROM: 1 KB\\r\\nClock Speed: 16 MHz\\r\\nDimensions: 68.6mm x 53.4mm\\r\\nWeight: 25g\\r\\nUSB Interface: ATmega16U2\\r\\nInput Voltage (USB): 5V\\r\\nDigital I/O Pins Voltage: 5V\\r\\nAnalog Input Pins Voltage: 5V\\r\\nOperating Temperature: -40°C to 85°C'}\n",
            "i 14\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFF30EB60>, 'prompt': 'You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: Potentiometer 10K. Give a description of the component having 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) Technical specifications', 'response': 'Description:\\r\\nA Potentiometer 10K, short for Potentiometer with a resistance value of 10 kilo-ohms, is a variable resistor that allows for precise control over the flow of electric current. It consists of a resistive element usually made of carbon, cermet, or conductive plastic, along with a wiper that can slide along this element. The resistance between the wiper and one end of the resistive element can be varied by rotating the shaft or sliding the wiper, thereby changing the voltage division in a circuit.\\r\\nApplications:\\r\\nPotentiometers find wide-ranging applications in various electronic circuits and systems, including:\\r\\nVolume Control: In audio equipment like amplifiers, radios, and mixers, potentiometers are used to adjust the volume.\\r\\nBrightness Control: In lighting systems, potentiometers can be used to control the intensity or brightness of lights, including LED strips.\\r\\nMotor Speed Control: Potentiometers can regulate the speed of DC motors by controlling the voltage supplied to them.\\r\\nUser Interface: They are often used in user interface elements like knobs and sliders in electronic devices to provide manual control over parameters.\\r\\nCalibration: Potentiometers are also employed in calibration setups and instrumentation circuits where precise adjustment of voltage or resistance is required.\\r\\nTechnical Specifications:\\r\\nResistance: 10 kilo-ohms (10KΩ)\\r\\nPower Rating: The maximum power that can be dissipated across the potentiometer without damage, typically ranging from 0.1 to 2 watts.\\r\\nTolerance: Specifies the allowable deviation from the nominal resistance value, often ranging from 5% to 20%.\\r\\nOperating Temperature: The range of temperatures within which the potentiometer can safely operate without significant deviation from its electrical properties.\\r\\nPhysical Dimensions: Dimensions such as length, width, and height, along with mounting options, determine how and where the potentiometer can be installed.\\r\\nMechanical Lifespan: Specifies the number of cycles or rotations the potentiometer can endure before failure.\\r\\nElectrical Connections: Typically, potentiometers have three terminals: the two ends of the resistive element and the wiper terminal. The wiper terminal is connected to the circuit to provide variable resistance.'}\n",
            "i 15\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFB839FF0>, 'prompt': 'Can you make a short description about the part: Diode Rectifier\\r\\n\\r\\nIt should be divided into 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) technical specification', 'response': \"Description:\\r\\nA diode rectifier is an electronic component that converts alternating current (AC) into direct current (DC) by allowing current to flow in only one direction. It consists of a semiconductor junction between a P-type and an N-type material, creating a barrier that permits current flow when the voltage is applied in the forward direction and blocks it when applied in the reverse direction.\\r\\nApplications:\\r\\nDiode rectifiers are extensively used in power supply circuits to convert AC power from the mains into DC power for various electronic devices such as televisions, computers, and mobile phones. They are also employed in signal demodulation, voltage regulation, and battery charging circuits. In addition, diode rectifiers find applications in automotive electronics, renewable energy systems, and industrial machinery where conversion from AC to DC power is required.\\r\\nTechnical Specifications:\\r\\nThe technical specifications of a diode rectifier include parameters such as forward voltage drop, maximum forward current, reverse voltage, reverse recovery time, and power dissipation rating. Forward voltage drop typically ranges from about 0.2 to 1.0 volts, depending on the diode's material and design. Maximum forward current indicates the maximum current the diode can safely handle in the forward direction. Reverse voltage specifies the maximum voltage that can be applied across the diode in the reverse direction without causing breakdown. Reverse recovery time refers to the time required for the diode to switch from conducting to non-conducting state when the applied voltage changes direction. Power dissipation rating determines the maximum amount of power the diode can dissipate without overheating and failing. These specifications vary among different types and models of diode rectifiers, catering to various application requirements.\"}\n",
            "i 16\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA64BE20>, 'prompt': 'You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: Diode Rectifier. Give a description of the component having 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) Technical specifications', 'response': 'Description:\\r\\nA diode rectifier is a semiconductor device that allows current to flow in one direction only, effectively converting alternating current (AC) into direct current (DC). It consists of a PN junction, typically made of silicon or germanium, with two terminals: an anode and a cathode. When the voltage at the anode is higher than the voltage at the cathode, the diode becomes forward-biased, allowing current to flow through it. Conversely, when the voltage at the cathode is higher than the voltage at the anode, the diode becomes reverse-biased, blocking current flow. Diode rectifiers come in various packages, including discrete through-hole and surface-mount types, as well as integrated circuits.\\r\\nApplications:\\r\\nDiode rectifiers find widespread applications in various electronic circuits, especially in power supply units, where converting AC to DC is necessary. Some common applications include:\\r\\nAC to DC converters: Diode rectifiers are used in bridge rectifiers and full-wave rectifiers to convert AC voltage from mains power into DC voltage for powering electronic devices.\\r\\nBattery charging circuits: They are employed in rectifying AC voltage from adapters or generators to charge batteries efficiently.\\r\\nSignal demodulation: Diode rectifiers are used in radio and communication circuits to extract the modulating signal from the carrier wave.\\r\\nVoltage regulation: In combination with capacitors and voltage regulators, diode rectifiers are used to stabilize and regulate DC voltage levels.\\r\\nTechnical Specifications:\\r\\nThe technical specifications of a diode rectifier depend on factors such as its construction, material, maximum forward current, maximum reverse voltage, and switching characteristics. Some typical specifications include:\\r\\nMaximum forward current (If): This is the maximum current that the diode can conduct without damage when it is forward-biased.\\r\\nMaximum reverse voltage (Vr): This is the maximum voltage that the diode can withstand in the reverse direction without breakdown.\\r\\nForward voltage drop (Vf): This is the voltage drop across the diode when it is conducting in the forward direction. It is typically around 0.7 volts for silicon diodes and varies with temperature and current.\\r\\nReverse recovery time: This is the time it takes for the diode to switch from the conducting state to the blocking state when the polarity of the applied voltage changes from forward to reverse. Lower reverse recovery time indicates faster switching speed.\\r\\nPower dissipation (Pd): This is the maximum amount of power that the diode can dissipate without exceeding its maximum junction temperature.\\r\\nPackage type: Diode rectifiers come in various packages such as DO-41, DO-15, TO-220, SMD, etc., which determine their physical dimensions and mounting configurations.'}\n",
            "i 17\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA4C2CB0>, 'prompt': 'You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: Rotary Encoder Module. Give a description of the component having 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) Technical specifications', 'response': 'Description:\\nA Rotary Encoder Module is a compact electronic device primarily used for converting the angular position or rotation of a shaft into digital signals. It typically consists of a rotary encoder mounted on a PCB (Printed Circuit Board) along with necessary interfacing components. The rotary encoder itself comprises a rotating shaft with a series of contacts or a coded disc and sensors that detect changes in position as the shaft turns. These changes are then translated into digital signals, usually in the form of pulse outputs or digital codes, which can be processed by microcontrollers or other digital systems.\\nApplications:\\nThe Rotary Encoder Module finds wide-ranging applications across various industries and domains, owing to its versatility and precision in detecting rotational movements. Some common applications include:\\nUser input devices: Used in electronic knobs, dials, and control panels for devices such as audio equipment, industrial machinery, and consumer electronics.\\nRobotics: Employed in robotic joints and actuators to monitor and control the rotation of motors and mechanical components.\\nMeasurement and instrumentation: Integrated into devices for measuring angles, distances, and rotational speed in applications like CNC machines, telescopes, and motorized positioning systems.\\nHuman-machine interfaces (HMI): Incorporated into user interfaces for industrial control systems, home automation, and virtual reality devices to provide intuitive control and feedback mechanisms.\\nGaming peripherals: Utilized in gaming controllers and steering wheels to capture rotational inputs for interactive gameplay experiences.\\nAutomotive: Integrated into vehicle systems for functions like steering angle detection, throttle position sensing, and gearbox control.\\nTechnical specifications:\\nRotary encoder type: Incremental or Absolute\\nResolution: Number of pulses per revolution (PPR) for incremental encoders, or number of unique positions for absolute encoders.\\nOutput interface: Digital output signals such as quadrature, parallel, or serial communication protocols like SPI (Serial Peripheral Interface) or I2C (Inter-Integrated Circuit).\\nOperating voltage: Typically ranging from 3.3V to 5V DC.\\nOperating temperature range: -40°C to +85°C or higher, depending on the specific model.\\nMechanical dimensions: Diameter and length of the shaft, mounting hole dimensions, and overall form factor.\\nEnvironmental protection: Some rotary encoder modules may feature IP (Ingress Protection) ratings for resistance against dust and moisture, suitable for harsh operating conditions.\\nLifespan: Expected operational lifetime or MTTF (Mean Time To Failure) under normal usage conditions.\\nAdditional features: Built-in debouncing circuitry, detents for tactile feedback, and adjustable shaft sensitivity may be available in certain models, enhancing usability and reliability.'}\n",
            "i 18\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA64BF40>, 'prompt': 'Can you make a short description about the part: 3-6V motor\\n\\nIt should be divided into 3 sections as follows:\\n1) Description\\n2) Applications\\n3) technical specification', 'response': 'Description:\\r\\nA 3-6V motor is a versatile electromechanical device designed to convert electrical energy into mechanical energy. This type of motor operates effectively within a voltage range of 3 to 6 volts, making it suitable for a variety of low-power applications. Typically compact and lightweight, these motors often feature a simple design consisting of a rotor, stator, and brushes, allowing for efficient conversion of electrical power into rotational motion.\\r\\nApplications:\\r\\nRobotics: 3-6V motors are commonly used in robotics applications due to their compact size and compatibility with low-voltage power sources. They can power wheels, manipulator arms, and other moving components in robotic systems.\\r\\nDIY Projects: Hobbyists and DIY enthusiasts often utilize 3-6V motors in various projects such as model cars, boats, airplanes, and small-scale machinery.\\r\\nEducational Purposes: These motors are frequently employed in educational settings to teach basic principles of electromechanical systems, circuitry, and motor control.\\r\\nPortable Devices: They can be found in small electronic devices such as toy drones, handheld fans, vibrating toothbrushes, and miniature appliances due to their low power consumption and compact size.\\r\\nTechnical Specifications:\\r\\nVoltage Range: 3-6 volts\\r\\nOperating Current: Typically ranges from a few milliamps to a few hundred milliamps, depending on the load and efficiency of the motor.\\r\\nRPM (Rotations Per Minute): Varies depending on the specific motor model and load conditions, but typically ranges from a few hundred to a few thousand RPM.\\r\\nTorque: The torque output of these motors is usually moderate, suitable for driving small loads or mechanisms.\\r\\nMotor Type: Depending on the application, these motors can be brushed or brushless, with brushed motors being simpler and typically more affordable, while brushless motors offer higher efficiency and longevity.\\r\\nMounting Options: They may feature various mounting options such as screw holes or brackets for easy integration into different systems and structures.'}\n",
            "i 19\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA4C2CB0>, 'prompt': 'Can you make a short description about the part: Snap on Connector Clip for 9V battery\\r\\n\\r\\nIt should be divided into 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) technical specification', 'response': 'Description:\\r\\nThe Snap-on Connector Clip for 9V battery is a convenient and reliable way to connect a 9V battery to various electronic devices. Its snap-on design ensures quick and secure attachment to the battery terminals, allowing for hassle-free installation and removal. The clip features sturdy construction and a compact size, making it ideal for both professional and DIY electronics projects.\\r\\nApplications:\\r\\nThis connector clip is widely used in a variety of applications, including powering small electronic devices such as remote controls, toys, smoke detectors, and portable audio equipment. It is also commonly utilized in prototyping and hobbyist projects where a reliable power source is needed.\\r\\nTechnical Specifications:\\r\\nCompatible Battery: 9V alkaline or rechargeable battery\\r\\nMaterial: High-quality plastic and metal components\\r\\nDimensions: Compact size for easy integration into electronic circuits\\r\\nConnection: Snap-on design for quick and secure attachment to battery terminals\\r\\nCurrent Rating: Designed to handle typical currents for 9V battery-operated devices\\r\\nDurability: Sturdy construction ensures long-lasting performance even in demanding environments'}\n",
            "i 20\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFF1DEEF0>, 'prompt': 'You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: Resistor. Give a description of the component having 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) Technical specifications', 'response': \"Description:\\r\\nA resistor is a passive two-terminal electrical component that opposes the flow of electric current. It is typically constructed using a ceramic or carbon composition and is characterized by its resistance value, measured in ohms (Ω). Resistors come in various shapes and sizes, with the most common being the cylindrical axial lead type, but they can also be found in surface mount packages for compact designs.\\r\\nApplications:\\r\\nResistors find extensive use across a wide range of electronic circuits, including those in IoT devices. Some common applications include:\\r\\nVoltage division: Resistors are frequently used to create voltage dividers, allowing precise control over voltage levels in a circuit.\\r\\nCurrent limiting: They are employed to limit the amount of current flowing through a circuit, preventing damage to sensitive components.\\r\\nPull-up and pull-down resistors: These are used in digital circuits to ensure a well-defined logic level, especially in microcontroller-based systems.\\r\\nFiltering: Resistors are used in conjunction with capacitors to create low-pass, high-pass, and band-pass filters, which are crucial for signal conditioning and noise reduction in IoT sensors and communication modules.\\r\\nTemperature sensing: Certain types of resistors exhibit a change in resistance with temperature, making them suitable for temperature sensing applications in IoT devices.\\r\\nTechnical Specifications:\\r\\nWhen selecting a resistor for a specific application, the following technical specifications need to be considered:\\r\\nResistance value (Ω): The nominal resistance value of the resistor, which determines how much it impedes the flow of current.\\r\\nTolerance (%): The allowable deviation from the nominal resistance value. Common tolerances include 1%, 5%, and 10%.\\r\\nPower rating (W): The maximum amount of power the resistor can dissipate without being damaged. It's essential to choose a resistor with a power rating higher than the anticipated power dissipation in the circuit.\\r\\nTemperature coefficient (ppm/°C): Some resistors exhibit a change in resistance with temperature. The temperature coefficient specifies this change per degree Celsius.\\r\\nPackage type: Resistors come in various package types, including through-hole and surface mount, each suited for different mounting methods and space constraints.\"}\n",
            "i 21\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA4C2B90>, 'prompt': 'You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: 9V battery. Give a description of the component having 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) Technical specifications', 'response': 'Description:\\r\\nThe 9V battery is a compact and portable power source commonly used in electronic devices. It typically consists of six smaller 1.5-volt cells connected in series within a rectangular housing, providing a total voltage output of 9 volts. These batteries are widely available and are known for their reliability and longevity.\\r\\nApplications:\\r\\nIoT Devices: 9V batteries are suitable for powering small IoT devices such as sensors, actuators, and low-power microcontrollers due to their compact size and adequate voltage output.\\r\\nRemote Monitoring Systems: They are ideal for remote monitoring systems deployed in areas without access to power outlets, providing a convenient and portable power solution.\\r\\nPortable Electronics: Many portable electronic devices, such as smoke detectors, portable radios, and handheld gaming consoles, utilize 9V batteries for their power needs.\\r\\nEducational Projects: 9V batteries are commonly used in educational projects and prototypes due to their simplicity and ease of use.\\r\\nTechnical Specifications:\\r\\nVoltage: 9 volts (nominal)\\r\\nChemistry: Typically, 9V batteries are available in two chemistries: alkaline and lithium.\\r\\nCapacity: Capacity varies depending on the brand and chemistry but typically ranges from 400mAh to 1200mAh.\\r\\nSize: The standard size of a 9V battery is approximately 48.5mm x 26.5mm x 17.5mm (L x W x H).\\r\\nTerminal Type: 9V batteries usually feature snap-style terminals for easy connection to electronic devices.\\r\\nShelf Life: These batteries have a relatively long shelf life, often retaining their charge for several years when stored properly.\\r\\nOperating Temperature: The operating temperature range varies depending on the battery chemistry but generally falls between -20°C to 60°C for alkaline batteries and -40°C to 60°C for lithium batteries.'}\n",
            "i 22\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFF30EB60>, 'prompt': 'You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: Passive Buzzer. Give a description of the component having 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) Technical specifications', 'response': 'Description:\\nA passive buzzer is a small electronic component designed to produce audible sound signals when an electric current is passed through it. It consists of a piezoelectric ceramic disc housed in a plastic or metal casing. When voltage is applied across the terminals of the buzzer, the piezoelectric element expands or contracts, causing mechanical vibrations that produce sound waves. Unlike active buzzers, passive buzzers do not have built-in oscillators or driver circuits, so they require an external signal source to produce sound.\\nApplications:\\nPassive buzzers find applications in various electronic projects and IoT devices where audible alerts, notifications, or alarms are required. Some common applications include:\\nIoT Devices: Passive buzzers can be integrated into IoT devices to provide audible feedback for user interactions, status updates, or alarm notifications.\\nHome Automation Systems: They can be used in smart home systems to indicate events such as doorbell presses, security breaches, or sensor activations.\\nAlarm Systems: Passive buzzers are commonly used in alarm clocks, security systems, and industrial alarms to alert users of critical events or emergencies.\\nEducational Projects: They are often used in educational electronics projects to demonstrate principles of sound generation and basic circuitry.\\nDIY Electronics: Hobbyists and makers often use passive buzzers in DIY electronics projects such as electronic games, musical instruments, or novelty gadgets.\\nTechnical Specifications:\\nOperating Voltage: Typically operates within a range of 3V to 12V, although specific models may have different voltage requirements.\\nSound Output: Generates sound waves with frequencies typically ranging from a few hundred Hertz to a few kilohertz.\\nOperating Current: Consumption varies depending on the voltage applied and the sound output level but is generally in the range of tens of milliamps.\\nConstruction: Consists of a piezoelectric ceramic disc mounted within a plastic or metal housing, with two external terminals for connection to a power source.\\nSize and Form Factor: Available in various sizes and shapes, with diameters ranging from a few millimeters to several centimeters, making them suitable for different applications and mounting configurations.\\nDurability: Relatively durable and resistant to mechanical stress, but excessive voltage or current can damage the piezoelectric element, leading to reduced performance or failure.\\nEnvironmental Considerations: Operating temperature range varies depending on the specific model but typically spans from -20°C to 70°C, making them suitable for indoor and outdoor use in most environments.'}\n",
            "i 23\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA4C1C30>, 'prompt': 'Can you make a short description about the part: Resistor\\r\\n\\r\\nIt should be divided into 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) technical specification', 'response': 'Description:\\r\\nA resistor is a fundamental electronic component designed to impede the flow of electric current in a circuit. It is typically constructed from materials with high resistance to electrical flow, such as carbon or metal. Resistor components come in various shapes and sizes, but they all function to regulate the amount of current flowing through a circuit by converting electrical energy into heat.\\r\\nApplications:\\r\\nResistors find extensive use in electronic circuits for a variety of purposes. They are commonly employed to control the voltage and current levels, limit the flow of current to protect sensitive components, divide voltage, terminate transmission lines, and set bias conditions in amplifiers. Additionally, resistors are crucial in analog-to-digital and digital-to-analog conversion processes, as well as in sensor circuits, voltage regulators, and signal conditioning circuits across industries like telecommunications, automotive, aerospace, and consumer electronics.\\r\\nTechnical Specifications:\\r\\nResistors are characterized by their resistance value, measured in ohms (Ω), which determines the extent to which they impede current flow. Other important specifications include tolerance (the degree to which the actual resistance may deviate from the specified value), power rating (the maximum amount of power the resistor can dissipate without damage), temperature coefficient (how much the resistance changes with temperature), and physical dimensions (size, shape, and mounting type). Resistors come in various types including carbon film, metal film, wire wound, and surface mount, each suited for specific applications based on their properties and construction.'}\n",
            "i 24\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFF32E890>, 'prompt': 'You have been given an IoT kit component: USA A to USB C. Give a description of the component having 3 sections as follows:\\n1) Description\\n2) Applications\\n3) Technical specifications', 'response': \"Description:\\r\\nThe USA A to USB C cable is a type of connector cable designed to facilitate data transfer and power delivery between devices. It features a standard USA A plug on one end and a USB C plug on the other. The USA A plug typically fits into standard USB ports found on computers, laptops, power adapters, and other electronic devices, while the USB C plug is commonly used in modern smartphones, tablets, laptops, and other gadgets. The cable is usually constructed with high-quality materials such as durable PVC or nylon braiding to ensure longevity and reliable performance.\\r\\nApplications:\\r\\nThis cable serves various applications in the IoT (Internet of Things) domain and beyond:\\r\\nCharging: It allows for fast charging of USB C-enabled devices from USA A power sources such as wall chargers, power banks, and car chargers.\\r\\nData Transfer: It enables the transfer of data between USB C devices and computers or other devices with USA A ports, facilitating tasks such as file sharing, software updates, and device synchronization.\\r\\nIoT Connectivity: The cable can be used to connect IoT devices, sensors, and modules with USB C interfaces to central processing units or data hubs for data collection, analysis, and control purposes.\\r\\nMobile Device Connectivity: It provides a convenient solution for connecting USB C smartphones, tablets, and laptops to USA A accessories like keyboards, mice, external storage drives, and displays.\\r\\nTechnical Specifications:\\r\\nConnector 1: USA A male plug\\r\\nConnector 2: USB C male plug\\r\\nCable Length: Typically available in various lengths ranging from 1 to 3 meters (or custom lengths)\\r\\nData Transfer Speed: Supports USB 2.0, USB 3.0, or USB 3.1 Gen 1/Gen 2 standards for high-speed data transfer rates (up to 10 Gbps for USB 3.1 Gen 2)\\r\\nPower Delivery: Depending on the cable's specifications, it may support various power delivery standards, including USB Power Delivery (PD), allowing for fast charging of compatible devices with power levels up to 100W (20V/5A)\\r\\nCompatibility: Compatible with devices featuring USA A and USB C ports, including smartphones, tablets, laptops, desktop computers, power adapters, hubs, and IoT devices.\"}\n",
            "i 25\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA64BF40>, 'prompt': 'You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: Photoresistor (photocell). Give a description of the component having 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) Technical specifications', 'response': \"Description:\\r\\nA photoresistor, also known as a photocell or light-dependent resistor (LDR), is a passive component that changes its resistance based on the amount of light falling on its surface. It consists of a semiconductor material whose resistance decreases with increasing incident light intensity. When light hits the surface of the photoresistor, the photons excite electrons within the semiconductor, causing them to move and lowering the resistance of the material. Conversely, in low light conditions, the resistance of the photoresistor increases.\\r\\nApplications:\\r\\nLight sensing: Photoresistors are commonly used in light-sensing applications where the intensity of ambient light needs to be detected or measured. For example, they can be used in outdoor lighting systems to automatically adjust the brightness of lights based on the surrounding environmental conditions.\\r\\nSecurity systems: Photoresistors can be employed in security systems to detect unauthorized entry by sensing changes in light levels. They are often used in conjunction with infrared sensors to create motion detection systems for homes and businesses.\\r\\nIndustrial automation: In industrial settings, photoresistors are utilized for tasks such as object detection, product sorting, and quality control. They can be integrated into machinery to detect the presence or absence of objects based on their shadow or reflectivity.\\r\\nPhotography: Photoresistors are used in some photography equipment for controlling exposure settings. They can be employed to trigger the shutter or adjust aperture settings based on the available light.\\r\\nTechnical Specifications:\\r\\nResistance: Typically, photoresistors have a high resistance in darkness, often in the range of several megaohms, and a low resistance in bright light, often in the range of tens to hundreds of ohms.\\r\\nSpectral response: The sensitivity of a photoresistor to different wavelengths of light varies based on the material used. Some photoresistors are more sensitive to visible light, while others are sensitive to infrared or ultraviolet radiation.\\r\\nResponse time: The response time of a photoresistor refers to the time it takes for the resistance to change in response to a change in light intensity. This can vary depending on factors such as the size and construction of the photoresistor.\\r\\nOperating temperature range: Photoresistors operate within a specified temperature range, which can vary depending on the material and construction. It's essential to ensure that the photoresistor is used within its specified temperature limits to maintain accurate performance.\"}\n",
            "i 26\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA4C30A0>, 'prompt': 'Can you make a short description about the part: 830 Tie-Points Breadboard\\r\\n\\r\\nIt should be divided into 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) technical specification', 'response': \"Description:\\r\\nThe 830 Tie-Points Breadboard is a versatile electronic prototyping tool used by hobbyists, students, and professionals alike. It features a grid of 830 tie-points arranged in a convenient layout, allowing for easy and flexible circuit construction without the need for soldering. The breadboard typically consists of a plastic base with metal clips or sockets that securely hold electronic components in place, facilitating rapid experimentation and iteration in circuit design.\\r\\nApplications:\\r\\nThis breadboard is widely used in electronics labs, classrooms, and workshops for various applications, including prototyping circuits for educational projects, testing electronic components, and developing prototypes for small-scale electronic devices. It's particularly useful for quickly assembling and modifying circuits during the design and troubleshooting phases of electronics projects.\\r\\nTechnical Specification:\\r\\n830 tie-points arranged in a standard 63 x 10 grid pattern\\r\\nPlastic base with self-adhesive backing for easy mounting on a variety of surfaces\\r\\nMetal clips or sockets provide secure connections for electronic components\\r\\nTypically designed to accommodate components with standard lead spacing\\r\\nCompatible with a wide range of electronic components, including resistors, capacitors, integrated circuits, and jumper wires\\r\\nCompact and lightweight design for portability and convenience in various work environments\"}\n",
            "i 27\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFF30EB60>, 'prompt': 'Can you make a short description about the part: Joystick Module\\r\\n\\r\\nIt should be divided into 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) technical specification', 'response': 'Description:\\r\\nA joystick module is a compact input device primarily used for controlling motion in electronic systems. It typically consists of a lever or a handle that can be moved in multiple directions, along with built-in sensors to detect the direction and magnitude of the movement. Joystick modules often feature a spring mechanism that returns the lever to its neutral position when released, providing tactile feedback to the user. These modules are commonly found in gaming consoles, remote-controlled vehicles, and industrial control systems.\\r\\nApplications:\\r\\nGaming: Joystick modules are extensively used in gaming consoles and arcade machines for controlling character movements, camera angles, and other in-game actions.\\r\\nRemote-controlled Vehicles: They serve as the primary control interface for remote-controlled cars, drones, and robotic arms, allowing precise navigation and manipulation.\\r\\nSimulation and Training: Joysticks are utilized in flight simulators, driving simulators, and other training systems to simulate real-world control interfaces for pilots, drivers, and operators.\\r\\nIndustrial Control: In industrial settings, joystick modules are employed for controlling machinery, cranes, and robotic arms, enabling operators to manipulate equipment with accuracy and efficiency.\\r\\nTechnical Specifications:\\r\\nOperating Voltage: Typically ranges from 3.3V to 5V DC.\\r\\nOutput Interface: Analog or digital output signals depending on the specific module.\\r\\nSensitivity: Adjustable sensitivity settings to customize the response of the joystick to user input.\\r\\nDimensions: Compact and lightweight design for easy integration into various electronic systems.\\r\\nDurability: Built to withstand frequent use and mechanical stress, with robust construction materials.\\r\\nCompatibility: Compatible with a wide range of microcontrollers and development platforms, including Arduino, Raspberry Pi, and other embedded systems.\\r\\nDirectional Range: Provides multi-directional movement detection, including up, down, left, right, and diagonal directions.\\r\\nInterface: Usually equipped with standard interface connectors for easy connection to host devices and external circuits.\\r\\nMounting Options: Designed for both panel mount and PCB mount configurations, offering flexibility in installation methods.'}\n",
            "i 28\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA4C1BD0>, 'prompt': 'You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: 4 Digit 7-segment Display. Give a description of the component having 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) Technical specifications', 'response': \"Description:\\r\\nThe 4 Digit 7-segment Display is a compact electronic component designed to visually display numerical digits from 0 to 9, as well as some alphabetic characters. It consists of four individual 7-segment displays arranged in a single package, each capable of displaying one digit. Each segment within the display can be individually illuminated to form the desired digit or character.\\r\\nApplications:\\r\\nDigital Clocks and Timers: One of the most common applications of the 4 Digit 7-segment Display is in digital clocks and timers. With its ability to display numerical digits, it can accurately show time in hours and minutes.\\r\\nCountdown Timers: Whether it's for cooking, sports events, or industrial processes, the display can be utilized as a countdown timer, showing the remaining time in a visually clear format.\\r\\nMeasurement Instruments: In various measurement instruments such as multimeters and temperature controllers, the display can present numerical readings for user convenience.\\r\\nDigital Signage: While not as versatile as full-color LED displays, the 4 Digit 7-segment Display can still be used for basic digital signage applications, such as displaying room numbers, bus schedules, or simple messages.\\r\\nTechnical Specifications:\\r\\nNumber of Digits: 4\\r\\nSegment Type: Common cathode or common anode (depending on the specific model)\\r\\nDigit Height: Typically around 0.5 to 1 inch (12.7 to 25.4 mm)\\r\\nColor: Red, green, blue, or a combination of colors\\r\\nForward Voltage: Varies depending on the specific LED and color, typically around 1.8 to 2.2 volts per segment\\r\\nForward Current: Varies depending on the specific LED and brightness requirements, typically around 10 to 20 milliamps per segment\\r\\nPin Configuration: Commonly, each digit has 8 pins: 7 for segments (a-g) and one for common anode/cathode\\r\\nInterface: Can be directly interfaced with microcontrollers or other digital logic circuits using simple wiring and appropriate current limiting resistors.\"}\n",
            "i 29\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFF32E890>, 'prompt': 'You have been given an IoT kit component: Button for IoT kit. Give a description of the component having 3 sections as follows:\\n1) Description\\n2) Applications\\n3) Technical specifications', 'response': \"Description:\\r\\nThe Button for the IoT kit is a simple yet versatile component designed to provide input functionality in Internet of Things (IoT) projects. It typically consists of a push-button switch housed in a small enclosure, often with an ergonomic design for comfortable use. The button can be pressed to send a signal or trigger an action in an IoT system, making it an essential interface element for user interaction.\\r\\nApplications:\\r\\nThe Button component finds application in various IoT projects and scenarios, including but not limited to:\\r\\nHome automation: Controlling lights, fans, or other appliances with a press of a button.\\r\\nIndustrial monitoring: Initiating data collection or triggering alerts in industrial sensor networks.\\r\\nWearable technology: Interacting with wearable devices for tasks like fitness tracking or notifications.\\r\\nSecurity systems: Arming/disarming alarms or activating emergency alerts.\\r\\nSmart agriculture: Initiating watering cycles or activating environmental sensors in agricultural setups.\\r\\nHealthcare: Patient monitoring and emergency call systems.\\r\\nTechnical specifications:\\r\\nSwitch type: Normally open (NO) or normally closed (NC) depending on configuration.\\r\\nContact rating: Typically ranges from a few milliamps to several amps.\\r\\nOperating voltage: Usually compatible with standard voltages like 3.3V or 5V DC.\\r\\nOperating temperature: Typically -20°C to +70°C, suitable for indoor and outdoor use.\\r\\nInterface: May use digital or analog signaling depending on the microcontroller's input requirements.\\r\\nDurability: Rated for a certain number of actuations, typically in the range of thousands to millions of cycles.\\r\\nSize and form factor: Compact design suitable for integration into various IoT devices and prototypes.\\r\\nMounting options: Surface mount or through-hole mounting for easy installation on PCBs or enclosures.\\r\\nConnectivity: Wired connection to the microcontroller or wireless connectivity options like Bluetooth or Wi-Fi in advanced models.\"}\n",
            "i 30\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA6BE4A0>, 'prompt': 'You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: Thermistor. Give a description of the component having 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) Technical specifications', 'response': \"Description:\\r\\nA thermistor is a type of resistor whose resistance varies significantly with temperature. It's made from semiconductor material, typically ceramic or polymer, and is characterized by its negative temperature coefficient (NTC) or positive temperature coefficient (PTC). NTC thermistors decrease in resistance as temperature rises, while PTC thermistors increase in resistance with rising temperature. They come in various shapes and sizes, with some encapsulated in metal or glass for protection and durability.\\r\\nApplications:\\r\\nThermistors find applications in a wide range of industries and systems where temperature monitoring or control is essential. Some common applications include:\\r\\nTemperature sensing and control in HVAC (heating, ventilation, and air conditioning) systems.\\r\\nThermal protection in electrical circuits to prevent overheating.\\r\\nTemperature measurement in medical devices like thermometers and incubators.\\r\\nTemperature compensation in electronic circuits to stabilize performance.\\r\\nAutomotive applications such as engine temperature monitoring and climate control systems.\\r\\nIndustrial processes where precise temperature control is required, like in food processing or chemical manufacturing.\\r\\nTechnical Specifications:\\r\\nThe technical specifications of a thermistor can vary depending on its type, but some common parameters include:\\r\\nResistance at a specific temperature (usually 25°C), denoted as R25.\\r\\nTemperature coefficient, which indicates how much the resistance changes per degree Celsius of temperature change.\\r\\nOperating temperature range, which defines the temperature limits within which the thermistor can function effectively.\\r\\nAccuracy and tolerance, specifying the deviation from the actual temperature measurement.\\r\\nThermal time constant, representing how quickly the thermistor responds to changes in temperature.\\r\\nMaximum power rating, indicating the maximum amount of power the thermistor can dissipate without damage.\\r\\nPackaging type and size, which determine the physical form factor and mounting options of the thermistor.\"}\n",
            "i 31\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA4C2F50>, 'prompt': 'You have been given an IoT kit component: Snap on Connector Clip for 9V battery. Give a description of the component having 3 sections as follows:\\n1) Description\\n2) Applications\\n3) Technical specifications', 'response': 'Description:\\r\\nThe Snap-on Connector Clip for 9V battery is a small electrical connector designed to easily attach to a standard 9-volt battery. It typically consists of two parts: a clip with metal contacts that snap securely onto the terminals of the battery, and a wire lead or connector on the other end for easy integration into electronic circuits or devices. The clip ensures a reliable connection to the battery, allowing for convenient power supply without the need for soldering or permanent attachment.\\r\\nApplications:\\r\\nThis component finds applications in various electronic projects, prototyping, and IoT (Internet of Things) applications where a portable and easily replaceable power source is needed. Some common applications include:\\r\\nDIY electronics projects\\r\\nPrototyping of electronic circuits\\r\\nLow-power IoT devices and sensors\\r\\nEducational purposes for teaching electronics\\r\\nTemporary power supply for testing and troubleshooting electronic equipment\\r\\nTechnical Specifications:\\r\\nCompatible Battery Type: Standard 9-volt battery (6LR61, 6F22, PP3, etc.)\\r\\nMaterial: Plastic clip with metal contacts\\r\\nWire Lead Length: Typically ranges from a few inches to several feet, depending on the specific variant or manufacturer\\r\\nConnector Type: Various options available, including bare wire leads, barrel connectors, or pin headers for easy integration into circuits\\r\\nCurrent Rating: Typically rated for low to moderate current loads, suitable for powering small electronic devices and circuits\\r\\nMounting: Snap-on design for easy attachment and removal from the battery terminals\\r\\nDurability: Designed for repeated use and reliable electrical connections'}\n",
            "i 32\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFB839FF0>, 'prompt': 'You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: Joystick Module. Give a description of the component having 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) Technical specifications', 'response': 'Description:\\r\\nThe Joystick Module is a versatile input device commonly used in electronic projects and IoT applications. It consists of a small lever or stick that can be moved in multiple directions, typically along two axes (X and Y), and sometimes includes a push-button functionality. The module translates the movement and button presses into electrical signals that can be easily read by a microcontroller or other electronic circuitry.\\r\\nApplications:\\r\\nGaming: Joystick modules are frequently used in DIY gaming projects, allowing users to control characters or objects within a game environment.\\r\\nRobotics: They are used for controlling the movement of robotic arms, vehicles, or drones, providing precise and intuitive control.\\r\\nRemote Control Systems: Joysticks are ideal for remote control applications such as controlling remote-operated vehicles (ROVs), drones, or robotic platforms.\\r\\nHuman-Computer Interaction (HCI): They can be integrated into interfaces for physically impaired individuals, providing an accessible means of controlling electronic devices.\\r\\nIndustrial Control: Joysticks find applications in industrial machinery and equipment for controlling various parameters such as direction, speed, and positioning.\\r\\nTechnical Specifications:\\r\\nOperating Voltage: Typically operates within a range of 3.3V to 5V.\\r\\nAxes: Usually equipped with two analog axes for X and Y directions, providing smooth and continuous motion sensing.\\r\\nOutput: Analog output signals proportional to the position of the joystick along each axis.\\r\\nButton: Some joystick modules include a built-in push-button switch that can be activated by pressing down on the joystick.\\r\\nInterface: Connects to microcontrollers or other electronic circuits via analog or digital pins.\\r\\nDimensions: Compact size, typically around a few centimeters in length and width, making it suitable for integration into various projects.\\r\\nDurability: Designed for repeated use and manipulation, ensuring long-term reliability in different applications.\\r\\nMounting: Often equipped with mounting holes for easy installation onto a project enclosure or circuit board.\\r\\nCompatibility: Compatible with popular development platforms such as Arduino, Raspberry Pi, and other microcontrollers, facilitating easy integration into projects.'}\n",
            "i 33\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA4C2BC0>, 'prompt': 'You have been given an IoT kit component: Potentiometer 10K. Give a description of the component having 3 sections as follows:\\n1) Description\\n2) Applications\\n3) Technical specifications', 'response': 'Description:\\r\\nA potentiometer, often abbreviated as \"pot,\" is a type of variable resistor that allows you to adjust the resistance manually by turning a knob or slider. The potentiometer typically consists of a resistive element (usually made of carbon, cermet, or conductive plastic) with a movable contact called a wiper. By rotating the knob or slider, the wiper\\'s position changes along the resistive element, resulting in a change in resistance. Potentiometers are commonly used for controlling the volume on audio equipment, adjusting the brightness of displays, setting the speed of motors, and numerous other applications where variable resistance is required.\\r\\nApplications:\\r\\nVolume control in audio equipment such as amplifiers, radios, and mixing consoles.\\r\\nBrightness control in displays and lighting systems.\\r\\nTuning and calibration in electronic circuits.\\r\\nSpeed control in motors and servomechanisms.\\r\\nSensing applications such as temperature control, light intensity adjustment, and user interface control in electronic devices.\\r\\nTechnical Specifications:\\r\\nResistance: 10,000 ohms (10K ohms)\\r\\nTolerance: Typically ±10% or better (can vary based on specific model)\\r\\nPower Rating: Varies, but commonly ranges from 0.05 watts to 0.5 watts\\r\\nOperating Temperature Range: -40°C to +125°C (depending on the type)\\r\\nMechanical Life: Varies depending on quality and usage, but typically rated for thousands of rotations\\r\\nPhysical Dimensions: Varies widely depending on the form factor and design, but commonly available in cylindrical, square, or slider configurations with different shaft lengths and knob types.'}\n",
            "i 34\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFB839FF0>, 'prompt': 'You have been given an IoT kit component: Ultrasonic Sensor. Give a description of the component having 3 sections as follows:\\n1) Description\\n2) Applications\\n3) Technical specifications', 'response': 'Description:\\r\\nThe Ultrasonic Sensor is a type of sensor that uses sound waves to measure distances to objects. It typically consists of a transmitter and a receiver. The transmitter emits high-frequency sound waves, which bounce off nearby objects and return to the receiver. By calculating the time it takes for the sound waves to return, the sensor can determine the distance to the object.\\r\\nApplications:\\r\\nDistance measurement: Ultrasonic sensors are commonly used for measuring distances in various applications such as robotics, automation, and industrial control systems.\\r\\nObject detection and avoidance: They are used in robotics and autonomous vehicles to detect obstacles and avoid collisions.\\r\\nLiquid level detection: Ultrasonic sensors can be used to measure the level of liquids in tanks or containers by measuring the distance to the liquid surface.\\r\\nParking assistance systems: They are utilized in automotive applications to assist drivers in parking by detecting the distance to nearby objects.\\r\\nTechnical Specifications:\\r\\nOperating principle: Ultrasonic sound waves\\r\\nOperating frequency: Typically in the range of 20 kHz to 200 kHz\\r\\nDetection range: Varies depending on the model, but commonly ranges from a few centimeters to several meters\\r\\nOutput: Analog or digital signal depending on the model\\r\\nPower supply: Typically requires a DC power source, commonly 5V\\r\\nBeam angle: The angle of the ultrasonic beam emitted by the sensor, usually between 15 to 60 degrees\\r\\nAccuracy: Varies depending on factors such as environmental conditions and object properties, but typically high accuracy within specified range'}\n",
            "i 35\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA64BE20>, 'prompt': 'Can you make a short description about the part: 104 pF ceramic capacitor\\r\\n\\r\\nIt should be divided into 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) technical specification', 'response': 'Description:\\r\\nA 104 pF ceramic capacitor is a small electronic component designed to store and release electrical energy in circuits. It features a capacitance of 104 picofarads (pF), which means it can hold a charge of 104 trillionths of a farad. This capacitor typically has a ceramic composition, making it robust, stable, and suitable for various electronic applications.\\r\\nApplications:\\r\\nDue to its small size and stable performance, the 104 pF ceramic capacitor finds application in a wide range of electronic devices and circuits. It is commonly used in radio frequency (RF) circuits, oscillators, filters, and timing circuits. Additionally, it plays a crucial role in decoupling and bypassing applications, where it helps to stabilize voltage levels and reduce noise in power supply lines. Its versatility and reliability make it a fundamental component in modern electronic design across industries such as telecommunications, consumer electronics, and automotive systems.\\r\\nTechnical Specification:\\r\\nCapacitance: 104 picofarads (pF)\\r\\nComposition: Ceramic\\r\\nTolerance: Typically within ±5% or ±10%\\r\\nVoltage Rating: Varies depending on the specific capacitor, commonly ranging from a few volts to tens or hundreds of volts\\r\\nOperating Temperature Range: Typically -55°C to +125°C\\r\\nPackage Type: Available in various surface mount (SMD) and through-hole packages, such as 0402, 0603, 0805, etc.\\r\\nDielectric Material: Usually made of ceramic materials like barium titanate or similar high-permittivity ceramics, providing stable capacitance over a wide range of frequencies and temperatures.'}\n",
            "i 36\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA64BEB0>, 'prompt': 'You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: Prototype expansion module. Give a description of the component having 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) Technical specifications', 'response': 'Description:\\r\\nThe prototype expansion module is a versatile component designed to enhance the functionality and capabilities of IoT development kits. It serves as an interface between the development board and various sensors, actuators, and communication modules. Typically, it consists of a printed circuit board (PCB) with multiple headers, connectors, and peripheral components, providing users with a convenient platform for rapid prototyping and experimentation in IoT projects.\\r\\nApplications:\\r\\nSensor Integration: The expansion module enables seamless integration of various sensors such as temperature, humidity, motion, and proximity sensors, allowing developers to create IoT devices for environmental monitoring, smart homes, and industrial automation.\\r\\nActuator Control: It facilitates the connection of actuators like motors, relays, and servos, enabling the development of IoT applications for remote control, automation, and robotics.\\r\\nCommunication Expansion: With support for communication modules such as Wi-Fi, Bluetooth, LoRa, and GSM/GPRS, the expansion module enables IoT devices to connect to networks and communicate data to cloud platforms, smartphones, and other devices.\\r\\nPrototyping and Testing: The module serves as a platform for rapid prototyping, enabling developers to quickly test and validate IoT concepts and designs before finalizing the hardware and firmware for deployment.\\r\\nEducation and Learning: It is an excellent tool for educational purposes, allowing students and enthusiasts to gain hands-on experience in IoT hardware design, sensor integration, and wireless communication protocols.\\r\\nTechnical Specifications:\\r\\nConnectivity: Multiple headers and connectors for interfacing with microcontrollers, sensors, actuators, and communication modules.\\r\\nPower Supply: Voltage regulators and power distribution circuitry to provide stable power to connected components.\\r\\nInterface Protocols: Support for common interface protocols such as I2C, SPI, UART, and GPIO, enabling seamless communication between devices.\\r\\nForm Factor: Compact size compatible with standard IoT development boards, ensuring easy integration and compatibility with existing hardware setups.\\r\\nExpandability: Expansion headers or slots for further customization and integration of additional components as per project requirements.\\r\\nCompatibility: Designed to work with popular IoT development platforms such as Arduino, Raspberry Pi, ESP8266, and ESP32, ensuring broad compatibility and ease of use for developers.'}\n",
            "i 37\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA64BF40>, 'prompt': 'Can you make a short description about the part: Potentiometer 10K\\n\\nIt should be divided into 3 sections as follows:\\n1) Description\\n2) Applications\\n3) technical specification', 'response': 'Description:\\r\\nA potentiometer 10K is a variable resistor with a resistance value of 10,000 ohms (10K ohms). It consists of a resistive element with a movable contact called a wiper, which slides along the resistive track, allowing the user to adjust the resistance value. Potentiometers are commonly used for controlling electrical devices by varying resistance manually.\\r\\nApplications:\\r\\nPotentiometers find widespread use in various electronic circuits and devices. Some common applications include:\\r\\nVolume control in audio equipment such as amplifiers, radios, and speakers.\\r\\nBrightness control in displays and lighting systems.\\r\\nSpeed control in motor drives and robotics.\\r\\nTuning and calibration in measurement instruments like multimeters and oscilloscopes.\\r\\nSetting reference voltages in power supplies and voltage regulators.\\r\\nAdjustment of parameters in industrial control systems and machinery.\\r\\nTechnical Specifications:\\r\\nResistance: 10,000 ohms (10K ohms)\\r\\nTolerance: Potentiometers typically have a tolerance ranging from ±5% to ±20%, indicating the allowable deviation from the specified resistance value.\\r\\nPower Rating: The maximum power dissipation a potentiometer can handle without overheating. For a 10K potentiometer, the power rating might typically range from 0.1 to 1 watt, depending on its size and construction.\\r\\nMechanical Configuration: Potentiometers come in various mechanical configurations, including single-turn and multi-turn types, with different shaft lengths and types (e.g., rotary or slide).\\r\\nOperating Voltage: The maximum voltage that can be applied across the potentiometer without causing damage. This depends on the insulation properties of the resistive element and typically ranges from a few volts to several hundred volts.\\r\\nOperating Temperature: The temperature range within which the potentiometer can operate reliably without significant drift in resistance or mechanical failure. Typical operating temperatures range from -55°C to 125°C, but this can vary depending on the specific potentiometer model and construction.'}\n",
            "i 38\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFF30EB60>, 'prompt': 'You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: ELEGOO Power supply module. Give a description of the component having 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) Technical specifications', 'response': 'Description:\\r\\nThe ELEGOO Power Supply Module is a compact and versatile power management component designed for IoT (Internet of Things) projects and other electronics applications. It serves as a reliable source of power, offering regulated voltage output to ensure stable operation of connected devices. The module typically includes input and output terminals, along with control features for adjusting voltage levels as per project requirements. With its small form factor and ease of integration, this module is suitable for various DIY electronics projects, prototyping, and educational purposes.\\r\\nApplications:\\r\\nIoT Devices: The power supply module can be used to power various IoT devices such as sensors, actuators, and microcontrollers, ensuring reliable operation and longevity.\\r\\nEmbedded Systems: It is suitable for powering embedded systems, development boards, and single-board computers like Arduino, Raspberry Pi, and ESP8266/ESP32.\\r\\nRobotics: In robotics projects, the module can provide stable power to motor drivers, microcontrollers, and other electronic components, contributing to efficient and precise robotic movements.\\r\\nHome Automation: It can be integrated into home automation systems to power smart devices, sensors, and communication modules, facilitating remote monitoring and control of appliances.\\r\\nEducational Projects: The module is ideal for educational purposes, allowing students and hobbyists to learn about power management concepts and electronics prototyping in a hands-on manner.\\r\\nTechnical Specifications:\\r\\nInput Voltage: Typically supports a wide range of input voltages, such as 5V to 12V DC.\\r\\nOutput Voltage: Adjustable output voltage, commonly ranging from 1.25V to 12V DC, depending on the model and configuration.\\r\\nOutput Current: Provides a certain maximum output current, often in the range of 0.5A to 3A, suitable for powering various electronic components and devices.\\r\\nRegulation: Built-in voltage regulation circuitry ensures stable output voltage, with low ripple and noise.\\r\\nProtections: May include overcurrent protection, overvoltage protection, and thermal shutdown features to safeguard connected devices and the module itself from damage.\\r\\nForm Factor: Compact design with standard pin headers or screw terminals for easy integration into electronic circuits and projects.\\r\\nControl: Some models may offer voltage adjustment via potentiometer or digital control interfaces, allowing flexibility in voltage regulation.'}\n",
            "i 39\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA64BEB0>, 'prompt': 'You have been given an IoT kit component: ULN 2003 Stepper Motor Driver Module. Give a description of the component having 3 sections as follows:\\n1) Description\\n2) Applications\\n3) Technical specifications', 'response': 'Description:\\r\\nThe ULN2003 Stepper Motor Driver Module is a small electronic component designed to drive stepper motors efficiently. It utilizes the ULN2003 integrated circuit, which is a high-voltage, high-current Darlington transistor array. This module provides an easy and convenient way to control stepper motors using microcontrollers or other control systems. It typically includes a ULN2003 IC, input pins for controlling the motor, output pins for connecting to the stepper motor, and additional circuitry for protection and stability.\\r\\nApplications:\\r\\nRobotics: The ULN2003 Stepper Motor Driver Module is commonly used in robotic applications for precise control of stepper motors, allowing robots to move accurately and perform various tasks.\\r\\n3D Printing: Stepper motors are often employed in 3D printers for controlling the movement of the print head and the build platform. The ULN2003 module can be used to drive these motors, enabling precise positioning and smooth operation.\\r\\nCNC Machines: Computer Numerical Control (CNC) machines rely on stepper motors to move the cutting tools or workpieces along predefined paths. The ULN2003 module can drive these motors, ensuring precise movement and accurate machining.\\r\\nAutomation Systems: Stepper motors are widely used in automation systems for tasks such as conveyor belt control, positioning mechanisms, and robotic arms. The ULN2003 module facilitates the integration of stepper motors into such systems, allowing for efficient control and operation.\\r\\nTechnical Specifications:\\r\\nOperating Voltage: Typically compatible with 5V DC, but may vary depending on the specific module.\\r\\nMaximum Output Current: Each output channel of the ULN2003 IC can handle up to 500mA continuous current.\\r\\nNumber of Output Channels: The ULN2003 IC integrated into the module typically provides seven output channels, allowing for the control of up to seven-wire stepper motors.\\r\\nControl Interface: Typically includes input pins for controlling the direction and steps of the stepper motor, allowing for easy integration with microcontrollers or control systems.\\r\\nDimensions: Compact size, typically designed to fit into standard breadboard layouts or mounting on other circuit boards.'}\n",
            "i 40\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA4C2CE0>, 'prompt': 'You have been given an IoT kit component: Sound Sensor Module. Give a description of the component having 3 sections as follows:\\n1) Description\\n2) Applications\\n3) Technical specifications', 'response': \"Description:\\r\\nThe Sound Sensor Module, also known as a sound detection sensor or microphone sensor, is a small electronic device designed to detect sound waves in its vicinity. It typically consists of a built-in microphone, amplifier circuitry, and analog or digital output pins. When sound waves reach the microphone, they cause vibrations that are converted into electrical signals. These signals are then processed by the amplifier circuitry and output as voltage changes or digital signals, depending on the module's configuration.\\r\\nApplications:\\r\\nSecurity Systems: Sound sensors can be used in security systems to detect unusual sounds, such as breaking glass or loud noises, and trigger alarms or notifications.\\r\\nSmart Home Automation: They can be integrated into smart home systems to activate or control devices based on voice commands or specific sounds, like turning on lights when someone enters a room.\\r\\nIndustrial Monitoring: In industrial environments, sound sensors can monitor machinery for abnormal sounds indicating malfunctions or maintenance needs.\\r\\nNoise Pollution Monitoring: Sound sensors can be deployed in urban areas to monitor noise levels and identify sources of noise pollution.\\r\\nGesture Recognition: In combination with other sensors, sound sensors can contribute to gesture recognition systems by detecting claps, taps, or other auditory cues.\\r\\nTechnical Specifications:\\r\\nOperating Voltage: Typically operates within a range of 3.3V to 5V.\\r\\nOutput Type: Analog or digital output, depending on the module's configuration.\\r\\nDetection Range: Varies depending on the sensitivity and design of the microphone, but typically can detect sounds within a few meters.\\r\\nFrequency Response: The frequency range over which the sensor can detect sound waves, usually from around 100 Hz to 10 kHz.\\r\\nSensitivity: Adjustable sensitivity levels to detect sound at different thresholds.\\r\\nInterface: Usually equipped with standard interface pins for easy connection to microcontrollers or other electronic devices.\\r\\nDimensions: Compact size for easy integration into various projects.\\r\\nOperating Temperature: Typically operates within a temperature range of -10°C to 50°C, suitable for indoor use in most environments.\"}\n",
            "i 41\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFF32E890>, 'prompt': 'Can you make a short description about the part: DHT11 temperature and humidity module\\r\\n\\r\\nIt should be divided into 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) technical specification', 'response': 'Description:\\r\\nThe DHT11 temperature and humidity module is a sensor device designed to accurately measure both temperature and humidity levels in the surrounding environment. It utilizes a digital sensor to provide precise readings, making it ideal for various applications where monitoring environmental conditions is essential.\\r\\nApplications:\\r\\nThis module finds applications in a wide range of fields including weather monitoring, home automation, HVAC (Heating, Ventilation, and Air Conditioning) systems, agricultural monitoring, and industrial automation. It is commonly used in projects such as weather stations, greenhouse monitoring systems, and smart thermostats to ensure optimal conditions are maintained.\\r\\nTechnical Specifications:\\r\\nTemperature Range: 0°C to 50°C (32°F to 122°F)\\r\\nHumidity Range: 20% to 90% RH\\r\\nAccuracy:\\r\\nTemperature: ±2°C (±0.5°C typical)\\r\\nHumidity: ±5% RH\\r\\nOperating Voltage: 3.3V to 5V DC\\r\\nOutput: Digital signal\\r\\nResponse Time: 2 seconds (typical)\\r\\nDimensions: Approximately 15.5mm x 12mm x 5.5mm\\r\\nInterface: Single-wire digital interface\\r\\nLow power consumption: Average current consumption is less than 1mA\\r\\nCalibration: Factory calibrated'}\n",
            "i 42\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA4C29B0>, 'prompt': 'You have been given an IoT kit component: Joystick Module. Give a description of the component having 3 sections as follows:\\n1) Description\\n2) Applications\\n3) Technical specifications', 'response': 'Description:\\r\\nThe Joystick Module is a compact input device commonly used in electronic projects and IoT (Internet of Things) applications. It consists of a small lever or knob that can be moved in various directions to provide analog input signals. Typically, it contains two potentiometers (one for the X-axis and one for the Y-axis) and a tactile switch. The potentiometers measure the position of the joystick along each axis, while the tactile switch can be pressed down to provide a digital signal.\\r\\nApplications:\\r\\nRobotics: Joystick modules are frequently used in robotics projects to control the movement of robotic arms or vehicles.\\r\\nGaming: They can be integrated into DIY game controllers for gaming enthusiasts.\\r\\nRemote control systems: Joysticks are used in remote-controlled devices such as drones or remote-controlled cars.\\r\\nUser interfaces: They can serve as intuitive input devices for various electronic gadgets and interfaces, offering a more tactile and interactive experience for users.\\r\\nTechnical specifications:\\r\\nOperating voltage: Typically 3.3V or 5V, compatible with most microcontrollers.\\r\\nOutput: Analog voltage signals proportional to the position of the joystick along the X and Y axes.\\r\\nDigital output: A tactile switch that provides a digital signal when pressed.\\r\\nInterface: Usually equipped with male header pins for easy connection to a breadboard or microcontroller development board.\\r\\nDimensions: Compact and lightweight, suitable for integration into various electronic projects.\\r\\nCompatibility: Can be easily interfaced with popular microcontrollers such as Arduino, Raspberry Pi, and others.\\r\\nDurability: Built with durable materials to withstand repeated usage and manipulation.'}\n",
            "i 43\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFF32E890>, 'prompt': 'You have been given an IoT kit component: Prototype expansion module. Give a description of the component having 3 sections as follows:\\n1) Description\\n2) Applications\\n3) Technical specifications', 'response': 'Description:\\r\\nThe Prototype Expansion Module is a versatile component designed to enhance the capabilities of IoT (Internet of Things) development kits. It typically consists of a modular board with various slots, connectors, and interfaces, allowing users to easily prototype and expand the functionality of their IoT projects. The module often features a breadboard area for solderless prototyping, along with headers or connectors for interfacing with microcontrollers, sensors, actuators, and other electronic components. It provides a convenient platform for experimenting with different hardware configurations and implementing custom IoT solutions.\\r\\nApplications:\\r\\nThe Prototype Expansion Module finds applications in a wide range of IoT projects, including but not limited to:\\r\\nHome automation: Building smart devices for controlling lights, appliances, and security systems.\\r\\nEnvironmental monitoring: Developing sensors for measuring temperature, humidity, air quality, and other parameters.\\r\\nIndustrial automation: Creating systems for monitoring and controlling machinery, processes, and infrastructure.\\r\\nWearable technology: Prototyping wearable devices for health monitoring, fitness tracking, and personal safety.\\r\\nSmart agriculture: Designing solutions for monitoring soil moisture, temperature, and crop conditions in agricultural settings.\\r\\nEducational purposes: Teaching electronics, programming, and IoT concepts through hands-on experimentation and project-based learning.\\r\\nTechnical Specifications:\\r\\nBreadboard area: Typically includes a solderless breadboard for prototyping circuits without the need for soldering.\\r\\nExpansion slots: Provides slots or headers for connecting additional modules, sensors, and actuators.\\r\\nInterface connectors: Offers standard interfaces such as GPIO (General Purpose Input/Output), I2C, SPI, UART, and analog inputs/outputs for interfacing with microcontrollers and external devices.\\r\\nPower supply: Supports various power input options, including USB, battery, or external power adapters.\\r\\nCompatibility: Designed to work seamlessly with popular IoT development platforms and microcontroller boards such as Arduino, Raspberry Pi, ESP32, and others.\\r\\nDimensions: Compact size for easy integration into IoT projects and experimentation setups.\\r\\nMaterial: Typically constructed using high-quality materials for durability and reliability in prototyping environments.\\r\\nDocumentation and resources: Comes with comprehensive documentation, tutorials, and sample projects to assist users in getting started and exploring the full potential of the module.'}\n",
            "i 44\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA4C1D20>, 'prompt': 'You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: ULN 2003 Stepper Motor Driver Module. Give a description of the component having 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) Technical specifications', 'response': 'Description:\\r\\nThe ULN2003 Stepper Motor Driver Module is a versatile integrated circuit (IC) module commonly used to control bipolar stepper motors. It is based on the ULN2003A Darlington transistor array, which consists of seven high-voltage, high-current Darlington transistor pairs. These pairs are capable of sinking up to 500 mA per channel and can handle voltages of up to 50V. The module typically includes the necessary circuitry for motor control, such as current limiting resistors and protection diodes.\\r\\nApplications:\\r\\nRobotics: The ULN2003 Stepper Motor Driver Module finds extensive use in robotics applications for controlling the motion of robotic arms, grippers, and other movable components.\\r\\nCNC Machines: In Computer Numerical Control (CNC) machines, stepper motors are commonly used for precise positioning of cutting tools, and the ULN2003 module can be employed to drive these motors.\\r\\n3D Printers: Stepper motors are crucial components in 3D printers for controlling the movement of the print head and build platform. The ULN2003 module can be utilized to drive these motors in such applications.\\r\\nAutomated Systems: Various automated systems, such as automated doors, conveyor belts, and surveillance cameras, rely on stepper motors for controlled movement, and the ULN2003 module can be integrated into their control circuits.\\r\\nDIY Projects: Hobbyists and electronics enthusiasts often use the ULN2003 module in DIY projects involving motor control, such as automated plant watering systems, camera sliders, and motion-controlled vehicles.\\r\\nTechnical Specifications:\\r\\nInput Voltage: Typically compatible with a wide range of input voltages, commonly ranging from 5V to 12V DC.\\r\\nOutput Voltage: Can drive stepper motors with voltages of up to 50V.\\r\\nMaximum Output Current: Each Darlington pair can sink up to 500 mA of current.\\r\\nNumber of Channels: The module usually includes seven channels, corresponding to the seven Darlington transistor pairs.\\r\\nControl Interface: Typically features a simple control interface, such as a 4-wire connection for stepper motor control (4 inputs for motor winding and 1 input for common terminal).\\r\\nBuilt-in Protection: Includes built-in protection diodes for suppressing voltage spikes that may occur when driving inductive loads such as stepper motors.\\r\\nCompact Size: The module is usually compact in size, making it easy to integrate into various electronic projects and devices.'}\n",
            "i 45\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA64BEB0>, 'prompt': 'You have been given an IoT kit component: IR Receiver module. Give a description of the component having 3 sections as follows:\\n1) Description\\n2) Applications\\n3) Technical specifications', 'response': 'Description:\\r\\nThe IR (Infrared) Receiver module is a component used in IoT (Internet of Things) projects to detect and receive infrared signals from remote controls or other IR-transmitting devices. It typically consists of a photodiode, amplifier, and demodulator circuitry enclosed in a small, compact package. When exposed to infrared light, the photodiode generates a tiny current proportional to the intensity of the received IR radiation. The amplifier then boosts this weak signal for further processing, while the demodulator extracts the digital information encoded in the IR signal.\\r\\nApplications:\\r\\nThe IR Receiver module finds applications in various electronic devices and IoT projects, including:\\r\\nRemote control systems: Used in TVs, DVD players, air conditioners, and other consumer electronics for remote operation.\\r\\nHome automation: Integrated into smart home systems to control lighting, appliances, and other devices remotely.\\r\\nRobotics: Employed in robotic systems for receiving commands and instructions via IR remote controls.\\r\\nSecurity systems: Utilized in IR-based intrusion detection systems and surveillance cameras for remote monitoring and control.\\r\\nEntertainment systems: Integrated into gaming consoles and audio/video equipment for remote control functionality.\\r\\nTechnical Specifications:\\r\\nOperating wavelength: Typically around 940nm.\\r\\nOperating voltage: Typically 3.3V to 5V DC.\\r\\nDetection angle: Varies based on the specific module but commonly around 90 degrees.\\r\\nOutput signal: Digital (TTL or CMOS compatible) or analog (PWM or demodulated signal).\\r\\nOperating temperature: Typically -20°C to +85°C.\\r\\nDimensions: Small form factor, often mounted on a breakout board for easy integration into circuits.\\r\\nSensitivity: Varies depending on the module and manufacturer, with some modules offering adjustable sensitivity settings.\\r\\nCompatibility: Compatible with various microcontrollers and development platforms like Arduino, Raspberry Pi, and ESP8266 for easy integration into IoT projects.'}\n",
            "i 46\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA4C1D20>, 'prompt': 'Can you make a short description about the part: IR Receiver module\\r\\n\\r\\nIt should be divided into 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) technical specification', 'response': \"Description:\\r\\nAn IR (Infrared) receiver module is a small electronic component that detects infrared signals transmitted from a remote control or another IR source. It typically consists of a photodiode or phototransistor that converts infrared light into an electrical signal. This module is commonly used in consumer electronics for remote control functionality, allowing devices like TVs, air conditioners, and media players to receive commands wirelessly.\\r\\nApplications:\\r\\nIR receiver modules find widespread use in various applications, primarily in devices requiring remote control capabilities. Some common applications include:\\r\\nHome entertainment systems: Used in televisions, audio systems, and DVD/Blu-ray players for remote operation.\\r\\nHome automation: Integrated into smart home devices for controlling lights, thermostats, and other appliances remotely.\\r\\nAutomotive: Incorporated into car stereo systems and remote keyless entry systems for vehicle control.\\r\\nIndustrial automation: Employed in machinery and equipment for remote monitoring and control purposes.\\r\\nConsumer electronics: Found in gaming consoles, set-top boxes, and digital cameras for remote functionality.\\r\\nTechnical Specifications:\\r\\nOperating wavelength: Typically around 940 nanometers (nm), although variations exist.\\r\\nSensitivity: The module's ability to detect IR signals at a specified distance.\\r\\nSupply voltage: Voltage required for proper operation, usually ranging from 3V to 5V.\\r\\nOutput signal: Typically a digital signal (e.g., TTL) or analog voltage proportional to the intensity of received IR light.\\r\\nReception angle: The range over which the module can detect IR signals, usually measured in degrees.\\r\\nOperating temperature: Range within which the module operates reliably, often between -20°C to 85°C.\\r\\nResponse time: The time taken by the module to detect and process incoming IR signals.\\r\\nDimensions: Physical size and form factor of the module, which can vary based on the manufacturer and model.\"}\n",
            "i 47\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA6BE4A0>, 'prompt': 'Can you make a short description about the part: ELEGOO Power supply module\\r\\n\\r\\nIt should be divided into 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) technical specification', 'response': 'Description:\\r\\nThe ELEGOO Power Supply Module is a compact and efficient power supply solution designed to deliver stable voltage output for various electronic projects. With its sleek design and robust construction, this module provides reliable power for your circuits, ensuring consistent performance.\\r\\nApplications:\\r\\nArduino Projects: Ideal for powering Arduino boards and peripherals, ensuring uninterrupted operation.\\r\\nDIY Electronics: Suitable for a wide range of DIY electronics projects, from robotics to home automation systems.\\r\\nPrototyping: Essential for prototyping circuits and testing electronic components, offering a stable power source for accurate measurements.\\r\\nEducational Use: Perfect for educational purposes in schools, colleges, and maker spaces, enabling students to learn about electronics and circuitry.\\r\\nTechnical Specification:\\r\\nInput Voltage: AC 100-240V, 50/60Hz\\r\\nOutput Voltage: DC 5V, 3.3V\\r\\nOutput Current: 700mA (5V), 500mA (3.3V)\\r\\nEfficiency: ≥80%\\r\\nProtection: Overcurrent, Overvoltage, Short Circuit\\r\\nDimensions: 52mm x 32mm x 18mm\\r\\nWeight: 25g (approximately)\\r\\nInterface: Terminal Blocks for easy connection\\r\\nOperating Temperature: -20°C to 60°C\\r\\nCertification: CE, FCC\\r\\nFeatures: Compact Size, High Efficiency, Stable Output Voltage, Built-in Protection Circuits.\\r'}\n",
            "i 48\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFF1DEEF0>, 'prompt': 'Can you make a short description about the part: Tilt Ball Switch\\r\\n\\r\\nIt should be divided into 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) technical specification', 'response': 'Description:\\r\\nA Tilt Ball Switch is a simple electronic sensor that detects orientation changes by the movement of a small metal ball within a conductive housing. When the sensor is tilted, the ball makes or breaks electrical contact, allowing it to function as a switch. This mechanism makes it particularly suitable for detecting changes in orientation or inclination.\\r\\nApplications:\\r\\nTilt Ball Switches find applications in various industries and products where detecting motion or orientation is essential. They are commonly used in automotive safety systems to trigger airbag deployment upon vehicle collision detection. Additionally, they are employed in consumer electronics, such as gaming controllers and handheld devices, to control functions based on device orientation. Moreover, they are utilized in industrial equipment for tilt sensing and machinery safety interlocks.\\r\\nTechnical Specification:\\r\\nTilt Ball Switches come in various configurations, with different contact ratings, sensitivities, and mounting options. Typical specifications include the maximum tilt angle for reliable operation, the maximum voltage and current ratings, response time, and durability ratings for the number of cycles the switch can endure. Additionally, some variants may offer options for sealed housings for use in harsh environments or with specific resistance to vibration and shock.'}\n",
            "i 49\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA4C28F0>, 'prompt': 'You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: USB A to Micro B. Give a description of the component having 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) Technical specifications', 'response': \"Description:\\r\\nThe USB A to Micro B cable is a standard connectivity solution used in various IoT (Internet of Things) and hardware projects. It features a USB Type-A connector on one end and a Micro USB Type-B connector on the other. The USB Type-A connector is typically found on computers, power adapters, and other host devices, while the Micro USB Type-B connector is commonly used for connecting to peripherals such as smartphones, tablets, and microcontrollers. This cable facilitates data transfer, power delivery, and communication between devices, making it an essential component in many IoT setups.\\r\\nApplications:\\r\\nThe USB A to Micro B cable finds numerous applications across IoT and hardware projects, including:\\r\\nMicrocontroller Programming: It is commonly used to connect microcontrollers such as Arduino, Raspberry Pi, and ESP8266 to a computer for programming and debugging purposes.\\r\\nPowering IoT Devices: Many IoT devices, sensors, and development boards utilize Micro USB for power input, and this cable enables them to be powered from a USB port or a USB power adapter.\\r\\nData Transfer: It facilitates data transfer between IoT devices and host systems, allowing for the exchange of sensor data, firmware updates, and configuration settings.\\r\\nCharging Smart Devices: The cable can be used to charge smartphones, tablets, and other portable electronics from a USB power source, making it useful in both consumer and industrial applications.\\r\\nTechnical Specifications:\\r\\nConnectors: USB Type-A male to Micro USB Type-B male\\r\\nCompatibility: Compatible with USB 2.0 and USB 3.0 standards\\r\\nLength: Available in various lengths ranging from 1 to 3 meters\\r\\nConductors: Typically features four conductors: two for power (VCC and GND) and two for data (D+ and D-)\\r\\nMaterials: Constructed with durable materials for long-lasting performance and reliability\\r\\nData Transfer Rate: Supports data transfer speeds of up to 480 Mbps (USB 2.0) or 5 Gbps (USB 3.0), depending on the host device's capabilities\\r\\nPower Delivery: Capable of delivering up to 2.5 watts of power (5 volts at 0.5 amps) for charging and powering devices\\r\\nShielding: Equipped with shielding to minimize electromagnetic interference and ensure signal integrity\\r\\nCompliance: Conforms to USB specifications and standards for interoperability and compatibility with a wide range of devices.\"}\n",
            "i 50\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFF32E890>, 'prompt': 'Can you make a short description about the part: USB B to USB A Cable\\n\\nIt should be divided into 3 sections as follows:\\n1) Description\\n2) Applications\\n3) technical specification', 'response': 'Description:\\nThe USB B to USB A cable is a versatile connectivity solution designed to link devices with different USB interfaces. Featuring a USB B connector on one end and a USB A connector on the other, this cable facilitates the seamless transfer of data and power between various devices. Its sturdy construction ensures reliable performance and durability.\\nApplications:\\nThis cable finds wide applications in the realm of technology and electronics, serving as a bridge between devices such as printers, scanners, external hard drives, and computers. It enables users to connect peripherals equipped with USB B ports to host devices with USB A ports, facilitating data transfer, peripheral operation, and power delivery in diverse settings such as offices, homes, and educational institutions.\\nTechnical Specification:\\nConnector Type: USB B Male to USB A Male\\nCable Length: Available in various lengths, typically ranging from 1 to 3 meters\\nData Transfer Speed: Supports USB 2.0 or USB 3.0 standards, depending on the specific cable model\\nCompatibility: Compatible with a wide range of devices equipped with USB ports, including computers, printers, scanners, external hard drives, and more\\nConstruction: Constructed with high-quality materials for enhanced durability and reliable performance\\nPower Delivery: Capable of delivering power to compatible devices, enabling charging and operation simultaneously'}\n",
            "i 51\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA4C2DD0>, 'prompt': 'Can you make a short description about the part: 9V 1A adapter\\n\\nIt should be divided into 3 sections as follows:\\n1) Description\\n2) Applications\\n3) technical specification', 'response': \"Description:\\r\\nA 9V 1A adapter is a power supply unit designed to deliver a stable electrical output of 9 volts with a current capacity of 1 ampere. It typically consists of a plug-in adapter with a DC output connector suitable for various electronic devices.\\r\\nApplications:\\r\\nThis type of adapter finds wide applications in powering low to moderately power-consuming electronic devices such as small appliances, LED lighting systems, routers, modems, CCTV cameras, portable speakers, and similar gadgets. It's commonly used in household and commercial settings where a reliable power source is required for continuous operation of such devices.\\r\\nTechnical Specifications:\\r\\nVoltage Output: 9 volts\\r\\nCurrent Output: 1 ampere (1000 milliamps)\\r\\nInput Voltage: AC 100-240V, 50/60Hz (universal voltage)\\r\\nOutput Connector: Typically barrel-type connectors, commonly available in various sizes such as 5.5mm x 2.1mm or 5.5mm x 2.5mm\\r\\nPolarity: Center positive (where the inner contact of the connector is positive while the outer sleeve is negative)\\r\\nEfficiency: Typically high efficiency, often exceeding 80%\\r\\nProtection Features: May include overcurrent protection, overvoltage protection, short-circuit protection, and thermal protection to safeguard both the adapter and connected devices from damage due to electrical faults or overheating.\\r\\nSize and Form Factor: Compact and lightweight design, suitable for portability and space-saving installations.\\r\\nCompliance: Compliant with relevant safety and quality standards such as CE, FCC, RoHS, and UL, ensuring safe and reliable operation.\"}\n",
            "i 52\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA64BF40>, 'prompt': 'You have been given an IoT kit component: DHT11 temperature and humidity module. Give a description of the component having 3 sections as follows:\\n1) Description\\n2) Applications\\n3) Technical specifications', 'response': \"Description:\\r\\nThe DHT11 is a basic digital temperature and humidity sensor. It consists of a capacitive humidity sensor and a thermistor to measure the surrounding air's relative humidity and temperature, respectively. The module has a small form factor and typically comes with three pins for easy integration into projects. It communicates using a single-wire digital protocol, making it easy to interface with microcontrollers and IoT devices.\\r\\nApplications:\\r\\nEnvironmental monitoring: The DHT11 is commonly used in weather stations, home automation systems, and agricultural applications to monitor temperature and humidity levels.\\r\\nHVAC systems: It can be integrated into heating, ventilation, and air conditioning systems for climate control and energy efficiency.\\r\\nIndoor comfort monitoring: In homes and offices, the DHT11 can be used to monitor indoor climate conditions to ensure optimal comfort for occupants.\\r\\nFood storage: It can be employed to monitor temperature and humidity levels in food storage areas to prevent spoilage and ensure food safety.\\r\\nTechnical Specifications:\\r\\nOperating Voltage: 3.3V - 5V DC\\r\\nTemperature Measurement Range: 0°C to 50°C\\r\\nTemperature Measurement Accuracy: ±2°C\\r\\nHumidity Measurement Range: 20% RH to 90% RH\\r\\nHumidity Measurement Accuracy: ±5% RH\\r\\nResolution: Temperature: 1°C, Humidity: 1% RH\\r\\nInterface: Single-wire digital interface (one data line)\\r\\nSampling Rate: 1 Hz (once every second)\\r\\nDimensions: Typically around 15mm x 12mm x 5mm\\r\\nOperating Temperature Range: 0°C to 50°C\\r\\nStorage Temperature Range: -20°C to 70°C\"}\n",
            "i 53\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA4C1B40>, 'prompt': 'You have been given an IoT kit component: USB B to USB A Cable. Give a description of the component having 3 sections as follows:\\n1) Description\\n2) Applications\\n3) Technical specifications', 'response': 'Description:\\r\\nThe USB B to USB A Cable is a type of data cable commonly used in electronics and computer peripherals. It features a USB Type B connector on one end and a USB Type A connector on the other end. The Type B connector is typically square-shaped with beveled corners, while the Type A connector is rectangular with a flat face and slightly beveled edges. The cable is designed to facilitate the transfer of data and power between devices equipped with USB ports.\\r\\nApplications:\\r\\nThis cable is widely used in various applications, including:\\r\\nConnecting printers, scanners, and external hard drives to computers or laptops.\\r\\nLinking MIDI controllers, audio interfaces, and other music equipment to computers for recording or playback.\\r\\nPowering and programming microcontroller boards such as Arduino or Raspberry Pi.\\r\\nConnecting digital cameras, smartphones, and tablets to computers for data transfer or charging.\\r\\nTechnical Specifications:\\r\\nConnector Type: USB Type B Male to USB Type A Male\\r\\nCable Length: Typically available in various lengths, such as 1 meter, 2 meters, or 3 meters.\\r\\nData Transfer Speed: Supports USB 2.0 or USB 3.0 standards, with respective maximum data transfer rates of 480 Mbps for USB 2.0 and up to 5 Gbps for USB 3.0.\\r\\nCompatibility: Compatible with devices equipped with USB Type A or USB Type B ports, including computers, laptops, printers, scanners, external hard drives, MIDI controllers, microcontroller boards, digital cameras, smartphones, and tablets.\\r\\nCable Construction: Typically consists of insulated copper conductors for data and power transmission, surrounded by a protective outer jacket made of PVC or similar material for durability and flexibility.\\r\\nShielding: May feature shielding to reduce electromagnetic interference (EMI) and ensure reliable data transmission.\\r\\nDurability: Designed to withstand frequent plugging and unplugging, with reinforced connectors and strain relief to prevent cable damage.\\r\\nCompliance: Compliant with USB specifications set by the USB Implementers Forum (USB-IF) for reliable performance and interoperability.'}\n",
            "i 54\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA64BE20>, 'prompt': 'You have been given an IoT kit component: Stepper Motor. Give a description of the component having 3 sections as follows:\\n1) Description\\n2) Applications\\n3) Technical specifications', 'response': \"Description:\\r\\nA stepper motor is a type of brushless DC electric motor that divides a full rotation into a number of equal steps. Unlike a conventional DC motor, which rotates continuously when voltage is applied to its terminals, a stepper motor rotates in discrete steps. This characteristic makes stepper motors ideal for precise motion control applications.\\r\\nApplications:\\r\\nStepper motors find applications in various fields due to their precise control and ability to move in discrete increments. Some common applications include:\\r\\nCNC machines: Stepper motors are widely used in computer numerical control (CNC) machines for controlling the movement of cutting tools.\\r\\n3D printers: Stepper motors are used to precisely control the movement of the print head and build platform in 3D printers.\\r\\nRobotics: Stepper motors are utilized in robotic systems for controlling the movement of robotic arms, grippers, and other actuators.\\r\\nAutomation systems: They are employed in automated systems for tasks such as conveyor belt control, sorting mechanisms, and packaging machines.\\r\\nCamera platforms: Stepper motors are used in camera platforms for pan and tilt movements, allowing for precise positioning of the camera.\\r\\nTechnical Specifications:\\r\\nStep Angle: The angle through which the motor rotates for each step. Common step angles include 1.8° (200 steps per revolution) and 0.9° (400 steps per revolution).\\r\\nHolding Torque: The maximum torque that the motor can exert while stationary and energized. It determines the motor's ability to hold a load in position without slipping.\\r\\nDrive Voltage: The voltage required to operate the motor. This voltage varies depending on the specific stepper motor model and can range from a few volts to several tens of volts.\\r\\nCurrent Rating: The maximum current that the motor windings can handle without overheating. It is typically specified in amps (A).\\r\\nShaft Diameter: The diameter of the motor shaft, which determines compatibility with various coupling and mounting options.\\r\\nSize: Stepper motors are available in various sizes, ranging from small NEMA 8 motors used in miniature applications to large NEMA 34 motors for industrial machinery.\"}\n",
            "i 55\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA4C2950>, 'prompt': 'You have been given an IoT kit component: Membrane Switch Module. Give a description of the component having 3 sections as follows:\\n1) Description\\n2) Applications\\n3) Technical specifications', 'response': 'Description:\\r\\nA membrane switch module is a type of electrical switch consisting of a thin, flexible membrane with electrical contacts printed on its surface. It typically comprises multiple layers, including a graphic overlay layer, a spacer layer, and a circuit layer. When pressure is applied to the surface of the membrane, it deforms slightly, allowing the contacts to connect and complete an electrical circuit. Membrane switches are often used as user interface components in electronic devices due to their durability, compact design, and customizable graphic overlays.\\r\\nApplications:\\r\\nConsumer Electronics: Membrane switches are commonly found in products like remote controls, calculators, and kitchen appliances.\\r\\nIndustrial Control Panels: They are used in industrial control panels and machinery for their resistance to dust, water, and harsh environments.\\r\\nMedical Devices: Membrane switches are utilized in medical equipment such as patient monitoring devices and diagnostic instruments.\\r\\nAutomotive: They can be found in car dashboards, control panels, and infotainment systems.\\r\\nAerospace: Membrane switches are used in aircraft instrumentation and control systems due to their reliability and lightweight design.\\r\\nTechnical Specifications:\\r\\nMaterial: Typically constructed from layers of polyester, polycarbonate, or similar flexible materials.\\r\\nThickness: Varies depending on the design and application, but typically ranges from 0.1 mm to 0.5 mm.\\r\\nElectrical Rating: Voltage and current ratings depend on the specific design and intended application of the membrane switch.\\r\\nActuation Force: The amount of force required to activate the switch typically ranges from 50 grams to 500 grams.\\r\\nLifecycle: Membrane switches are known for their durability and can withstand millions of actuations under normal operating conditions.\\r\\nEnvironmental Protection: Many membrane switches offer resistance to moisture, chemicals, and temperature extremes, making them suitable for use in harsh environments.\\r\\nCustomization: Graphic overlays can be customized with various colors, designs, and labeling to meet specific branding or user interface requirements.'}\n",
            "i 56\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA64BE20>, 'prompt': 'You have been given an IoT kit component: Active Buzzer. Give a description of the component having 3 sections as follows:\\n1) Description\\n2) Applications\\n3) Technical specifications', 'response': 'Description: An active buzzer is a small electronic component that produces sound when an electrical signal is applied to it. It consists of a piezoelectric element and an internal oscillator circuit. When voltage is applied, the piezoelectric element vibrates, producing sound waves. Unlike passive buzzers, active buzzers generate sound without needing an external waveform generator. They typically come in small cylindrical or rectangular packages and have two leads for connection to a power source.\\r\\nApplications: Active buzzers are commonly used in various electronic projects and IoT applications for audio feedback or alerting purposes. Some common applications include:\\r\\nAlarm systems: Active buzzers can be used to produce audible alerts for security systems, fire alarms, and intrusion detection systems.\\r\\nHome automation: They can be integrated into smart home devices to provide audio feedback for user interactions, such as doorbell chimes or voice prompts.\\r\\nIoT projects: Active buzzers are popular in IoT projects for notifying users of events, such as sensor readings exceeding predefined thresholds or system malfunctions.\\r\\nEducational projects: They are often used in educational settings to teach basic electronics concepts and for hands-on learning in STEM (science, technology, engineering, and mathematics) courses.\\r\\nTechnical specifications: The specifications of an active buzzer may vary depending on the manufacturer and model, but typical specifications include:\\r\\nOperating voltage: Usually around 3-5 volts DC.\\r\\nOperating current: Typically in the range of 10-20 mA.\\r\\nSound output frequency: Varies depending on the design, but commonly in the audible range (20 Hz to 20 kHz).\\r\\nSound pressure level (SPL): Typically ranges from 70 dB to 100 dB, depending on the operating voltage and design.\\r\\nDimensions: Sizes can vary, but they are often compact and lightweight, suitable for integration into small electronic devices.\\r\\nMounting options: Some active buzzers come with mounting holes or adhesive backing for easy installation in electronic projects.'}\n",
            "i 57\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA4C1B70>, 'prompt': 'You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: Snap on Connector Clip for 9V battery. Give a description of the component having 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) Technical specifications', 'response': \"Description:\\r\\nThe Snap on Connector Clip for 9V battery is a small, compact component designed to easily attach to a standard 9-volt battery. It typically consists of two parts: a male connector with metal prongs that snap securely onto the battery terminals, and a female connector with wires attached for easy integration into circuits or devices. The clip is usually made of durable materials like plastic or metal to ensure longevity and reliability in various applications.\\r\\nApplications:\\r\\nThe versatility of the Snap on Connector Clip for 9V battery makes it suitable for a wide range of applications in the realm of IoT and hardware projects. Some common uses include:\\r\\nPrototyping: It's often used in prototyping circuits and electronic projects where a 9V battery is the power source.\\r\\nDIY Electronics: Hobbyists and enthusiasts can utilize these clips to power DIY electronic gadgets and devices.\\r\\nSensor Networks: In IoT projects, these clips can power sensor nodes and data collection devices in remote or hard-to-reach locations.\\r\\nEducational Purposes: It's an excellent tool for teaching electronics and circuitry in classrooms or workshops due to its simplicity and ease of use.\\r\\nPortable Electronics: It can be employed in small, portable electronic devices like handheld instruments, LED flashlights, and portable audio players.\\r\\nTechnical Specifications:\\r\\nCompatibility: Designed to fit standard 9-volt batteries.\\r\\nMaterial: Typically made of durable plastic or metal.\\r\\nConnector Type: Male and female connectors for easy attachment and integration into circuits.\\r\\nWire Length: The length of the wires attached to the female connector may vary depending on the manufacturer and intended application.\\r\\nCurrent Rating: The maximum current carrying capacity of the connector clip should be considered based on the specific application requirements.\\r\\nDimensions: Compact and lightweight design for easy integration into various projects.\\r\\nDurability: Constructed to withstand repeated use and provide reliable performance over time.\\r\\nSafety Features: May include features such as insulation to prevent short circuits and protect against electric shock.\"}\n",
            "i 58\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFF1DF5E0>, 'prompt': 'You have been given an IoT kit component: 1 Digit 7-segment Display. Give a description of the component having 3 sections as follows:\\n1) Description\\n2) Applications\\n3) Technical specifications', 'response': 'Description:\\r\\nThe 7-segment display is a common component used in electronic circuits and devices for displaying numerical digits. It consists of seven individually controllable segments arranged in the shape of an \"8\", with an additional horizontal segment at the bottom. Each segment can be individually turned on or off to display numbers from 0 to 9 and some alphanumeric characters. The display typically has either a common cathode or common anode configuration, meaning that either the cathodes or anodes of all segments are connected together.\\r\\nApplications:\\r\\nDigital clocks and timers: The 7-segment display is commonly used to display time in digital clocks and timers.\\r\\nCounters and scoreboards: It can be used to display scores, counts, or any numerical data in various applications like sports scoreboards, production counters, etc.\\r\\nMeasurement devices: In devices such as multimeters and temperature indicators, 7-segment displays are used to display measured values.\\r\\nConsumer electronics: Many consumer devices like microwave ovens, washing machines, and calculators use 7-segment displays for numerical output.\\r\\nTechnical specifications:\\r\\nNumber of segments: 7 (plus a decimal point in some variants)\\r\\nAvailable colors: Common colors include red, green, blue, and yellow, but other colors are also available.\\r\\nOperating voltage: Typically operates at low voltages, commonly around 5 volts.\\r\\nCurrent consumption: Each segment typically consumes around 10-20 mA of current.\\r\\nSize: Available in various sizes ranging from small displays suitable for handheld devices to larger displays for industrial applications.\\r\\nInterface: Can be interfaced with microcontrollers or other digital circuits using simple digital signals to control each segment.'}\n",
            "i 59\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA4C1B40>, 'prompt': 'You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: Tilt Ball Switch. Give a description of the component having 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) Technical specifications', 'response': \"Description:\\r\\nThe tilt ball switch is a simple yet effective electronic component that functions as a sensor. It consists of a small metal ball inside a tube with two conductive contacts at either end. Under normal circumstances, the metal ball rests on one of the contacts, maintaining an electrical connection. However, when the sensor is tilted or moved, the ball rolls and bridges the gap between the contacts, completing the circuit and signaling a change in position. This action can be leveraged to detect motion, orientation, or inclination in various applications.\\r\\nApplications:\\r\\nThe tilt ball switch finds widespread use in diverse IoT and hardware projects due to its versatility and simplicity. Some common applications include:\\r\\nSecurity Systems: Tilt ball switches can be employed in security systems to detect unauthorized movement or tampering of doors, windows, or cabinets. When the sensor is tilted, it triggers an alarm or activates a surveillance camera.\\r\\nVehicle Tracking: In automotive applications, tilt ball switches can be integrated into anti-theft systems to detect changes in the vehicle's position. If the vehicle is being towed or lifted, the switch will activate, sending an alert to the owner or security system.\\r\\nOrientation Sensing: These switches are also utilized for orientation sensing in devices such as handheld electronic gadgets or IoT devices. By monitoring the position of the tilt switch, the device can adjust its display or functionality accordingly.\\r\\nGaming Controllers: Tilt ball switches are sometimes incorporated into gaming controllers for motion-sensitive gameplay. Tilting the controller can translate into in-game actions, adding an interactive element to gaming experiences.\\r\\nEnvironmental Monitoring: In environmental monitoring systems, tilt ball switches can be used to detect changes in the orientation of sensors or equipment. For example, in weather stations, they can trigger adjustments to the position of solar panels for optimal sunlight exposure.\\r\\nTechnical Specifications:\\r\\nOperating Voltage: Typically operates within a low voltage range, commonly 3.3V or 5V, making it suitable for integration into various electronic systems.\\r\\nContact Rating: The contact rating determines the maximum current and voltage that can be safely handled by the switch. It varies depending on the specific model but is usually in the range of a few milliamps to a few amps.\\r\\nResponse Time: The response time of the tilt ball switch is generally fast, making it suitable for applications requiring real-time detection of motion or orientation changes.\\r\\nDurability: The durability of the switch is an important consideration, especially in applications subject to frequent movement or vibration. High-quality switches are designed to withstand numerous tilting cycles without degradation in performance.\\r\\nMounting Options: Tilt ball switches are available in various form factors and mounting options, including surface mount and through-hole configurations, to facilitate easy integration into different electronic designs.\\r\\nOperating Temperature Range: Like other electronic components, tilt ball switches have specified operating temperature ranges within which they can function reliably. It's essential to choose a switch with a temperature range suitable for the intended application environment.\"}\n",
            "i 60\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFF1DF5E0>, 'prompt': 'Can you make a short description about the part: HC-SR501 PIR motion sensor module\\r\\n\\r\\nIt should be divided into 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) technical specification', 'response': 'Description:\\r\\nThe HC-SR501 PIR (Passive Infrared) motion sensor module is a compact and affordable device designed to detect motion within its detection range. It utilizes infrared radiation emitted by objects in its field of view to detect movement, making it ideal for applications where motion detection is required.\\r\\nApplications:\\r\\nThe HC-SR501 PIR motion sensor module finds widespread use in various applications such as:\\r\\nSecurity systems: It can be integrated into alarm systems to detect intruders or unauthorized access.\\r\\nLighting control: It can trigger lights to turn on/off automatically based on movement, enhancing energy efficiency and convenience.\\r\\nHome automation: It can be part of smart home setups to automate tasks like turning on appliances or adjusting temperature based on occupancy.\\r\\nWildlife monitoring: It can be used in wildlife cameras to detect and capture images or videos of animals in their natural habitat.\\r\\nTechnical Specifications:\\r\\nOperating Voltage: 5V - 20V DC\\r\\nStandby Current: < 50µA\\r\\nSensing Distance: Up to 7 meters\\r\\nSensing Angle: 120 degrees\\r\\nDelay Time: Adjustable from 5 seconds to 300 seconds\\r\\nTrigger Mode: Repeatable (default) or Non-repeatable\\r\\nOutput Signal: Digital (High/Low)\\r\\nDimensions: 32mm x 24mm x 25mm\\r\\nOperating Temperature: -15°C to +70°C'}\n",
            "i 61\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA4C2FE0>, 'prompt': 'You have been given an IoT kit component: Water Level Detection Sensor Module. Give a description of the component having 3 sections as follows:\\n1) Description\\n2) Applications\\n3) Technical specifications', 'response': 'Description:\\r\\nThe Water Level Detection Sensor Module is a small electronic device designed to detect the presence or absence of water. It typically consists of a sensor probe, control circuitry, and output interface. The sensor probe is usually made of corrosion-resistant materials and is placed in the water tank or container whose level needs to be monitored. When water comes into contact with the probe, it completes an electrical circuit, triggering the control circuitry to send a signal indicating water presence.\\r\\nApplications:\\r\\nHome automation: Used in smart home systems to monitor water levels in tanks, pools, or sump pumps.\\r\\nIndustrial applications: Employed in industrial processes to monitor water levels in tanks, reservoirs, and pipelines, ensuring optimal levels for operations.\\r\\nAgriculture: Used in irrigation systems to monitor water levels in soil or reservoirs, enabling efficient water management.\\r\\nEnvironmental monitoring: Deployed in environmental monitoring systems to measure water levels in rivers, lakes, and other bodies of water for research and conservation purposes.\\r\\nSecurity systems: Integrated into security systems to detect water leaks or flooding in homes, offices, and warehouses, triggering alarms or notifications.\\r\\nTechnical Specifications:\\r\\nOperating Voltage: Typically operates at DC voltages ranging from 3V to 5V.\\r\\nDetection Method: Utilizes conductivity or capacitance-based sensing methods to detect water presence.\\r\\nSensing Range: Varies depending on the specific model, but typically detects water levels within a few millimeters to several centimeters.\\r\\nOutput Interface: Provides digital or analog output signals, which can be interfaced with microcontrollers, PLCs (Programmable Logic Controllers), or IoT platforms.\\r\\nMaterial: Constructed using corrosion-resistant materials such as stainless steel or plastic for durability and longevity.\\r\\nEnvironmental Protection: May feature IP (Ingress Protection) ratings for resistance against dust and water ingress, ensuring reliable operation in various environmental conditions.'}\n",
            "i 62\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA64BE20>, 'prompt': 'You have been given an IoT kit component: 4 Digit 7-segment Display. Give a description of the component having 3 sections as follows:\\n1) Description\\n2) Applications\\n3) Technical specifications', 'response': 'Description:\\r\\nThe 4 Digit 7-segment Display is a common electronic component used to visually display numerical information. It consists of four individual 7-segment displays, each capable of displaying numbers from 0 to 9. Each segment is composed of LEDs arranged in the shape of the number \"8\", with an additional LED for the decimal point. The display can be controlled through a microcontroller or other digital logic circuitry to show different numbers or characters.\\r\\nApplications:\\r\\nDigital Clocks: Displaying time in hours and minutes.\\r\\nCountdown Timers: Indicating time remaining in various applications.\\r\\nTemperature Readouts: Showing temperature values in degrees Celsius or Fahrenheit.\\r\\nScoreboards: Displaying scores or points in games or competitions.\\r\\nMeasurement Instruments: Displaying readings from sensors such as distance, pressure, or voltage.\\r\\nProcess Monitoring: Indicating parameters like speed, RPM, or pressure in industrial applications.\\r\\nTechnical Specifications:\\r\\nNumber of Digits: 4\\r\\nType of Display: Common Cathode or Common Anode (depends on the specific model)\\r\\nDigit Height: Typically 0.56 inches (14.2 mm), but other sizes are available.\\r\\nLED Color: Usually red, but also available in other colors like green, blue, or yellow.\\r\\nOperating Voltage: Typically 3V to 5V DC.\\r\\nCurrent Consumption: Varies depending on the brightness of the display and the number of segments illuminated.\\r\\nInterface: Generally driven using a serial interface like SPI (Serial Peripheral Interface) or I2C (Inter-Integrated Circuit).\\r\\nMounting: Usually comes in a through-hole or surface-mount package for easy integration onto circuit boards.'}\n",
            "i 63\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFF30EB60>, 'prompt': 'Can you make a short description about the part: Sound Sensor Module\\n\\nIt should be divided into 3 sections as follows:\\n1) Description\\n2) Applications\\n3) technical specification', 'response': 'Description:\\nA Sound Sensor Module is an electronic device designed to detect sound levels in its environment and convert them into electrical signals. It typically consists of a microphone or a sound sensor, an amplifier circuit, and an output interface. The microphone picks up sound waves, which are then amplified and converted into voltage variations proportional to the sound intensity. These voltage signals can be further processed or used directly to trigger actions based on the detected sound levels.\\nApplications:\\nSound Sensor Modules find diverse applications across various fields. They are commonly used in noise pollution monitoring systems to measure and analyze ambient noise levels in urban areas. In home automation, these modules enable voice-activated control of appliances and devices, allowing users to interact with their environment through sound commands. Sound Sensor Modules are also utilized in security systems for detecting abnormal sounds or disturbances, alerting users to potential threats. Additionally, they play a crucial role in robotics and industrial automation for sound-based localization, navigation, and communication tasks.\\nTechnical Specifications:\\nOperating Voltage: Typically ranges from 3.3V to 5V DC\\nDetection Range: Varies depending on the sensitivity of the microphone/sensor\\nOutput Interface: Analog or digital output (e.g., voltage, PWM, serial)\\nFrequency Response: Wide frequency range to capture various types of sounds\\nSensitivity Adjustment: Some modules may feature adjustable sensitivity settings\\nSize and Form Factor: Compact and often designed for easy integration into different applications\\nCompatibility: Compatible with microcontrollers and single-board computers for data processing and integration into larger systems\\nSignal-to-Noise Ratio (SNR): High SNR for accurate sound detection and analysis\\nEnvironmental Considerations: Some modules may feature waterproof or dustproof designs for outdoor applications'}\n",
            "i 64\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA4C2C20>, 'prompt': 'Can you make a short description about the part: RC522 RFID Module\\r\\n\\r\\nIt should be divided into 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) technical specification', 'response': 'Description:\\nThe RC522 RFID Module is a compact and versatile radio-frequency identification (RFID) reader module. It employs the RC522 integrated circuit to facilitate contactless communication with RFID tags or cards. This module operates at 13.56 MHz frequency and uses the ISO/IEC 14443A standard for communication, enabling seamless interaction with a wide range of RFID tags and cards.\\nApplications:\\nThe RC522 RFID Module finds applications in various fields such as access control systems, attendance tracking systems, inventory management, payment systems, and asset tracking. It is extensively used in security systems, smart locks, electronic toll collection systems, and public transportation for efficient identification and authentication purposes. Additionally, it is employed in hobbyist projects and prototyping due to its ease of use and affordability.\\nTechnical Specifications:\\nOperating Frequency: 13.56 MHz\\nCommunication Protocol: ISO/IEC 14443A\\nSupported RFID Tags: MIFARE 1 KB, MIFARE 4 KB, MIFARE Ultralight, NTAG203, and others compatible with ISO/IEC 14443A\\nCommunication Interface: SPI (Serial Peripheral Interface)\\nOperating Voltage: 3.3V (5V tolerant)\\nMaximum Communication Range: Up to 5 cm\\nDimensions: Small form factor, typically around 40mm x 60mm\\nIntegrated Features: Built-in antenna, on-chip cryptography support for secure data transmission\\nCompatibility: Compatible with various microcontrollers including Arduino, Raspberry Pi, and others, making it easy to integrate into existing projects.'}\n",
            "i 65\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA64BEB0>, 'prompt': 'You have been given an IoT kit component: ELEGOO Power supply module. Give a description of the component having 3 sections as follows:\\n1) Description\\n2) Applications\\n3) Technical specifications', 'response': \"Description:\\r\\nThe ELEGOO Power Supply Module is a compact and versatile component designed for use in IoT (Internet of Things) projects. It provides a stable and adjustable power supply, allowing users to regulate voltage levels according to their specific project requirements. This module typically features a small form factor and can be easily integrated into various electronic setups.\\r\\nApplications:\\r\\nThe ELEGOO Power Supply Module finds application in a wide range of IoT projects and electronic experiments. Some common applications include:\\r\\nPowering microcontrollers, sensors, and other electronic components in IoT devices.\\r\\nPrototyping and testing electronic circuits by providing a reliable power source.\\r\\nEducational purposes, teaching students about power supply regulation and circuit design.\\r\\nDIY electronics projects, such as home automation systems, weather stations, and smart gadgets.\\r\\nIntegration into robotics projects, providing power to motors, controllers, and sensors.\\r\\nTechnical Specifications:\\r\\nInput Voltage: The module typically accepts a wide range of input voltages, such as 5V to 12V DC.\\r\\nOutput Voltage: It provides adjustable output voltage, which can be set within a specified range, such as 1.25V to 12V DC.\\r\\nOutput Current: The maximum output current is often specified, such as 1A or 2A, depending on the model.\\r\\nVoltage Regulation: The module usually features built-in voltage regulation circuitry for stable output voltage.\\r\\nProtection Features: Some models may include protection features like overcurrent protection, overvoltage protection, and short-circuit protection.\\r\\nInterface: It may have input and output terminals for easy connection to other components and circuits.\\r\\nSize and Form Factor: The physical dimensions and form factor of the module may vary, but it's typically compact and designed for easy integration into electronic projects.\"}\n",
            "i 66\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA6BE4A0>, 'prompt': 'Can you make a short description about the part: Servo Motor SG90\\n\\nIt should be divided into 3 sections as follows:\\n1) Description\\n2) Applications\\n3) technical specification', 'response': \"Description:\\r\\nThe SG90 Servo Motor is a compact and lightweight actuator commonly used in various robotics, RC (Remote Control) vehicles, and automation projects. It operates on the principle of a closed-loop control system, where its position is precisely controlled based on input signals. The SG90 is renowned for its affordability, reliability, and ease of use, making it a popular choice among hobbyists and professionals alike.\\r\\nApplications:\\r\\nThe SG90 Servo Motor finds widespread applications across different fields, including:\\r\\nRobotics: Used for controlling robot arms, grippers, and other mechanical movements with precision.\\r\\nRC Vehicles: Employed in radio-controlled cars, airplanes, boats, and helicopters for steering, throttle control, and other maneuvers.\\r\\nAutomation: Integrated into various automated systems for tasks such as opening and closing valves, controlling camera movements, and adjusting solar panels' orientation.\\r\\nEducation: Utilized in educational settings to teach concepts of robotics, electronics, and control systems due to its simplicity and versatility.\\r\\nTechnical Specifications:\\r\\nOperating Voltage: 4.8V - 6V\\r\\nStall Torque: 1.8 kg/cm (4.8V), 2.2 kg/cm (6V)\\r\\nOperating Speed: 0.12 sec/60° (4.8V), 0.10 sec/60° (6V)\\r\\nOperating Temperature: -30°C to +60°C\\r\\nDimensions: 23mm x 12mm x 29mm\\r\\nWeight: 9g\\r\\nRotation Range: 180°\\r\\nConnector Type: 3-pin female header (usually brown for ground, red for power, and orange for control signal)\\r\\nGear Type: Plastic gears\\r\\nControl Signal: Pulse Width Modulation (PWM) signal with a frequency of around 50Hz, with a pulse width ranging from 1ms to 2ms, where 1ms represents the minimum position, and 2ms represents the maximum position.\\n\"}\n",
            "i 67\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA4C29B0>, 'prompt': 'You have been given an IoT kit component: Passive Buzzer. Give a description of the component having 3 sections as follows:\\n1) Description\\n2) Applications\\n3) Technical specifications', 'response': 'Description:\\r\\nA Passive Buzzer is a type of electronic component that generates sound when an electric current is passed through it. It consists of a piezoelectric element housed in a plastic casing. Unlike an active buzzer, which produces a specific frequency when powered, a passive buzzer requires an external oscillating signal to produce sound. It essentially acts as a vibrating membrane when subjected to an alternating current, producing audible sound waves.\\r\\nApplications:\\r\\nAlarm systems: Passive buzzers are commonly used in alarm systems to alert users of potential threats or emergencies.\\r\\nElectronic games: They can be incorporated into electronic games to provide sound effects or feedback to players.\\r\\nIoT devices: Passive buzzers can be integrated into IoT devices to provide auditory notifications or alerts for various events or conditions, such as temperature changes, motion detection, or system errors.\\r\\nEducational purposes: They are often used in educational kits and projects to demonstrate basic principles of electronics and sound generation.\\r\\nTechnical Specifications:\\r\\nOperating Voltage: Typically, passive buzzers operate within a voltage range of 3V to 12V, although specific models may have different voltage requirements.\\r\\nFrequency Range: The frequency range of a passive buzzer depends on its design and construction but is usually between a few hundred Hertz to several kilohertz.\\r\\nSound Output: The sound output level of a passive buzzer is measured in decibels (dB) and varies depending on factors such as voltage, frequency, and construction.\\r\\nConstruction: Passive buzzers typically consist of a piezoelectric element (e.g., ceramic disk) mounted within a plastic housing, with two wire leads for electrical connections.\\r\\nSize and Form Factor: Passive buzzers come in various sizes and form factors, ranging from small surface-mount devices to larger through-hole components, allowing for flexibility in design and integration.'}\n",
            "i 68\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFF1DF5E0>, 'prompt': 'You have been given an IoT kit component: ESP Wroom 32. Give a description of the component having 3 sections as follows:\\n1) Description\\n2) Applications\\n3) Technical specifications', 'response': \"Description:\\r\\nThe ESP Wroom 32 is a powerful microcontroller module developed by Espressif Systems. It integrates a dual-core 32-bit processor, along with Wi-Fi and Bluetooth connectivity capabilities. It's based on the ESP32 chip, which is known for its low power consumption and high performance. The module comes in a compact form factor, making it suitable for various IoT (Internet of Things) applications.\\r\\nApplications:\\r\\nThe ESP Wroom 32 module finds applications in a wide range of IoT projects and products. Some common uses include:\\r\\nHome automation: Controlling lights, appliances, and security systems remotely via Wi-Fi or Bluetooth.\\r\\nIndustrial automation: Monitoring and controlling machinery and equipment in factories and warehouses.\\r\\nSmart agriculture: Collecting data from sensors to optimize crop irrigation, monitor soil conditions, and manage livestock.\\r\\nWearable devices: Building smartwatches, fitness trackers, and other wearable gadgets with Bluetooth connectivity.\\r\\nEnvironmental monitoring: Gathering data on air quality, temperature, humidity, and other environmental parameters for analysis and visualization.\\r\\nTechnical Specifications:\\r\\nMicrocontroller: Dual-core Xtensa 32-bit LX6 microprocessor\\r\\nClock frequency: Up to 240 MHz\\r\\nWi-Fi: 802.11 b/g/n\\r\\nBluetooth: Bluetooth v4.2 BR/EDR and BLE (Bluetooth Low Energy)\\r\\nFlash memory: 4 MB\\r\\nRAM: 520 KB\\r\\nGPIO pins: 36 (including 15 PWM outputs)\\r\\nADC channels: 18 (12-bit SAR ADC)\\r\\nOperating voltage: 2.2V to 3.6V\\r\\nOperating temperature: -40°C to +125°C\\r\\nDimensions: 18mm x 25.5mm\\r\\nIntegrated peripherals: SPI, I2C, I2S, UART, ADC, DAC, RTC, Touch sensors\"}\n",
            "i 69\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA4C30A0>, 'prompt': 'You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: ELEGOO DS1307 RTC Module. Give a description of the component having 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) Technical specifications', 'response': 'Description:\\r\\nThe ELEGOO DS1307 RTC Module is a compact and versatile real-time clock (RTC) module designed for integration into IoT projects and electronic devices. This module utilizes the DS1307 chip, a highly accurate RTC integrated circuit that communicates with the host microcontroller via I2C protocol. The module features a small form factor and is equipped with a battery backup system, ensuring accurate timekeeping even in the absence of external power. With its simplicity of use and precise timekeeping capabilities, the ELEGOO DS1307 RTC Module is an essential component for projects requiring time-sensitive operations or data logging.\\r\\nApplications:\\r\\nThe ELEGOO DS1307 RTC Module finds applications in various IoT and embedded systems projects where accurate timekeeping is crucial. Some common applications include:\\r\\nClocks and timers: Utilized in digital clocks, countdown timers, and scheduling systems.\\r\\nData logging: Enables precise timestamping of data in applications such as weather stations, environmental monitoring, and industrial automation.\\r\\nSecurity systems: Integrated into access control systems, surveillance cameras, and alarm systems to maintain accurate time records.\\r\\nHome automation: Used in smart home devices for scheduling tasks, energy management, and synchronization of multiple devices.\\r\\nWearable devices: Incorporated into wearable electronics for fitness tracking, sleep monitoring, and activity logging.\\r\\nTechnical Specifications:\\r\\nChipset: DS1307 RTC integrated circuit\\r\\nCommunication: I2C interface\\r\\nSupply Voltage: 5V\\r\\nBattery Backup: CR2032 coin cell battery (included)\\r\\nAccuracy: ±2ppm from 0°C to +40°C\\r\\nOperating Temperature Range: -40°C to +85°C\\r\\nDimensions: Compact form factor for easy integration into electronic projects\\r\\nCompatibility: Compatible with various microcontrollers including Arduino, Raspberry Pi, and other development platforms with I2C support.'}\n",
            "i 70\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFF1DEEF0>, 'prompt': 'You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: HiLetgo GY-521 module. Give a description of the component having 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) Technical specifications', 'response': 'Description:\\r\\nThe HiLetgo GY-521 module is a compact and versatile sensor module designed for motion tracking and orientation sensing applications. It incorporates an MPU-6050 sensor chip, which combines a 3-axis gyroscope and a 3-axis accelerometer into a single package. The module also includes an onboard Digital Motion Processor (DMP) which offloads complex motion processing tasks from the host microcontroller, making it easier to integrate into various projects. It communicates with the host microcontroller via the I2C interface, allowing for easy integration with a wide range of microcontrollers and development boards.\\r\\nApplications:\\r\\nThe HiLetgo GY-521 module finds applications in various fields where motion tracking and orientation sensing are required. Some common applications include:\\r\\nRobotics: Used for stabilizing and controlling the movement of robotic platforms.\\r\\nDrone and UAV (Unmanned Aerial Vehicle) stabilization: Provides accurate orientation data for maintaining stability during flight.\\r\\nVirtual reality and augmented reality systems: Tracks the movement and orientation of VR/AR headsets and controllers.\\r\\nMotion-sensitive gaming controllers: Enables motion-based control inputs for gaming consoles and peripherals.\\r\\nWearable devices: Integrates into wearable gadgets for activity tracking, gesture recognition, and motion-based user interfaces.\\r\\nMotion analysis and research: Used in biomechanical studies, sports performance analysis, and other research applications requiring precise motion tracking data.\\r\\nTechnical Specifications:\\r\\nSensor Chip: MPU-6050\\r\\nAxes: 3-axis gyroscope, 3-axis accelerometer\\r\\nCommunication Interface: I2C (Inter-Integrated Circuit)\\r\\nVoltage Supply: 3.3V - 5V\\r\\nOperating Voltage: 3.3V\\r\\nGyroscope Range: ±250, ±500, ±1000, ±2000 degrees per second\\r\\nAccelerometer Range: ±2g, ±4g, ±8g, ±16g\\r\\nDimensions: 21mm x 16mm'}\n",
            "i 71\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFF32E890>, 'prompt': 'You have been given an IoT kit component: NPN transistor PN2222. Give a description of the component having 3 sections as follows:\\n1) Description\\n2) Applications\\n3) Technical specifications', 'response': 'Description:\\r\\nThe NPN transistor PN2222 is a versatile semiconductor device commonly used in electronic circuits. It belongs to the bipolar junction transistor (BJT) family and is specifically categorized as an NPN (Negative-Positive-Negative) transistor. Physically, it typically comes in a TO-92 package, which is small and easy to handle. The PN2222 has three terminals: the Base (B), the Emitter (E), and the Collector (C). It operates by controlling the flow of current between the Collector and the Emitter terminals based on the current applied to its Base terminal.\\r\\nApplications:\\r\\nThe PN2222 transistor finds numerous applications in electronic circuits due to its ability to amplify signals and act as a switch. Some common applications include:\\r\\nSignal Amplification: It can amplify weak signals in audio amplifiers, radio receivers, and other low-power applications.\\r\\nSwitching: It can turn high-power loads on or off in applications such as relay drivers, motor control circuits, LED drivers, and more.\\r\\nOscillation: It can be used in oscillator circuits for generating oscillations in radio frequency (RF) circuits, timers, and pulse generators.\\r\\nVoltage Regulation: It can be incorporated into voltage regulator circuits to stabilize voltages in power supplies and voltage reference circuits.\\r\\nTechnical Specifications:\\r\\nMaximum Collector-Base Voltage (Vcbo): 75V\\r\\nMaximum Collector-Emitter Voltage (Vceo): 40V\\r\\nMaximum Emitter-Base Voltage (Vebo): 6V\\r\\nMaximum Collector Current (Ic): 600mA\\r\\nContinuous Collector Current (Ic): 600mA\\r\\nPower Dissipation (Pd): 500mW\\r\\nTransition Frequency (ft): 250MHz (typical)\\r\\nCurrent Gain (hFE): 100 - 300 (typical)'}\n",
            "i 72\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA64BF40>, 'prompt': 'You have been given an IoT kit component: Female to male Dupont Wire. Give a description of the component having 3 sections as follows:\\n1) Description\\n2) Applications\\n3) Technical specifications', 'response': 'Description:\\r\\nThe Female to Male Dupont Wire is a versatile electrical component commonly used in electronics projects and IoT (Internet of Things) applications. It consists of a set of wires with female Dupont connectors on one end and male Dupont connectors on the other end. These connectors allow for easy and secure connections between various electronic components such as sensors, microcontrollers, and breadboards. The wires are typically made of flexible and durable materials like PVC or silicone, ensuring reliable performance and longevity.\\r\\nApplications:\\r\\nThe Female to Male Dupont Wire finds widespread use in prototyping, DIY electronics, and IoT projects due to its convenience and versatility. Some common applications include:\\r\\nConnecting sensors to microcontrollers or development boards for data acquisition and processing.\\r\\nEstablishing connections between different modules or components within an electronic circuit.\\r\\nCreating custom wiring harnesses for specific project requirements.\\r\\nPrototyping and testing electronic circuits on breadboards or perfboards.\\r\\nBuilding simple plug-and-play setups for experimenting with hardware and software interactions.\\r\\nTechnical Specifications:\\r\\nLength: Typically available in various lengths ranging from a few inches to several feet, allowing for flexible configurations and cable management.\\r\\nWire Gauge: The wires are usually made of 22 AWG (American Wire Gauge) stranded copper conductors, offering a good balance between flexibility and conductivity.\\r\\nConnector Type: The Female to Male Dupont Wire features Dupont connectors on both ends, with the female connector housing receptacles for male pins and the male connector featuring protruding pins for insertion into female sockets.\\r\\nCompatibility: Compatible with standard Dupont connectors commonly used in electronics projects, ensuring easy integration with a wide range of components and modules.\\r\\nInsulation: Insulated with PVC or silicone material to protect the conductors and ensure electrical safety.\\r\\nColor Coding: Available in various colors for easy identification and organization of connections within complex circuits or systems. Common colors include red, black, blue, green, yellow, and white.'}\n",
            "i 73\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFB839FF0>, 'prompt': 'Can you make a short description about the part: Button for IoT kit\\r\\n\\r\\nIt should be divided into 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) technical specification', 'response': 'Description:\\r\\nThe Button for IoT kit is a compact and versatile device designed to seamlessly integrate into IoT systems, enabling users to trigger actions or commands with a simple press. Its ergonomic design ensures ease of use, while its wireless connectivity capabilities make it ideal for remote operation. With its responsive tactile feedback, the Button offers a reliable means of interaction in various environments, from home automation setups to industrial applications.\\r\\nApplications:\\r\\nThe Button finds wide-ranging applications across diverse IoT scenarios. In smart homes, it serves as a convenient way to control lighting, appliances, or security systems with a single press. In industrial settings, it can be utilized for initiating processes, triggering alerts, or monitoring equipment status. Additionally, the Button is invaluable in healthcare for patient monitoring and emergency response systems. Its flexibility makes it adaptable to numerous use cases, contributing to enhanced efficiency and convenience in IoT environments.\\r\\nTechnical Specification:\\r\\nWireless Connectivity: Supports various wireless protocols such as Wi-Fi, Bluetooth, Zigbee, or LoRaWAN for seamless integration into IoT networks.\\r\\nPower Source: Operates on battery power for enhanced portability and flexibility.\\r\\nButton Type: Utilizes a tactile push-button mechanism for reliable and responsive user interaction.\\r\\nDurability: Constructed with durable materials to withstand frequent use and varying environmental conditions.\\r\\nCompatibility: Compatible with popular IoT platforms and protocols, facilitating easy integration and interoperability.\\r\\nSize and Form Factor: Compact and lightweight design for easy installation and mounting in diverse applications.\\r\\nCustomization: Supports programmable functionality, allowing users to customize actions or commands triggered by button presses according to specific requirements.'}\n",
            "i 74\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA64BE20>, 'prompt': 'You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: Sound Sensor Module. Give a description of the component having 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) Technical specifications', 'response': 'Description:\\nThe Sound Sensor Module is a small electronic component designed to detect sound levels in its surrounding environment. It typically consists of a built-in microphone that captures audio signals, an analog-to-digital converter (ADC) to convert the analog sound waves into digital signals, and supporting circuitry for signal conditioning and processing. Some variants may also include additional features like adjustable sensitivity and onboard amplification.\\nApplications:\\nThe Sound Sensor Module finds applications in various fields, including:\\nHome Automation: It can be used to detect sounds such as doorbells, alarms, or even baby cries, triggering automated responses like turning on lights or sending notifications to a smartphone.\\nSecurity Systems: Integrating sound sensors into security systems enables detection of unusual noises such as glass breaking or footsteps, enhancing the effectiveness of intrusion detection.\\nIndustrial Monitoring: In industrial settings, sound sensors can be employed for monitoring equipment operation, detecting abnormalities such as machine malfunctions or excessive noise levels, which may indicate potential issues.\\nEnvironmental Monitoring: Sound sensors contribute to environmental monitoring by measuring noise pollution levels in urban areas or detecting specific sounds in natural habitats, aiding in wildlife conservation efforts.\\nHealthcare: Sound sensors can be utilized in healthcare applications for monitoring patient vital signs, such as breathing patterns and heartbeats, particularly in settings where continuous monitoring is required.\\nTechnical Specifications:\\nOperating Voltage: Typically compatible with a wide range of voltages, commonly 3.3V or 5V.\\nDetection Range: Varies depending on the sensitivity and design of the module, often capable of detecting sound levels within a range of 20dB to 90dB or higher.\\nOutput: Analog or digital output signal, depending on the module type. Analog output provides a continuous voltage proportional to the detected sound level, while digital output may indicate sound presence or trigger thresholds.\\nSensitivity: Adjustable sensitivity levels may be available in some modules, allowing users to fine-tune the detection threshold.\\nInterface: Simple to integrate into microcontroller-based projects via analog or digital input pins.\\nSize: Compact form factor suitable for integration into various electronic systems and projects.\\nAdditional Features: Some modules may include onboard amplification, filtering, or noise reduction capabilities to improve performance in noisy environments.'}\n",
            "i 75\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFB839FF0>, 'prompt': 'You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: L293D. Give a description of the component having 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) Technical specifications', 'response': 'Description:\\r\\nThe L293D is a popular integrated circuit (IC) primarily designed for driving small DC motors and stepper motors. It is commonly used in robotics, automation, and other projects where motor control is required. The IC contains four half-H bridge drivers, allowing it to control the direction and speed of two DC motors independently.\\r\\nApplications:\\r\\nRobotic projects: The L293D is widely used in robotics for controlling the movement of robotic arms, wheels, or other locomotion mechanisms.\\r\\nAutomation systems: It can be employed in various automated systems such as conveyor belts, door openers, and window blinds.\\r\\nRemote-controlled vehicles: Used in hobbyist projects like RC cars, boats, and planes for controlling motorized movements.\\r\\nPrototyping and experimentation: Due to its versatility and ease of use, the L293D is often used in prototyping and experimentation with motor control applications.\\r\\nTechnical Specifications:\\r\\nSupply Voltage: 4.5V to 36V\\r\\nOutput Current per Channel: 600mA (1.2A peak)\\r\\nNumber of Channels: 4 (two H-bridges)\\r\\nLogic Voltage: 3.3V to 5V\\r\\nOperating Temperature: -40°C to 125°C\\r\\nPackage Type: 16-pin DIP (Dual In-line Package) or SOIC (Small Outline Integrated Circuit)\\r\\nMotor Types Supported: DC motors, stepper motors\\r\\nBuilt-in Diodes: Internal diodes are included for protection against back electromotive force (EMF) generated by the motors.'}\n",
            "i 76\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFF1DF5E0>, 'prompt': 'You have been given an IoT kit component: Rotary Encoder Module. Give a description of the component having 3 sections as follows:\\n1) Description\\n2) Applications\\n3) Technical specifications', 'response': \"Description:\\r\\nA Rotary Encoder Module is a sensor device used to convert the angular position or rotation of a shaft into an analog or digital signal. It typically consists of a rotating shaft attached to a disc with evenly spaced contact pads or slots and a stationary sensor that detects the changes in the disc's position as the shaft rotates. This sensor generates electrical signals corresponding to the direction and magnitude of the rotation, allowing for precise measurement and control of rotational movement.\\r\\nApplications:\\r\\nRobotics: Rotary encoders are commonly used in robotic systems to accurately control the movement of robotic arms, joints, and actuators.\\r\\nIndustrial Automation: They play a vital role in industrial automation applications such as CNC machines, conveyor systems, and automated assembly lines for position sensing and feedback control.\\r\\nAutomotive: Rotary encoders are used in automotive applications for controlling the position of throttle valves, steering wheels, and gear shifts.\\r\\nConsumer Electronics: They are found in various consumer electronics devices like printers, computer mice, and audio equipment for user interface control and navigation.\\r\\nMedical Devices: Rotary encoders are used in medical equipment such as MRI machines, surgical robots, and patient monitoring systems for precise positioning and control.\\r\\nTechnical Specifications:\\r\\nResolution: Specifies the number of pulses generated per revolution, indicating the encoder's accuracy in detecting small changes in rotation.\\r\\nOperating Voltage: The voltage range within which the encoder operates reliably.\\r\\nOutput Interface: Indicates the type of output signal generated by the encoder, such as digital (e.g., pulse-width modulation) or analog (e.g., voltage or current).\\r\\nShaft Type: Describes the type of shaft (e.g., D-shaft, hollow shaft) and its dimensions for compatibility with different mechanical systems.\\r\\nEnvironmental Conditions: Includes operating temperature range, humidity tolerance, and resistance to dust, water, and vibrations for suitability in various environmental conditions.\\r\\nMounting Options: Specifies the mounting method (e.g., panel mount, PCB mount) for easy integration into different electronic systems.\\r\\nDimension and Weight: Provides the physical dimensions and weight of the encoder for design and installation purposes.\"}\n",
            "i 77\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA64BEB0>, 'prompt': 'You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: 100μF electrolytic capacitor. Give a description of the component having 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) Technical specifications', 'response': \"Description:\\r\\nThe 100μF electrolytic capacitor is an electronic component designed to store and release electrical energy in circuits. It consists of two conductive plates separated by an electrolyte, typically a liquid or gel-like substance. One plate is coated with a thin layer of oxide, which serves as the dielectric. This construction allows electrolytic capacitors to achieve high capacitance values in a relatively small package compared to other capacitor types.\\r\\nApplications:\\r\\nPower Supply Filtering: Electrolytic capacitors are commonly used in power supply circuits to smooth out voltage fluctuations and reduce ripple, ensuring a stable DC voltage output.\\r\\nCoupling and Decoupling: They are employed in coupling and decoupling applications to block DC while allowing AC signals to pass through, facilitating signal transmission between different stages of electronic circuits.\\r\\nTiming Circuits: In conjunction with resistors, electrolytic capacitors can be used in timing circuits to generate precise time delays or oscillations.\\r\\nAudio Amplification: Electrolytic capacitors are utilized in audio circuits for coupling and filtering purposes, helping to maintain signal integrity and remove unwanted noise.\\r\\nTechnical Specifications:\\r\\nCapacitance: 100 microfarads (μF)\\r\\nVoltage Rating: The voltage rating of the capacitor indicates the maximum voltage it can withstand without breakdown. Typically, for electrolytic capacitors, this ranges from a few volts to several hundred volts. Ensure the voltage rating of the capacitor meets or exceeds the requirements of the circuit.\\r\\nPolarity: Electrolytic capacitors are polarized, meaning they have a positive (+) and negative (-) terminal. It is crucial to observe polarity when connecting them in a circuit to prevent damage or malfunction. The negative terminal is usually marked on the capacitor body.\\r\\nOperating Temperature: The operating temperature range specifies the temperatures within which the capacitor can operate reliably. Ensure the capacitor's operating temperature range suits the environmental conditions of its intended application.\\r\\nESR (Equivalent Series Resistance): Electrolytic capacitors exhibit some internal resistance known as equivalent series resistance (ESR). Lower ESR values are desirable for minimizing power losses and improving circuit efficiency.\\r\\nLifetime: Electrolytic capacitors have a finite lifespan, typically rated in hours of operation. Consider the capacitor's lifespan when designing long-term or critical applications, and select a capacitor with an appropriate rated lifespan.\"}\n",
            "i 78\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA64BF40>, 'prompt': 'You have been given an IoT kit component:  Elegoo UNO R3 controller board. Give a description of the component having 3 sections as follows:\\n1) Description\\n2) Applications\\n3) Technical specifications\\n\\n', 'response': \"Description:\\r\\nThe Elegoo UNO R3 controller board is a microcontroller board based on the ATmega328P chip. It's designed to be compatible with the Arduino UNO R3 board, making it ideal for prototyping and DIY electronics projects. The board features various input and output pins, including digital I/O pins, analog pins, and special function pins like PWM (Pulse Width Modulation) pins. It also includes a USB interface for programming and power supply.\\r\\nApplications:\\r\\nPrototyping: The Elegoo UNO R3 board is commonly used for prototyping various electronic projects due to its versatility and ease of use.\\r\\nHome automation: It can be used in home automation projects to control lights, appliances, and other devices remotely via the internet.\\r\\nRobotics: The board can serve as the brain of robotic projects, controlling motors, sensors, and other components.\\r\\nIoT (Internet of Things): With the addition of networking modules like Wi-Fi or Ethernet shields, the board can be used to build IoT devices for monitoring and controlling devices remotely.\\r\\nTechnical Specifications:\\r\\nMicrocontroller: ATmega328P\\r\\nOperating Voltage: 5V\\r\\nInput Voltage (recommended): 7-12V\\r\\nDigital I/O Pins: 14 (of which 6 provide PWM output)\\r\\nAnalog Input Pins: 6\\r\\nFlash Memory: 32KB (0.5KB used by bootloader)\\r\\nSRAM: 2KB\\r\\nEEPROM: 1KB\\r\\nClock Speed: 16 MHz\\r\\nUSB Interface: Type-B\\r\\nDimensions: 68.6mm x 53.4mm\"}\n",
            "i 79\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA4C2DD0>, 'prompt': 'You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: USB B to USB A Cable. Give a description of the component having 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) Technical specifications', 'response': 'Description:\\r\\nThe USB B to USB A Cable is a versatile data transfer and power supply cable commonly used in IoT (Internet of Things) projects and hardware setups. It features a USB Type B connector on one end and a USB Type A connector on the other end, allowing seamless connectivity between various devices, sensors, and microcontrollers. The cable is typically designed with high-quality materials to ensure reliable data transmission and stable power delivery, making it an essential component in IoT prototyping and deployment.\\r\\nApplications:\\r\\nThe USB B to USB A Cable finds widespread applications across different IoT scenarios and hardware projects, including but not limited to:\\r\\nConnecting microcontrollers (such as Arduino, Raspberry Pi, ESP32) to computers for programming and data transfer.\\r\\nPowering and communicating with IoT sensors, modules, and development boards.\\r\\nInterfacing with USB peripherals like cameras, displays, and input devices in IoT systems.\\r\\nEstablishing serial communication between IoT devices and computers for debugging and monitoring purposes.\\r\\nIntegrating IoT gateways with edge devices and cloud platforms for data aggregation and analysis.\\r\\nOverall, the cable serves as a fundamental link in the connectivity chain of IoT ecosystems, facilitating seamless data exchange and power distribution between various components.\\r\\nTechnical Specifications:\\r\\nConnector Type: USB Type B Male (Upstream) to USB Type A Male (Downstream)\\r\\nCable Length: Standard lengths range from 0.5 meters to 5 meters, with custom lengths available.\\r\\nData Transfer Rate: Supports USB 2.0 standard with a maximum transfer rate of 480 Mbps.\\r\\nPower Rating: Typically supports 5 volts DC (Direct Current) and up to 500 milliamperes (mA) of current for power delivery.\\r\\nCable Construction: Constructed with high-quality copper conductors and shielding for optimal signal integrity and durability.\\r\\nCompatibility: Compatible with a wide range of devices, including PCs, laptops, microcontrollers, IoT development boards, and USB peripherals.\\r\\nOperating Temperature: Suitable for use within a temperature range of -10°C to 50°C, ensuring reliable performance in various environments.\\r\\nCompliance: Conforms to USB 2.0 specifications and may comply with additional industry standards for safety and reliability.\\r\\nRoHS Compliance: Manufactured with RoHS (Restriction of Hazardous Substances) compliant materials, ensuring environmental sustainability and safety.'}\n",
            "i 80\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFF30EB60>, 'prompt': 'Can you make a short description about the part: ESP Wroom 32:\\r\\n\\r\\nIt should be divided into 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) technical specification', 'response': 'Description:\\nThe ESP-WROOM-32 is a highly integrated and versatile Wi-Fi and Bluetooth module developed by Espressif Systems. It is based on the ESP32 system-on-chip (SoC), which combines a dual-core processor with Wi-Fi and Bluetooth capabilities, along with a rich set of peripherals. The module is compact in size, making it suitable for a wide range of IoT (Internet of Things) applications where wireless connectivity and processing power are required.\\nApplications:\\nIoT Devices: The ESP-WROOM-32 is commonly used in various IoT devices such as smart home appliances, wearable devices, and environmental sensors.\\nHome Automation: It enables the development of smart home systems for controlling lights, thermostats, and security cameras remotely.\\nIndustrial Automation: Industrial monitoring and control systems can benefit from its wireless connectivity and processing capabilities.\\nRobotics: The module can be integrated into robotic projects for wireless communication and control.\\nConsumer Electronics: It finds applications in consumer electronics products like smartwatches, fitness trackers, and wireless speakers.\\nTechnical Specifications:\\nMicrocontroller: Dual-core Tensilica LX6 microprocessor\\nWi-Fi: 802.11 b/g/n/e/i (2.4GHz) and 802.11 a/n/ac (5GHz)\\nBluetooth: Bluetooth v4.2 BR/EDR and Bluetooth Low Energy (BLE)\\nRAM: 520 KB SRAM\\nFlash: 4 MB SPI flash memory\\nGPIO: 36 GPIO pins with various functionalities\\nPeripherals: UART, I2C, SPI, ADC, DAC, PWM, and more\\nOperating Voltage: 2.2V to 3.6V\\nOperating Temperature: -40°C to 125°C\\nDimensions: 18mm x 25.5mm x 3.1mm\\nCertification: FCC, CE, IC, SRRC, KC, NCC, and Wi-Fi Alliance'}\n",
            "i 81\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA4C2D10>, 'prompt': 'Can you make a short description about the part: 9V battery\\r\\n\\r\\nIt should be divided into 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) technical specification', 'response': 'Description:\\r\\nA 9V battery is a small, rectangular-shaped power source commonly used in various electronic devices. It typically consists of six cylindrical or rectangular cells connected in series within a single housing. The exterior is usually made of plastic, with metal terminals for connection.\\r\\nApplications:\\r\\n9V batteries find widespread use in numerous electronic devices, ranging from small portable gadgets to household appliances. They are commonly employed in smoke detectors, handheld radios, digital cameras, remote controls, guitar pedals, and various other low-power devices where compact size and reliable power are essential.\\r\\nTechnical Specifications:\\r\\nVoltage: 9 volts (nominal)\\r\\nChemistry: Typically either alkaline, lithium, or rechargeable nickel-metal hydride (NiMH)\\r\\nCapacity: Varies depending on the chemistry and manufacturer, but typically ranges from around 400mAh to 1200mAh for alkaline, higher for lithium and NiMH.\\r\\nDimensions: Standard dimensions are approximately 48.5mm x 26.5mm x 17.5mm (length x width x height)\\r\\nTerminals: Usually features a positive (+) and negative (-) terminal for connection to devices, often in the form of snap connectors or screws.'}\n",
            "i 82\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA64BF40>, 'prompt': 'Can you make a short description about the part: Membrane Switch Module\\n\\nIt should be divided into 3 sections as follows:\\n1) Description\\n2) Applications\\n3) technical specification', 'response': 'Description:\\nA membrane switch module is a user interface technology that utilizes a thin, flexible membrane typically made of polyester or polycarbonate. This membrane contains circuitry printed with conductive inks, allowing it to function as a switch when pressure is applied to specific areas. Beneath the membrane, there are layers of adhesive and spacer materials that provide support and act as insulation between the circuits. When pressure is applied to the membrane switch, it deforms slightly, causing the conductive layers to make contact and complete a circuit, thus triggering a response.\\nApplications:\\nMembrane switch modules find wide-ranging applications across various industries due to their versatility, durability, and cost-effectiveness. They are commonly used in consumer electronics such as remote controls, microwave ovens, and control panels for appliances. Additionally, they are prevalent in industrial equipment, medical devices, automotive dashboards, and aerospace instrumentation. Their ability to withstand harsh environments, resist moisture and chemicals, and provide customizable designs make them suitable for numerous applications where traditional mechanical switches may not be ideal.\\nTechnical Specifications:\\nMaterial: Typically constructed from polyester or polycarbonate film\\nThickness: Ranges from 0.125 mm to 0.5 mm\\nConductive Elements: Printed with conductive inks such as silver or carbon\\nActuation Force: Varies depending on design, typically between 100g to 500g\\nLifecycle: Can withstand millions of actuations\\nOperating Temperature: Generally -40°C to 85°C, though variations exist depending on materials and components used\\nEnvironmental Resistance: Often resistant to moisture, chemicals, UV exposure, and extreme temperatures, depending on materials and coatings used\\nCustomization: Offers flexibility in design, including backlighting options, tactile feedback, and graphical overlays.'}\n",
            "i 83\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA4C19C0>, 'prompt': 'You have been given an IoT kit component: L293D. Give a description of the component having 3 sections as follows:\\n1) Description\\n2) Applications\\n3) Technical specifications', 'response': 'Description:\\r\\nThe L293D is a quadruple high-current half-H driver designed to control DC motors and inductive loads. It can drive two DC motors simultaneously, or one stepper motor, and offers bidirectional control for each motor. This integrated circuit (IC) contains built-in output clamping diodes for inductive load suppression, making it suitable for a variety of motor-driving applications.\\r\\nApplications:\\r\\nRobot control: The L293D is commonly used in robotics projects to control the movement of motors, enabling precise motion and direction control.\\r\\nAutomotive electronics: It can be used in automotive applications such as power window control, door lock systems, and windshield wiper control.\\r\\nIndustrial automation: The L293D is utilized in various industrial automation systems for controlling conveyor belts, lifts, and other machinery.\\r\\nDIY electronics projects: Hobbyists and DIY enthusiasts often use the L293D in their projects, such as remote-controlled cars, drones, and home automation systems.\\r\\nTechnical Specifications:\\r\\nSupply Voltage: 4.5V to 36V\\r\\nPeak Output Current (Per Channel): 600mA\\r\\nContinuous Output Current (Per Channel): 200mA\\r\\nMaximum Output Voltage: VCC\\r\\nOutput Clamp Diodes for Inductive Load Protection\\r\\nThermal Shutdown Protection\\r\\nOperating Temperature Range: 0°C to 70°C\\r\\nPackage: 16-pin DIP (Dual In-line Package) or 16-pin SOIC (Small Outline Integrated Circuit)'}\n",
            "i 84\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA64BF40>, 'prompt': 'Can you make a short description about the part: Female to male Dupont Wire\\n\\nIt should be divided into 3 sections as follows:\\n1) Description\\n2) Applications\\n3) technical specification', 'response': 'Description:\\r\\nFemale to male Dupont wire is a type of electrical cable commonly used in electronics and prototyping projects. It consists of a male connector at one end and a female connector at the other end, typically with a series of pre-crimped wires in between. These wires are housed within a flexible insulation material, such as PVC, making them easy to bend and maneuver. The male connector features pins that can be inserted into female headers, while the female connector accepts male pins, facilitating secure connections between various components on a breadboard or circuit board.\\r\\nApplications:\\r\\nThis type of wire is widely used in DIY electronics, robotics, and prototyping applications. It allows for easy and convenient connection between different components, such as microcontrollers, sensors, motors, and LEDs, without the need for soldering. Female to male Dupont wires are commonly used in projects involving Arduino, Raspberry Pi, and other development platforms, enabling rapid prototyping and experimentation. They are also useful for creating custom cables and extending connections within electronic circuits.\\r\\nTechnical Specifications:\\r\\nWire Gauge: Typically 22 AWG or 24 AWG\\r\\nLength: Available in various lengths, ranging from a few inches to several feet\\r\\nConnector Types: Standard Dupont connectors, with 2.54mm (0.1 inch) spacing between pins\\r\\nInsulation Material: PVC or similar flexible insulation\\r\\nColors: Wires may come in different colors for easy identification and organization\\r\\nCurrent Rating: Generally rated for low to moderate current applications, typically up to a few amperes\\r\\nOperating Temperature: Typically rated for a temperature range of -20°C to 80°C\\r\\nConnector Material: Brass pins with tin or gold plating for improved conductivity and corrosion resistance'}\n",
            "i 85\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFF1DEEF0>, 'prompt': 'You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: 830 Tie-Points Breadboard. Give a description of the component having 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) Technical specifications', 'response': \"Description:\\r\\nThe 830 Tie-Points Breadboard is a fundamental component in electronics prototyping and experimentation. It serves as a platform for quickly and easily connecting electronic components without the need for soldering. The breadboard consists of a plastic housing with numerous interconnected metal clips underneath the surface. These clips allow for the insertion and connection of electronic components such as resistors, capacitors, integrated circuits, and wires. It typically features multiple rows and columns of tie-points, providing ample space for building circuits of varying complexity.\\r\\nApplications:\\r\\nPrototyping: The breadboard is widely used in prototyping electronic circuits due to its versatility and ease of use. It allows engineers, hobbyists, and students to quickly test and iterate circuit designs without the need for permanent soldering.\\r\\nEducation: It is an essential tool in electronics education, providing a hands-on platform for teaching circuit theory, component functionality, and basic electronic design principles.\\r\\nRapid Development: In IoT projects, the breadboard facilitates the rapid development of prototypes for sensor interfaces, data acquisition systems, and other IoT devices. It enables quick experimentation and validation of concepts before moving to more permanent hardware solutions.\\r\\nTesting and Troubleshooting: The breadboard serves as a convenient platform for testing and troubleshooting electronic circuits. Components can be easily rearranged or replaced to diagnose issues and refine designs.\\r\\nTechnical Specifications:\\r\\nTie-Points: The 830 Tie-Points Breadboard typically offers 830 individual tie-points, providing ample space for circuit assembly.\\r\\nLayout: It features multiple rows and columns of interconnected tie-points, usually arranged in a grid pattern.\\r\\nMaterial: The breadboard is constructed from durable plastic, with metal clips or springs underneath the surface to provide electrical connections.\\r\\nConnection Method: Components are inserted into the breadboard's tie-points by simply pushing them into the desired position. The metal clips underneath establish electrical connections between adjacent tie-points.\\r\\nCompatibility: The breadboard is compatible with a wide range of electronic components, including resistors, capacitors, diodes, transistors, and integrated circuits.\\r\\nDimensions: It typically measures around 6.5 x 2.2 inches (165 x 55 mm), making it compact and portable for use in various projects.\\r\\nVoltage and Current Ratings: While the breadboard itself does not have specific voltage or current ratings, users should consider the limitations of the components being used within the circuit to avoid overloading or damaging the breadboard.\"}\n",
            "i 86\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA64BF40>, 'prompt': 'You have been given an IoT kit component: HC-SR501 PIR motion sensor module. Give a description of the component having 3 sections as follows:\\n1) Description\\n2) Applications\\n3) Technical specifications', 'response': 'Description:\\r\\nThe HC-SR501 PIR (Passive Infrared) motion sensor module is a compact electronic device designed to detect human or animal movement within its detection range. It consists of a pyroelectric sensor, which is capable of detecting changes in infrared radiation emitted by objects in its field of view. The module also includes supporting electronics for signal processing and output control. Its small size and simple design make it easy to integrate into various electronic projects.\\r\\nApplications:\\r\\nThe HC-SR501 PIR motion sensor module finds applications in a wide range of projects and systems, including:\\r\\nSecurity systems: It can be used to trigger alarms or activate surveillance cameras in response to detected motion.\\r\\nHome automation: It enables automated lighting control, turning on lights when motion is detected and turning them off after a period of inactivity.\\r\\nEnergy conservation: It helps conserve energy by automatically turning off lights or appliances when no motion is detected in a room.\\r\\nInteractive installations: It can be used in interactive art installations or exhibits to detect the presence of viewers and trigger audiovisual effects.\\r\\nWildlife monitoring: It can be deployed in outdoor settings to monitor wildlife activity and behavior.\\r\\nTechnical Specifications:\\r\\nOperating voltage: Typically operates at 5V DC, although some modules may support a wider voltage range.\\r\\nDetection range: Adjustable detection range, typically up to several meters.\\r\\nDetection angle: Wide-angle detection, typically ranging from 90 to 120 degrees.\\r\\nOutput: Digital output signal (usually HIGH or LOW) indicating the presence or absence of motion.\\r\\nSensitivity adjustment: Some modules feature a potentiometer for adjusting sensitivity to motion detection.\\r\\nOperating temperature: Generally operates within a temperature range of -20°C to 70°C.\\r\\nDimensions: Compact size, typically around 32mm x 24mm.'}\n",
            "i 87\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA4C2CE0>, 'prompt': 'You have been given an IoT kit component: Photoresistor (photocell). Give a description of the component having 3 sections as follows:\\n1) Description\\n2) Applications\\n3) Technical specifications', 'response': \"Description:\\r\\nA photoresistor, also known as a photocell or light-dependent resistor (LDR), is a type of resistor whose resistance varies based on the intensity of light it is exposed to. It is made of a semiconductor material whose conductivity increases when exposed to light and decreases in darkness. The resistance of a photoresistor decreases with increasing light intensity and increases with decreasing light intensity.\\r\\nApplications:\\r\\nPhotoresistors find various applications in electronic circuits, sensing systems, and IoT projects where the detection of light intensity is required. Some common applications include:\\r\\nAutomatic outdoor lighting systems: Photoresistors can be used to automatically turn on outdoor lights when it gets dark and turn them off when it gets bright.\\r\\nBurglar alarms: They can be employed in security systems to detect sudden changes in light intensity caused by an intruder.\\r\\nSolar panels: Photoresistors are used in solar panels to track the position of the sun and optimize solar energy collection.\\r\\nPhotography: In cameras, they can be used to adjust exposure settings automatically based on ambient light conditions.\\r\\nTechnical specifications:\\r\\nResistance Range: Typically ranges from a few hundred ohms to several megaohms, depending on the intensity of light.\\r\\nDark Resistance: The resistance of the photoresistor in darkness. It's usually in the range of megaohms.\\r\\nLight Resistance: The resistance of the photoresistor when exposed to bright light. It's typically in the range of hundreds of ohms to a few kiloohms.\\r\\nResponse Time: The time it takes for the photoresistor to change its resistance after a change in light intensity. It's usually in the milliseconds range.\\r\\nSpectral Response: Photoresistors have a specific spectral response, meaning they are sensitive to certain wavelengths of light more than others. This sensitivity varies based on the material composition of the photoresistor.\"}\n",
            "i 88\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA64BF40>, 'prompt': 'Can you make a short description about the part: Passive Buzzer\\n\\nIt should be divided into 3 sections as follows:\\n1) Description\\n2) Applications\\n3) technical specification', 'response': 'Description:\\r\\nA passive buzzer is an electronic component that produces sound when an electric signal is applied to it. It consists of a piezoelectric element housed in a small casing. Unlike an active buzzer, a passive buzzer requires an external signal to produce sound and does not have an internal oscillator. When a voltage is applied, the piezoelectric element vibrates, generating audible sound waves.\\r\\nApplications:\\r\\nPassive buzzers find applications in various electronic devices and projects where audio feedback or alerts are required. Some common applications include:\\r\\nAlarm systems: Passive buzzers are used in security systems, smoke detectors, and burglar alarms to indicate emergencies.\\r\\nElectronic appliances: They are used in kitchen appliances, such as microwave ovens and rice cookers, to indicate the end of a cycle or an error condition.\\r\\nDIY projects: Hobbyists and makers use passive buzzers in projects such as timers, games, and musical instruments for generating sound effects and melodies.\\r\\nTechnical Specification:\\r\\nOperating Voltage: Typically operates within a voltage range of 3V to 12V, depending on the specific model.\\r\\nFrequency Range: The frequency of sound produced depends on the design and construction of the buzzer but typically ranges from a few hundred Hertz to several kilohertz.\\r\\nSound Output: The sound intensity or loudness is measured in decibels (dB) and varies among different models. Typical sound output ranges from 70dB to 100dB.\\r\\nSize and Form Factor: Passive buzzers come in various sizes and shapes, including cylindrical, rectangular, and square, to suit different applications and mounting requirements.\\r\\nConstruction: Usually constructed with a plastic or metal casing to protect the piezoelectric element and provide mechanical stability. Some buzzers may also include mounting holes or pins for easy installation onto PCBs or enclosures.'}\n",
            "i 89\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFF32E890>, 'prompt': 'Can you make a short description about the part: 4 Digit 7-segment Display\\r\\n\\r\\nIt should be divided into 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) technical specification', 'response': 'Description:\\r\\nA 4 Digit 7-segment display is a common electronic component used to visually represent numerical information. It consists of four individual 7-segment displays arranged in a single unit, with each segment capable of displaying numerical digits from 0 to 9. These displays utilize a combination of illuminated segments to create numbers, letters, and other characters. Each segment is typically controlled by its own input signal, allowing for the independent display of different numbers on each digit.\\r\\nApplications:\\r\\nDigital Clocks and Timers: 4 Digit 7-segment displays are commonly used in digital clocks and timers to display the current time or countdowns.\\r\\nCounters and Measurement Devices: They are used in various electronic counters and measurement devices to display numerical data such as counts, readings, or measurements.\\r\\nInstrument Panels: In automotive and industrial settings, these displays find applications in instrument panels for displaying information like speed, temperature, or voltage.\\r\\nConsumer Electronics: They are also used in consumer electronics such as microwave ovens, calculators, and digital meters.\\r\\nInformation Displays: In public transportation systems, they are used to display information like bus numbers, departure times, and platform numbers.\\r\\nTechnical Specifications:\\r\\nDigit Count: 4 digits.\\r\\nSegment Type: 7-segment display (each digit contains 7 segments).\\r\\nInput Interface: Typically driven by microcontrollers or dedicated display drivers.\\r\\nOperating Voltage: Usually operates within the range of 3V to 5V.\\r\\nSegment Material: LEDs (Light Emitting Diodes) are commonly used for segment illumination.\\r\\nSize: Available in various sizes ranging from small, compact displays to larger, more visible ones.\\r\\nBrightness and Color: Brightness levels and color options (such as red, green, blue) may vary depending on the specific model and manufacturer.\\r\\nMounting Options: Can be mounted on PCBs (Printed Circuit Boards) or used in standalone configurations.'}\n",
            "i 90\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA64BF40>, 'prompt': 'You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: DHT11 temperature and humidity module. Give a description of the component having 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) Technical specifications', 'response': 'Description:\\r\\nThe DHT11 temperature and humidity module is a compact sensor module designed to measure both temperature and humidity levels in the surrounding environment. It integrates a DHT11 sensor chip, which comprises a capacitive humidity sensor and a thermistor to detect temperature. This module typically comes with a small PCB board featuring the sensor, along with necessary components for signal conditioning and communication.\\r\\nApplications:\\r\\nThe DHT11 module finds widespread applications across various industries and projects where monitoring environmental conditions is crucial. Some common applications include:\\r\\nHome automation systems: Integrating the DHT11 module allows for monitoring and controlling indoor climate conditions such as temperature and humidity.\\r\\nWeather stations: It can be used to collect data for weather monitoring and analysis, providing insights into local climate patterns.\\r\\nAgricultural monitoring: Farmers can utilize the DHT11 module to monitor temperature and humidity levels in greenhouses, helping to optimize growing conditions for crops.\\r\\nHVAC (Heating, Ventilation, and Air Conditioning) systems: The module can be incorporated into HVAC systems to ensure optimal indoor air quality and comfort.\\r\\nIndustrial process control: In industrial settings, the DHT11 module can be employed for monitoring environmental conditions in manufacturing processes, storage facilities, and more.\\r\\nTechnical Specifications:\\r\\nTemperature range: 0°C to 50°C (32°F to 122°F)\\r\\nHumidity range: 20% to 90% RH (Relative Humidity)\\r\\nAccuracy:\\r\\nTemperature: ±2°C\\r\\nHumidity: ±5% RH\\r\\nResolution:\\r\\nTemperature: 1°C\\r\\nHumidity: 1% RH\\r\\nOperating voltage: 3.3V to 5V DC\\r\\nCurrent consumption: 2.5mA max during conversion\\r\\nCommunication protocol: Single-wire digital interface\\r\\nDimensions: Typically small, around 15mm x 12mm, depending on the module design.\\r\\nOutput: Digital signal outputting temperature and humidity data in a serial format, typically compatible with microcontrollers like Arduino, Raspberry Pi, etc.'}\n",
            "i 91\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA4C2CE0>, 'prompt': 'Can you make a short description about the part: USB A to Micro B\\n\\nIt should be divided into 3 sections as follows:\\n1) Description\\n2) Applications\\n3) technical specification', 'response': 'Description:\\nThe USB A to Micro B cable is a commonly used connectivity solution in modern electronics. It features a USB Type-A connector on one end and a Micro USB Type-B connector on the other. The Type-A connector is typically found on computers, chargers, and power adapters, while the Micro Type-B connector is commonly used in smartphones, tablets, digital cameras, and other portable devices.\\nApplications:\\nThis cable is versatile and finds application in various scenarios. It is frequently used for charging and data transfer between devices such as smartphones, tablets, digital cameras, external hard drives, and more. Additionally, it can be used to connect peripherals like keyboards, mice, and game controllers to compatible devices.\\nTechnical Specifications:\\nThe USB A to Micro B cable typically supports USB 2.0 or USB 3.0 standards, providing data transfer speeds of up to 480 Mbps or 5 Gbps respectively. The cable is designed to deliver power and data simultaneously, making it suitable for charging devices while transferring data. It is constructed with durable materials to ensure longevity and reliable performance. The connectors are designed for repeated use, with a snug fit to prevent accidental disconnection during operation. Additionally, the cable may come in various lengths to accommodate different setups and requirements.'}\n",
            "i 92\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFF1DEEF0>, 'prompt': 'You have been given an IoT kit component: Fan Blade for 3-6V motor. Give a description of the component having 3 sections as follows:\\n1) Description\\n2) Applications\\n3) Technical specifications', 'response': 'Description:\\r\\nThe fan blade for a 3-6V motor is a small, lightweight component designed to be attached to a motor shaft. It typically consists of multiple blades arranged in a radial pattern around a central hub. These blades are often made of plastic or lightweight metal to minimize weight and maximize airflow efficiency. The hub of the fan blade usually has a central mounting hole or adapter that allows it to be securely attached to the shaft of a compatible motor.\\r\\nApplications:\\r\\nThis component is commonly used in various applications where airflow or cooling is required. Some typical applications include:\\r\\nElectronic devices: It can be used to provide cooling for components such as microcontrollers, processors, or power supply units in electronic devices.\\r\\nRobotics: It can be incorporated into robotic projects to provide airflow for cooling motors or other components.\\r\\nHVAC (Heating, Ventilation, and Air Conditioning) systems: It can be used in small-scale HVAC systems or prototypes to assist with air circulation.\\r\\nPersonal projects: Hobbyists and DIY enthusiasts often use these fan blades in custom projects such as miniature fans, air purifiers, or even small wind turbines.\\r\\nTechnical specifications:\\r\\nVoltage range: 3-6V (compatible with motors operating within this voltage range)\\r\\nMaterial: Typically made of lightweight plastic or metal\\r\\nBlade count: The number of blades can vary, with common configurations ranging from 2 to 6 blades.\\r\\nDiameter: The diameter of the fan blade determines the airflow capacity and compatibility with different motor sizes. Typical diameters range from a few centimeters to several inches.\\r\\nMounting: The fan blade is designed to be easily mounted onto the shaft of a compatible motor using a central mounting hole or adapter.\\r\\nRotation direction: The fan blade can be designed to rotate either clockwise or counterclockwise, depending on the specific requirements of the application.'}\n",
            "i 93\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA4C2D10>, 'prompt': 'You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: RGB LED. Give a description of the component having 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) Technical specifications', 'response': \"Description:\\r\\nAn RGB LED, short for Red-Green-Blue Light Emitting Diode, is a compact electronic component that integrates three individual LEDs into a single package. Each LED within the RGB LED emits light of a specific color: red, green, or blue. By controlling the intensity of each color component, a wide range of colors can be produced, allowing for vibrant and customizable lighting effects. RGB LEDs are commonly encapsulated in a clear or diffused plastic housing, making them suitable for various electronic projects and applications.\\r\\nApplications:\\r\\nDecorative Lighting: RGB LEDs are extensively used in decorative lighting applications, such as home ambiance lighting, architectural lighting, and themed displays. Their ability to generate a spectrum of colors enables dynamic and visually appealing lighting effects.\\r\\nEntertainment Systems: RGB LEDs are integral components in entertainment systems, including gaming peripherals, stage lighting, and mood lighting for parties or events. They can be synchronized with audio or video cues to create immersive experiences.\\r\\nSignage and Advertisement: RGB LEDs are utilized in signage and advertisement displays to attract attention and convey messages effectively. Their versatility in color rendering allows for eye-catching and attention-grabbing visuals.\\r\\nIoT and Smart Home Devices: RGB LEDs are incorporated into IoT devices and smart home systems for status indication, visual alerts, and mood enhancement. They can be controlled remotely via smartphone apps or integrated into home automation systems for seamless integration with other devices.\\r\\nTechnical Specifications:\\r\\nForward Voltage (Vf): Typically around 2.0-2.5 volts for each LED (red, green, blue).\\r\\nForward Current (If): Varies based on the specific LED and desired brightness, often in the range of 5-20 milliamps.\\r\\nOperating Voltage: Typically compatible with common voltage levels used in electronic circuits, such as 3.3 volts or 5 volts.\\r\\nPower Consumption: Depends on the operating current and voltage, usually a few hundred milliwatts to a couple of watts for full brightness operation.\\r\\nControl Interface: RGB LEDs can be controlled using various methods, including analog voltage levels for each color channel, digital PWM (Pulse Width Modulation) signals, or through dedicated LED driver ICs.\\r\\nPackage Type: Common package types include through-hole (e.g., 5mm or 10mm diameter) or surface-mount packages (e.g., 3528 or 5050 SMD packages).\\r\\nViewing Angle: The angle over which the emitted light is visible, typically ranging from 90 to 120 degrees, influencing the LED's light distribution characteristics.\\r\\nLifetime: RGB LEDs generally have a long operational lifespan, often rated for tens of thousands of hours of continuous use, depending on operating conditions and quality of construction.\"}\n",
            "i 94\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA6BE4A0>, 'prompt': 'You have been given an IoT kit component: HiLetgo GY-521 module. Give a description of the component having 3 sections as follows:\\n1) Description\\n2) Applications\\n3) Technical specifications', 'response': \"Description:\\r\\nThe HiLetgo GY-521 module is a compact and versatile sensor module designed for use in various Internet of Things (IoT) projects. It features an integrated MPU-6050 sensor chip, which combines a 3-axis gyroscope and a 3-axis accelerometer, allowing for precise motion sensing and orientation detection. The module also includes an onboard voltage regulator and level-shifting circuitry, making it compatible with both 3.3V and 5V microcontrollers. It communicates with the host microcontroller via the I2C interface, making it easy to integrate into existing projects.\\r\\nApplications:\\r\\nMotion tracking and gesture recognition: The module's gyroscope and accelerometer capabilities make it ideal for detecting and tracking motion, enabling applications such as gesture-controlled interfaces and virtual reality systems.\\r\\nInertial measurement units (IMUs): It can be used as part of an IMU for applications such as robotics, drones, and wearable devices, providing accurate orientation and motion data.\\r\\nVehicle tracking and stabilization: The module's motion sensing capabilities make it suitable for applications requiring vehicle tracking and stabilization, such as unmanned aerial vehicles (UAVs) and autonomous vehicles.\\r\\nGaming peripherals: It can be used to develop gaming peripherals such as motion-sensitive controllers and input devices, adding an extra dimension of interaction to gaming experiences.\\r\\nTechnical specifications:\\r\\nIntegrated MPU-6050 sensor chip\\r\\n3-axis gyroscope with programmable full-scale range (±250, ±500, ±1000, or ±2000 degrees per second)\\r\\n3-axis accelerometer with programmable full-scale range (±2g, ±4g, ±8g, or ±16g)\\r\\nOnboard voltage regulator and level-shifting circuitry for compatibility with 3.3V and 5V microcontrollers\\r\\nCommunication interface: I2C (TWI) digital interface\\r\\nOperating voltage: 3V to 5V\\r\\nDimensions: Approximately 21mm x 16mm\"}\n",
            "i 95\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFB839FF0>, 'prompt': 'You have been given an IoT kit component: Tilt Ball Switch. Give a description of the component having 3 sections as follows:\\n1) Description\\n2) Applications\\n3) Technical specifications', 'response': \"Description:\\r\\nThe Tilt Ball Switch is a simple electronic component that consists of a small metal ball inside a tube with two contacts at the ends. When the device is tilted or moved, the ball rolls to one end of the tube, making contact with one of the contacts and completing the circuit. When the device is upright or at rest, the ball rests in the center, breaking the circuit.\\r\\nApplications:\\r\\nMotion detection: The Tilt Ball Switch can be used to detect motion or orientation changes in various applications such as security systems, alarms, or interactive toys.\\r\\nVehicle security: It can be integrated into vehicle security systems to detect unauthorized movement or towing.\\r\\nGaming and toys: The switch can be incorporated into gaming controllers or toys to detect tilting or shaking actions for interactive gameplay.\\r\\nTechnical Specifications:\\r\\nContact Rating: The switch typically supports low voltage and current applications, often ranging from a few volts to around 12 volts and currents up to a few milliamps.\\r\\nOperating Angle: Depending on the design, the tilt angle required to trigger the switch can vary, but it's typically within a range of 10 to 30 degrees.\\r\\nContact Resistance: The resistance across the contacts when the switch is closed is usually low, typically in the range of a few ohms.\\r\\nDurability: The durability of the switch depends on the quality of construction and materials used, but it's generally designed to withstand multiple tilting cycles without failure.\\r\\nMounting: The switch can be mounted on a PCB (Printed Circuit Board) or other surfaces using soldering or adhesive methods, depending on the application requirements.\"}\n",
            "i 96\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA64BEB0>, 'prompt': 'You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: Breadboard Jumper Wire. Give a description of the component having 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) Technical specifications', 'response': \"Description:\\r\\nA breadboard jumper wire is an essential component in prototyping electronic circuits on breadboards. Typically, it consists of a flexible insulated wire with connectors at both ends. These connectors are designed to easily plug into the holes of a breadboard, establishing electrical connections between different points on the board. Breadboard jumper wires come in various lengths and colors, allowing for organized and efficient circuit building.\\r\\nApplications:\\r\\nPrototyping Circuits: Breadboard jumper wires are commonly used by electronics enthusiasts, hobbyists, and professionals alike for prototyping circuits. They enable the creation of temporary connections between components on a breadboard, facilitating the testing and design of electronic systems before permanent assembly.\\r\\nEducational Purposes: These wires are extensively utilized in educational settings such as classrooms and workshops to teach electronics and circuit design principles. They provide a hands-on approach to learning, allowing students to experiment with different circuit configurations and understand concepts like circuitry, connectivity, and component interaction.\\r\\nRapid Prototyping: Breadboard jumper wires play a crucial role in the rapid prototyping of IoT devices, sensors, and other electronic gadgets. They enable quick iterations and modifications during the development phase, helping engineers and designers bring their ideas to life faster and more efficiently.\\r\\nDIY Projects: From simple LED blinkers to complex robotics projects, breadboard jumper wires are a staple in various do-it-yourself (DIY) electronics projects. Makers and tinkerers leverage these wires to create custom electronic systems tailored to their specific needs and interests.\\r\\nTechnical Specifications:\\r\\nWire Gauge: Typically, breadboard jumper wires come with a standard wire gauge ranging from 22 AWG to 28 AWG, with 22 AWG being the most common. The gauge affects the wire's thickness and current-carrying capacity.\\r\\nLength: Breadboard jumper wires are available in various lengths, commonly ranging from a few centimeters to several inches. Longer wires provide flexibility in circuit layout, while shorter wires minimize clutter and improve organization.\\r\\nConnectors: The connectors at each end of the wire are designed to fit snugly into the holes of a breadboard. They are usually made of metal and may feature insulation or protective coatings to prevent short circuits.\\r\\nInsulation: The wire is insulated to prevent short circuits and ensure reliable electrical connections. Common insulation materials include PVC (polyvinyl chloride) and silicone, providing flexibility and durability.\\r\\nColor Coding: Breadboard jumper wires often come in multiple colors, allowing for easy identification and organization of connections within a circuit. Color coding helps users distinguish between different signals, power sources, and ground connections.\"}\n",
            "i 97\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA6BE4A0>, 'prompt': 'You have been given an IoT kit component: 104 pF ceramic capacitor. Give a description of the component having 3 sections as follows:\\n1) Description\\n2) Applications\\n3) Technical specifications', 'response': 'Description:\\r\\nA 104 pF ceramic capacitor is a type of electronic component used in circuits for its capacitance properties. It is typically small in size and cylindrical or rectangular in shape. The \"104\" designation indicates its capacitance value, where the first two digits represent the significant figures (10) and the third digit represents the multiplier (4), resulting in a capacitance of 1000 picofarads, or 104 pF.\\r\\nApplications:\\r\\nCoupling and decoupling: Ceramic capacitors are commonly used for coupling and decoupling purposes in electronic circuits, helping to stabilize voltage levels and filter out noise.\\r\\nRF circuits: Due to their high-frequency characteristics and low parasitic effects, ceramic capacitors are often used in radio frequency (RF) circuits, such as in antennas, oscillators, and filters.\\r\\nTiming circuits: In combination with resistors, ceramic capacitors can be used in timing circuits for generating precise time delays or oscillations.\\r\\nBypassing: Ceramic capacitors are employed for bypassing or shunting high-frequency signals to ground in order to prevent them from interfering with sensitive components in a circuit.\\r\\nTechnical Specifications:\\r\\nCapacitance: 104 pF (1000 picofarads)\\r\\nTolerance: Typically around ±10% or better, indicating the range within which the actual capacitance may vary from the specified value.\\r\\nVoltage rating: The maximum voltage that the capacitor can safely withstand without breaking down. This could range from a few volts to several hundred volts depending on the specific capacitor and its intended application.\\r\\nDielectric material: Ceramic capacitors use ceramic materials as their dielectric, providing stability, reliability, and high capacitance density.\\r\\nPackage type: Surface mount (SMD) or through-hole, depending on the specific application and manufacturing requirements.'}\n",
            "i 98\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA4C2CE0>, 'prompt': 'You have been given an IoT kit component: USB A to Micro B. Give a description of the component having 3 sections as follows:\\n1) Description\\n2) Applications\\n3) Technical specifications', 'response': 'Description:\\r\\nThe USB A to Micro B cable is a connector cable commonly used in the realm of Internet of Things (IoT) devices. It features a USB Type-A connector on one end and a Micro USB Type-B connector on the other end. The USB Type-A connector is typically plugged into a power source or a host device such as a computer, while the Micro USB Type-B connector is inserted into the IoT device or peripheral.\\r\\nApplications:\\r\\nThis cable serves a variety of applications in IoT setups:\\r\\nPowering IoT devices: It can be used to provide power to small IoT devices such as sensors, microcontrollers, and development boards.\\r\\nData transfer: It facilitates data transfer between IoT devices and host systems, allowing for firmware updates, data logging, and communication with cloud services.\\r\\nProgramming and debugging: Developers often use this cable to connect IoT development boards to their computers for programming and debugging purposes.\\r\\nTechnical Specifications:\\r\\nConnector 1: USB Type-A male\\r\\nConnector 2: Micro USB Type-B male\\r\\nCable Length: Typically available in various lengths ranging from 1 to 3 meters\\r\\nCompatibility: Compatible with a wide range of IoT devices, development boards, and host systems\\r\\nData Transfer Speed: Supports USB 2.0 standards for data transfer speeds up to 480 Mbps\\r\\nPower Rating: Capable of delivering power up to 2.5 watts (5 volts at 500 milliamps), suitable for low-power IoT devices'}\n",
            "i 99\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFF1DEEF0>, 'prompt': 'You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: Ultrasonic Sensor. Give a description of the component having 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) Technical specifications', 'response': 'Description:\\r\\nThe ultrasonic sensor is a versatile component commonly used in IoT projects and robotics. It operates by emitting high-frequency sound waves (ultrasonic waves) and measuring the time it takes for the waves to bounce back after hitting an object. This time difference helps determine the distance between the sensor and the object in front of it. Most ultrasonic sensors consist of a transmitter, a receiver, and a control circuit.\\r\\nApplications:\\r\\nDistance Measurement: One of the primary applications of ultrasonic sensors is to measure the distance between the sensor and an object accurately. This functionality finds applications in automated parking systems, obstacle detection in robotics, and industrial automation.\\r\\nObject Detection and Avoidance: Ultrasonic sensors are widely used in robotics and IoT devices to detect objects in their path and take appropriate actions to avoid collisions. This is useful in autonomous vehicles, drones, and smart appliances.\\r\\nLiquid Level Measurement: Ultrasonic sensors can also be used to measure the level of liquids in tanks or containers without the need for physical contact. This is valuable in industrial processes, agriculture, and smart home systems.\\r\\nProximity Sensing: Ultrasonic sensors can detect the presence of objects within a certain range without physical contact, making them suitable for applications such as automatic doors, hand sanitizer dispensers, and touchless faucets.\\r\\nTechnical Specifications:\\r\\nOperating Frequency: Typically operates at frequencies between 20 kHz to 200 kHz.\\r\\nDetection Range: Can detect objects within a range of a few centimeters to several meters, depending on the sensor model.\\r\\nPower Supply: Generally operates on low voltage DC power supply, commonly 5V or 3.3V.\\r\\nOutput Interface: Provides digital or analog output signals depending on the model. Digital output indicates the presence or absence of an object within the detection range, while analog output provides distance information.\\r\\nResolution: The resolution of ultrasonic sensors varies but is typically in the range of millimeters.\\r\\nBeam Angle: The angle of the ultrasonic beam emitted by the sensor determines its field of view. Common beam angles range from 15 to 60 degrees.\\r\\nEnvironmental Considerations: Some ultrasonic sensors may have IP-rated enclosures for protection against dust and water, making them suitable for outdoor or harsh industrial environments.'}\n",
            "i 100\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA64BE20>, 'prompt': 'Can you make a short description about the part: ELEGOO DS1307 RTC Module\\r\\n\\r\\nIt should be divided into 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) technical specification', 'response': 'Description:\\nThe ELEGOO DS1307 RTC (Real-Time Clock) Module is a compact and versatile electronic component designed to accurately keep track of time, date, and day of the week. It utilizes the DS1307 RTC chip, which is widely used for its reliability and precision in timekeeping applications. The module features a small form factor and can be easily integrated into various electronic projects, providing accurate timekeeping functionality.\\nApplications:\\nThe ELEGOO DS1307 RTC Module finds applications in a wide range of projects where precise timekeeping is essential. Some common applications include:\\nDigital clocks and watches\\nData logging systems\\nTimers and scheduling devices\\nAlarm systems\\nIoT (Internet of Things) projects\\nEmbedded systems requiring time-based functionality\\nAutomotive applications such as onboard clocks and event logging\\nTechnical Specification:\\nChipset: DS1307 RTC\\nOperating Voltage: 5V\\nI2C Interface for communication with microcontrollers\\nReal-time clock counts seconds, minutes, hours, date of the month, month, day of the week, and year\\nBattery backup for maintaining timekeeping in case of power loss\\n56-byte, battery-backed, nonvolatile (NV) RAM for storing data\\nAccuracy: ±2ppm from 0°C to +40°C\\nLow power consumption: typically 0.5μA in battery backup mode\\nCompact size for easy integration into projects: dimensions typically around 27mm x 28mm'}\n",
            "i 101\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFB839FF0>, 'prompt': 'You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: Membrane Switch Module. Give a description of the component having 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) Technical specifications', 'response': \"Description:\\r\\nA Membrane Switch Module is a type of user interface component commonly used in electronic devices. It consists of thin, flexible layers of polyester or polycarbonate materials sandwiched together to form a switch mechanism. These layers typically include a graphic overlay, a spacer layer, and a conductive membrane layer. The graphic overlay is where the user interacts, featuring printed symbols or icons corresponding to various functions. Beneath it, the spacer layer provides cushioning and separation between the graphic overlay and the conductive membrane layer. The conductive membrane layer contains circuitry, usually in the form of conductive ink or metal traces, which act as the switch contacts. When pressure is applied to the graphic overlay, it deforms the membrane, causing the conductive traces to make contact, thus completing an electrical circuit.\\r\\nApplications:\\r\\nMembrane Switch Modules find widespread applications in various industries due to their versatility and reliability. Some common applications include:\\r\\nConsumer electronics: Used in devices like remote controls, calculators, and kitchen appliances for user input.\\r\\nIndustrial controls: Employed in control panels and machinery interfaces for operator input and control.\\r\\nMedical devices: Integrated into medical equipment such as diagnostic instruments and patient monitoring systems.\\r\\nAutomotive: Found in car dashboard controls, steering wheel buttons, and other automotive interfaces for user interaction.\\r\\nAerospace: Utilized in cockpit controls and aircraft instrumentation for pilot input.\\r\\nTechnical Specifications:\\r\\nOperating Voltage: Typically compatible with low-voltage DC circuits, ranging from 3V to 24V.\\r\\nActuation Force: The force required to activate the switch typically ranges from 50g to 300g, depending on the design.\\r\\nLifespan: Membrane switches typically have a long lifespan, rated for tens of thousands to millions of actuations.\\r\\nEnvironmental Resistance: Many membrane switches are designed to withstand harsh environments, offering resistance to moisture, dust, and chemicals.\\r\\nCustomization Options: Graphic overlays can be customized with various colors, textures, and embossed features to meet specific design requirements.\\r\\nInterface Options: Can be designed with different types of interfaces, including single-button, keypad, or multi-switch arrays, depending on the application's needs.\\r\\nSize and Form Factor: Available in various sizes and shapes to accommodate different device designs and layouts.\\r\\nIntegration: Can be easily integrated into existing electronic systems using standard connection methods such as soldering or connectors.\"}\n",
            "i 102\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA4C2CE0>, 'prompt': 'Can you make a short description about the part: Thermistor\\r\\n\\r\\nIt should be divided into 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) technical specification', 'response': 'Description:\\r\\nA thermistor is a type of resistor whose electrical resistance varies significantly with temperature. The word \"thermistor\" is a portmanteau of \"thermal\" and \"resistor.\" Thermistors are made from semiconductor materials, typically metal oxides, and their resistance decreases as temperature rises (negative temperature coefficient or NTC) or increases as temperature rises (positive temperature coefficient or PTC).\\r\\nApplications:\\r\\nThermistors find wide applications in temperature sensing and control. They are commonly used in temperature measurement devices like thermostats, HVAC systems, medical equipment, and automotive applications. Thermistors are also utilized in overcurrent protection circuits, where their resistance change due to temperature can help regulate current flow.\\r\\nTechnical Specifications:\\r\\nThe technical specifications of a thermistor include its resistance-temperature characteristics, which are described by parameters like resistance at a specific temperature, tolerance, and thermal time constant. Thermistors are available in various shapes and sizes, with different resistance values and temperature ranges to suit different applications. The choice of thermistor type (NTC or PTC) depends on the specific requirements of the application, such as whether a decrease or increase in resistance with temperature change is desired. Additionally, factors such as stability, response time, and operating temperature range are crucial considerations in selecting the appropriate thermistor for a particular application.'}\n",
            "i 103\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA64BE20>, 'prompt': 'You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: Fan Blade for 3-6V motor. Give a description of the component having 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) Technical specifications', 'response': 'Description:\\r\\nThe fan blade for a 3-6V motor is a crucial component designed for efficient air circulation in various electronic devices. Crafted from durable materials like ABS plastic or lightweight metals, it boasts a balanced design to minimize vibration and noise during operation. Typically featuring a sleek, aerodynamic profile, it ensures optimal airflow while maintaining a compact form factor.\\r\\nApplications:\\r\\nThis fan blade finds versatile applications across numerous IoT and hardware projects, including but not limited to:\\r\\nElectronic cooling systems: Ideal for regulating temperature in IoT devices, microcontrollers, and small-scale electronic circuits.\\r\\nVentilation in enclosures: Essential for maintaining optimal conditions within enclosures housing sensitive electronic components, such as microcontrollers, sensors, and communication modules.\\r\\nPersonal computing: Used in DIY projects involving single-board computers like Raspberry Pi or Arduino to enhance heat dissipation and prevent overheating.\\r\\nHome automation: Integrated into smart home systems to facilitate airflow control in areas like automated HVAC systems, climate-controlled cabinets, and electronic equipment racks.\\r\\nRobotics: Employed in robotic designs to cool down motors, controllers, and other electronic components during extended operation or under heavy loads.\\r\\nTechnical specifications:\\r\\nOperating Voltage: 3-6V DC\\r\\nMaterial: ABS plastic or lightweight metal\\r\\nBlade Count: Typically 3-5 blades, optimized for balanced airflow and reduced noise.\\r\\nDimensions: Varies depending on the specific model, but generally compact to fit within constrained spaces.\\r\\nMounting: Designed for easy attachment to standard motor shafts, often utilizing set screws or snap-on mechanisms for secure installation.\\r\\nAirflow: Optimized blade design for efficient air circulation while minimizing power consumption.\\r\\nNoise Level: Low vibration and noise output, suitable for noise-sensitive environments.\\r\\nCompatibility: Compatible with a wide range of small DC motors operating within the specified voltage range.\\r\\nSafety: Constructed with safety in mind, featuring smooth edges and durable construction to prevent injury during handling and operation.'}\n",
            "i 104\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA4C2B00>, 'prompt': 'You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: RC522 RFID Module. Give a description of the component having 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) Technical specifications', 'response': 'Description:\\r\\nThe RC522 RFID Module is a compact and versatile electronic component designed for Radio-Frequency Identification (RFID) applications. It integrates an RFID reader and a matching antenna, enabling it to communicate wirelessly with RFID tags or cards within its operational range. This module operates on the principle of electromagnetic induction, where it generates an electromagnetic field to power up passive RFID tags and read their stored data.\\r\\nApplications:\\r\\nThe RC522 RFID Module finds widespread use in various IoT (Internet of Things) and embedded systems applications due to its simplicity, reliability, and cost-effectiveness. Some common applications include:\\r\\nAccess Control Systems: It can be used to control access to buildings, rooms, or restricted areas by authenticating RFID cards or tags.\\r\\nInventory Management: The module facilitates inventory tracking and management in warehouses, retail stores, and logistics operations by associating RFID tags with items.\\r\\nAttendance Systems: In educational institutions or workplaces, it can automate attendance tracking processes by scanning RFID-enabled ID cards.\\r\\nAsset Tracking: The module enables real-time tracking and monitoring of valuable assets, such as equipment, vehicles, or tools, by attaching RFID tags to them.\\r\\nSmart Locks: It can be integrated into smart lock systems to provide keyless entry using RFID cards or fobs.\\r\\nPayment Systems: The module is utilized in contactless payment systems, where RFID cards or mobile devices with NFC capabilities are used for transactions.\\r\\nTechnical Specifications:\\r\\nOperating Frequency: 13.56 MHz\\r\\nCommunication Interface: SPI (Serial Peripheral Interface)\\r\\nOperating Voltage: 3.3V\\r\\nOperating Current: < 13mA\\r\\nStandby Current: < 70μA\\r\\nReading Distance: Up to 3cm (depending on the antenna design and RFID tag characteristics)\\r\\nSupported RFID Tags: ISO14443A compatible tags (MIFARE Classic, MIFARE Ultralight, etc.)\\r\\nDimensions: Approximately 60mm x 40mm'}\n",
            "i 105\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA64BEB0>, 'prompt': 'Can you make a short description about the part: Active Buzzer\\n\\nIt should be divided into 3 sections as follows:\\n1) Description\\n2) Applications\\n3) technical specification', 'response': 'Description:\\r\\nAn Active Buzzer is an electronic device that generates audible sound when powered. Unlike passive buzzers, which rely on an external frequency source to produce sound, active buzzers have an integrated oscillator circuit, making them self-contained sound-generating components. When powered, the internal oscillator produces a specific frequency, causing the buzzer to emit a continuous or intermittent sound, depending on the design.\\r\\nApplications:\\r\\nActive buzzers find applications in various electronic projects and devices where audible alerts, notifications, or alarms are required. Some common applications include:\\r\\nAlarm systems\\r\\nTimer circuits\\r\\nReminder systems\\r\\nDoorbells\\r\\nAutomotive electronics (e.g., reverse parking sensors)\\r\\nHome automation projects\\r\\nDIY electronics projects requiring audio feedback\\r\\nTechnical Specifications:\\r\\nOperating Voltage: Typically 3V to 12V DC\\r\\nSound Output: Typically ranges from 70dB to 120dB\\r\\nOperating Current: Varies based on the model, typically in the range of 5mA to 30mA\\r\\nFrequency: Fixed frequency determined by the internal oscillator circuit, commonly between 2kHz to 5kHz\\r\\nConstruction: Compact and often encapsulated in a plastic housing with two wire leads for connection to a power source.'}\n",
            "i 106\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFF1DF5E0>, 'prompt': 'You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: Active Buzzer. Give a description of the component having 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) Technical specifications', 'response': 'Description:\\r\\nAn active buzzer is an electronic component that produces an audible sound when an electrical signal is applied to it. Unlike a passive buzzer, which requires an external oscillation circuit to produce sound, an active buzzer has an internal oscillator circuit, making it easier to use in various applications. Typically, it consists of a piezoelectric transducer that converts electrical energy into mechanical vibrations, creating sound waves.\\r\\nApplications:\\r\\nActive buzzers find applications in a wide range of electronic devices and systems where audible alerts or notifications are required. Some common applications include:\\r\\nAlarm Systems: Active buzzers are commonly used in alarm systems to signal various events such as intrusion detection, fire alarms, and security breaches.\\r\\nIoT Devices: In IoT (Internet of Things) applications, active buzzers can be integrated into smart home devices, wearable gadgets, and environmental monitoring systems to provide auditory feedback to users.\\r\\nElectronic Gadgets: Active buzzers are used in electronic gadgets such as digital clocks, timers, and kitchen appliances to signal specific events or indicate the completion of tasks.\\r\\nIndustrial Equipment: In industrial automation, active buzzers serve as warning indicators for machinery malfunctions, equipment failures, or process deviations.\\r\\nEducational Projects: Active buzzers are commonly used in educational projects to teach students about basic electronics, sound generation, and circuit design.\\r\\nTechnical Specifications:\\r\\nOperating Voltage: Typically operates within a voltage range of 3V to 5V DC.\\r\\nSound Output: Generates sound waves with frequencies ranging from a few hundred hertz to several kilohertz, depending on the design and specifications of the buzzer.\\r\\nSound Intensity: The sound intensity level varies between different models, with some buzzers capable of producing louder sounds than others.\\r\\nDimensions: Available in various sizes and shapes, with diameters ranging from a few millimeters to several centimeters.\\r\\nMounting: Can be surface-mounted or through-hole mounted, depending on the application requirements.\\r\\nOperating Temperature: Typically rated for operation within a temperature range of -20°C to 70°C, although this may vary depending on the specific model.\\r\\nCurrent Consumption: Generally consumes low amounts of current, making it suitable for battery-powered applications and energy-efficient devices.'}\n",
            "i 107\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA4C2F20>, 'prompt': 'Can you make a short description about the part: 100μF electrolytic capacitor\\n\\nIt should be divided into 3 sections as follows:\\n1) Description\\n2) Applications\\n3) technical specification', 'response': 'Description:\\r\\nA 100μF electrolytic capacitor is an electronic component designed to store and release electrical energy in the form of charge. It consists of two conductive plates, usually made of aluminum, separated by a thin insulating layer known as the dielectric. One of the distinguishing features of electrolytic capacitors is their polarity, with a marked positive and negative terminal indicating the direction of current flow. This capacitor type utilizes an electrolyte solution to enhance capacitance, allowing for relatively high capacitance values in a compact form factor.\\r\\nApplications:\\r\\nThe 100μF electrolytic capacitor finds widespread use in electronic circuits where energy storage and filtering are essential. It is commonly employed in power supply circuits to smooth out voltage fluctuations and reduce ripple, thus ensuring a stable and clean power output. Additionally, these capacitors are utilized in audio circuits for coupling and decoupling purposes, helping to eliminate unwanted noise and improve signal quality. Their high capacitance makes them suitable for buffering and bypassing in various electronic devices, including amplifiers, voltage regulators, and DC-DC converters.\\r\\nTechnical Specification:\\r\\nCapacitance: 100μF (microfarads)\\r\\nVoltage Rating: Typically ranging from 6V to 50V or higher\\r\\nCapacitance Tolerance: Generally around ±20%\\r\\nOperating Temperature Range: Typically -40°C to +105°C, although specialized variants may offer extended temperature ranges\\r\\nConstruction: Aluminum electrolytic capacitor with polarized design\\r\\nSize: Can vary depending on voltage and construction, commonly ranging from a few millimeters to several centimeters in diameter\\r\\nLeakage Current: Typically specified in datasheets, indicating the amount of current that leaks through the dielectric\\r\\nLifespan: Subject to degradation over time, especially if operated near their voltage and temperature limits; lifespan may vary depending on operating conditions and capacitor quality.'}\n",
            "i 108\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFF32E890>, 'prompt': 'Can you make a short description about the part: L293D\\r\\n\\r\\nIt should be divided into 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) technical specification', 'response': 'Description:\\r\\nThe L293D is a versatile integrated circuit (IC) primarily designed for driving small DC motors and stepper motors. It acts as a motor driver by providing bidirectional control for up to two motors, allowing both direction and speed control. With built-in protection features, it safeguards against overcurrent and back electromotive force (EMF), making it suitable for various robotic and automation projects.\\r\\nApplications:\\r\\nThe L293D finds extensive use in robotics, automation, and hobbyist projects requiring motor control. Some common applications include:\\r\\nRobotic vehicles: Controlling the movement of wheeled or tracked robots.\\r\\nDIY projects: Powering small-scale machinery, such as conveyor belts or miniature cranes.\\r\\nHome automation: Operating window blinds, door locks, or small actuators.\\r\\nEducational purposes: Teaching basic principles of motor control and circuitry in STEM (Science, Technology, Engineering, and Mathematics) education.\\r\\nTechnical Specifications:\\r\\nSupply Voltage: 4.5V to 36V\\r\\nMaximum Continuous Current per Channel: 600mA\\r\\nPeak Output Current per Channel: 1.2A\\r\\nNumber of Channels: 2 (for controlling two motors independently)\\r\\nOperating Temperature Range: -25°C to +125°C\\r\\nPackage Type: DIP (Dual In-line Package) or SOP (Small Outline Package)\\r\\nControl Interface: TTL compatible inputs for straightforward interfacing with microcontrollers or logic circuits.\\r\\nBuilt-in Diodes: Internal freewheeling diodes for protection against back EMF.\\r\\nThermal Shutdown: Automatic thermal shutdown to prevent damage due to overheating.'}\n",
            "i 109\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA4C2AD0>, 'prompt': 'You have been given an IoT kit component: 9V 1A adapter. Give a description of the component having 3 sections as follows:\\n1) Description\\n2) Applications\\n3) Technical specifications', 'response': \"Description:\\r\\nThe 9V 1A adapter is a power supply component designed to provide a stable 9-volt direct current (DC) output at a maximum current of 1 ampere (A). It typically consists of a plug-in adapter with a cable terminating in a connector suitable for powering or charging various electronic devices or circuits.\\r\\nApplications:\\r\\nIoT (Internet of Things) Projects: This adapter is commonly used in IoT projects requiring a reliable power source to operate sensors, microcontrollers, and other connected devices.\\r\\nElectronics Prototyping: It's suitable for powering breadboard circuits, Arduino boards, Raspberry Pi, and other development platforms during prototyping and testing phases.\\r\\nLow-Power Devices: Applications include powering low-power electronic gadgets such as small motors, LED displays, and wireless communication modules.\\r\\nTechnical Specifications:\\r\\nOutput Voltage: 9 volts (V)\\r\\nOutput Current: 1 ampere (A)\\r\\nOutput Connector: Typically comes with a barrel connector, commonly used sizes include 2.1mm and 2.5mm inner diameter.\\r\\nInput Voltage: Usually supports a wide range of input voltages, commonly 100-240 volts AC, making it suitable for use worldwide with appropriate plug adapters.\\r\\nOutput Polarity: The center of the barrel connector is usually positive (+), while the outer sleeve is negative (-), although it's essential to verify this polarity to ensure compatibility with the device being powered.\\r\\nRegulation: Typically provides regulated DC output voltage to ensure stable operation of connected devices.\\r\\nSafety Features: May include overvoltage protection, overcurrent protection, and short-circuit protection to safeguard both the adapter and connected devices.\\r\\nCertifications: May comply with safety and performance standards such as UL (Underwriters Laboratories) certification, CE (Conformité Européenne) marking, or others depending on the intended market and usage.\"}\n",
            "i 110\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA64BEB0>, 'prompt': 'You have been given an IoT kit component: MAX7219 Module. Give a description of the component having 3 sections as follows:\\n1) Description\\n2) Applications\\n3) Technical specifications', 'response': \"Description:\\r\\nThe MAX7219 module is an integrated circuit (IC) that serves as a display driver for 7-segment numerical LED displays. It can control up to eight digits, or seven-segment LED displays, using a minimal number of external components. The MAX7219 module essentially acts as an interface between a microcontroller and the LED displays, simplifying the process of driving multiple displays with minimal GPIO pins.\\r\\nApplications:\\r\\nDigital Clocks: The MAX7219 module is commonly used in digital clock projects where multiple 7-segment displays are required to show hours, minutes, and seconds.\\r\\nScoreboards: It can be employed in scoreboard projects where numeric data needs to be displayed, such as in sports events or competitions.\\r\\nTemperature Displays: By interfacing temperature sensors with a microcontroller, the MAX7219 module can be used to display temperature readings on LED displays.\\r\\nCountdown Timers: It's suitable for countdown timer applications, such as those used in kitchen appliances or sports timing.\\r\\nDigital Counters: In various applications where counting is involved, such as production line monitoring or attendance systems, the MAX7219 module can display count values.\\r\\nTechnical Specifications:\\r\\nSupply Voltage: Typically operates from 5V DC.\\r\\nSerial Interface: Utilizes a simple 3-wire serial interface for communication with the microcontroller (Data In, Load/CS, Clock).\\r\\nDrive Capability: Can drive up to eight digits of 7-segment LED displays directly.\\r\\nCascadable: Multiple MAX7219 modules can be cascaded together to extend the number of controlled digits.\\r\\nCurrent Limiting: Built-in current-limiting resistors for each LED segment, allowing for consistent brightness across displays.\\r\\nMultiplexing: Supports multiplexing to reduce the number of pins required from the microcontroller.\\r\\nPower Saving Mode: Includes a shutdown mode to reduce power consumption when the displays are not actively being updated.\\r\\nInternal Oscillator: Integrated oscillator reduces the number of external components required for operation.\"}\n",
            "i 111\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA4C2D40>, 'prompt': 'You have been given an IoT kit component: 100μF electrolytic capacitor. Give a description of the component having 3 sections as follows:\\n1) Description\\n2) Applications\\n3) Technical specifications', 'response': \"Description:\\r\\nAn electrolytic capacitor is a type of capacitor that uses an electrolyte as one of its plates to achieve a larger capacitance per unit volume than other types of capacitors. The 100μF electrolytic capacitor is specifically designed to store and release electrical energy in electronic circuits. It typically consists of two conducting plates, one of which is coated with an oxide layer, separated by an electrolyte-soaked material. This design allows it to achieve a high capacitance value in a relatively small package size.\\r\\nApplications:\\r\\nThe 100μF electrolytic capacitor is commonly used in various electronic circuits and IoT projects for several purposes, including:\\r\\nFiltering: It can smooth out fluctuations in power supplies by filtering out high-frequency noise and ripple voltage.\\r\\nCoupling: It can couple two circuits together while blocking DC voltage, allowing AC signals to pass through.\\r\\nTiming: It can be used in timing circuits and oscillators to control the frequency of signals.\\r\\nEnergy storage: It can temporarily store electrical energy and release it when needed, such as in flash units, motor start-up circuits, and pulse circuits.\\r\\nOverall, its versatility makes it a valuable component in IoT projects, ranging from simple sensor circuits to more complex control systems.\\r\\n\\r\\nTechnical Specifications:\\r\\nCapacitance: 100μF (microfarads)\\r\\nVoltage Rating: Typically ranges from 6V to 50V, depending on the specific capacitor.\\r\\nTolerance: Capacitance tolerance typically ranges from ±20% to ±10%.\\r\\nTemperature Range: Operating temperature ranges from -40°C to +85°C or higher, depending on the capacitor's specifications.\\r\\nPolarization: Electrolytic capacitors are polarized components, meaning they have a positive and a negative terminal. Incorrect polarity connection can lead to capacitor failure or even explosion.\\r\\nLifespan: The lifespan of electrolytic capacitors depends on factors such as temperature, voltage, and usage conditions but generally ranges from several thousand to tens of thousands of hours.\\r\\nSize and Form Factor: The physical size of the capacitor can vary depending on its capacitance and voltage rating, but common sizes include radial leaded and surface mount types.\"}\n",
            "i 112\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA64BF40>, 'prompt': 'Can you make a short description about the part: Photoresistor (photocell)\\r\\n\\r\\nIt should be divided into 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) technical specification', 'response': 'Description:\\r\\nA photoresistor, also known as a photocell or light-dependent resistor (LDR), is a passive component that exhibits a change in resistance based on the intensity of light it is exposed to. It consists of a semiconductor material whose resistance decreases as the intensity of incident light increases. When light falls on the photoresistor, the photons excite electrons in the semiconductor material, allowing them to flow more freely, thereby reducing the resistance of the component.\\r\\nApplications:\\r\\nPhotoresistors find wide applications in various fields including:\\r\\nAutomatic lighting control systems: Photoresistors are commonly used in streetlights, outdoor lighting systems, and indoor lighting systems to automatically adjust the brightness based on ambient light levels.\\r\\nBurglar alarm systems: They are utilized to detect unauthorized intrusions by sensing sudden changes in light intensity.\\r\\nPhotography: Photoresistors are employed in cameras to determine optimal exposure settings by measuring the amount of light available.\\r\\nSolar panels: Photoresistors are sometimes used in solar panels to track the position of the sun and adjust the panels accordingly for maximum energy capture.\\r\\nTechnical Specifications:\\r\\nThe technical specifications of a photoresistor typically include:\\r\\nResistance Range: The range of resistance values exhibited by the photoresistor under varying light conditions.\\r\\nDark Resistance: The resistance of the photoresistor when no light is falling on it.\\r\\nLight Resistance: The resistance of the photoresistor under maximum illumination.\\r\\nResponse Time: The time taken by the photoresistor to change its resistance when the light intensity changes.\\r\\nSpectral Response: The sensitivity of the photoresistor to different wavelengths of light, which can vary based on the material used in its construction.\\r\\nPower Rating: The maximum power the photoresistor can handle without being damaged.'}\n",
            "i 113\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFB839FF0>, 'prompt': 'Can you make a short description about the part: MAX7219 Module\\r\\n\\r\\nIt should be divided into 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) technical specification', 'response': 'Description:\\r\\nThe MAX7219 module is a compact and versatile integrated circuit (IC) designed to control up to 64 individual LEDs or 8 7-segment numeric displays through a 3-wire serial interface. It serves as a convenient solution for driving LED matrices or 7-segment displays with minimal external components. The MAX7219 chip handles multiplexing, brightness control, and display refresh, reducing the workload on the microcontroller or host device.\\r\\nApplications:\\r\\nLED Matrix Displays: The MAX7219 module is commonly used to create dynamic and visually appealing LED matrix displays for signs, scoreboards, clocks, and scrolling text.\\r\\nSeven-Segment Displays: It efficiently drives numeric displays in various applications such as digital clocks, temperature displays, and electronic meters.\\r\\nInformation Panels: The module finds utility in creating information panels or status indicators where multiple LEDs or segments need to be controlled independently or in patterns.\\r\\nDIY Projects: Hobbyists and enthusiasts often incorporate MAX7219 modules into their projects for displaying data or creating interactive visual elements.\\r\\nTechnical Specification:\\r\\nMaximum Display Digits: 8 digits for 7-segment displays or 64 individual LEDs.\\r\\nSerial Interface: Utilizes a simple 3-wire SPI (Serial Peripheral Interface) for communication with the microcontroller or host device.\\r\\nCascadable: Multiple MAX7219 modules can be cascaded together to extend the number of displays without requiring additional pins on the microcontroller.\\r\\nBrightness Control: Offers 16 levels of intensity control to adjust the brightness of the LEDs or segments.\\r\\nPower Supply: Typically operates in the range of 4.0V to 5.5V, making it compatible with a wide range of microcontroller boards.\\r\\nLow Power Consumption: Optimized for low power consumption, making it suitable for battery-powered applications.\\r\\nIntegrated BCD Code-B Decoder: Simplifies the interfacing with 7-segment displays by converting serial data into the necessary segment control signals.\\r\\nInternal Oscillator: Includes an internal oscillator for generating the necessary timing signals, reducing the need for external components.'}\n",
            "i 114\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA64BF40>, 'prompt': 'You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: ELEGOO Remote Control. Give a description of the component having 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) Technical specifications', 'response': 'Description:\\r\\nThe ELEGOO Remote Control is a versatile wireless control module designed for IoT (Internet of Things) projects. It consists of a handheld remote control unit and a receiver module, both utilizing RF (radio frequency) communication technology. The remote control unit features various buttons or switches that transmit signals to the receiver, enabling users to remotely control connected devices or systems within a certain range.\\r\\nApplications:\\r\\nThe ELEGOO Remote Control finds applications in a wide range of IoT projects and automation systems, including but not limited to:\\r\\nHome automation: Control lights, fans, curtains, and other appliances remotely.\\r\\nRobotics: Wirelessly control the movement and functions of robotic devices.\\r\\nAutomotive: Implement remote keyless entry systems or control vehicle accessories wirelessly.\\r\\nIndustrial automation: Control machinery and equipment from a distance, enhancing safety and efficiency.\\r\\nEntertainment: Control multimedia devices such as TVs, audio systems, and gaming consoles remotely.\\r\\nTechnical Specifications:\\r\\nOperating Frequency: Typically operates in the 433MHz or 315MHz frequency bands.\\r\\nCommunication Protocol: Utilizes RF communication for wireless data transmission between the remote control unit and the receiver module.\\r\\nRange: Effective communication range typically ranges from tens to hundreds of meters, depending on environmental conditions and obstacles.\\r\\nPower Supply: Both the remote control unit and the receiver module may require separate power sources, often using batteries or DC power supplies.\\r\\nCompatibility: Designed to be compatible with various microcontroller platforms such as Arduino, Raspberry Pi, and other development boards.\\r\\nInterface: The receiver module typically interfaces with the microcontroller via digital or analog pins, enabling easy integration into IoT projects.\\r\\nNumber of Channels: The remote control unit may feature multiple channels or buttons for transmitting different control signals, allowing for versatile control options.'}\n",
            "i 115\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA4C19F0>, 'prompt': 'Can you make a short description about the part: Prototype expansion module\\r\\n\\r\\nIt should be divided into 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) technical specification', 'response': 'Description:\\r\\nA prototype expansion module is a hardware component designed to enhance the functionality and capabilities of a prototype or early-stage product. It typically interfaces with the main prototype system and provides additional features or connectivity options to aid in development and testing phases.\\r\\nApplications:\\r\\nPrototype expansion modules find applications in various fields including electronics, robotics, IoT (Internet of Things), and consumer electronics. They are commonly used by engineers and developers to quickly prototype and iterate on new ideas, allowing for rapid development and testing of product concepts.\\r\\nTechnical Specifications:\\r\\nThe technical specifications of a prototype expansion module may vary depending on the specific requirements of the project. However, common features include compatibility with standard interfaces such as GPIO (General Purpose Input/Output), SPI (Serial Peripheral Interface), I2C (Inter-Integrated Circuit), and UART (Universal Asynchronous Receiver-Transmitter). Additionally, prototype expansion modules may include features such as analog and digital inputs/outputs, onboard sensors (e.g., temperature, humidity), communication interfaces (e.g., Ethernet, Wi-Fi, Bluetooth), and power management circuitry. The physical form factor and connectivity options of the module are often designed to seamlessly integrate with the main prototype system.'}\n",
            "i 116\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFB839FF0>, 'prompt': 'You have been given an IoT kit component: Diode Rectifier. Give a description of the component having 3 sections as follows:\\n1) Description\\n2) Applications\\n3) Technical specifications', 'response': 'Description:\\r\\nA diode rectifier is an electronic component designed to convert alternating current (AC) into direct current (DC). It consists of one or more diodes, which are semiconductor devices that allow current to flow in one direction while blocking it in the opposite direction. Diode rectifiers typically come in various forms, including single diode half-wave rectifiers, double diode full-wave rectifiers, and bridge rectifiers.\\r\\nApplications:\\r\\nDiode rectifiers are widely used in numerous electronic circuits and systems for converting AC power to DC power. Some common applications include:\\r\\nPower supplies: Diode rectifiers are essential components in power supply circuits for electronic devices, ranging from small gadgets to large industrial equipment.\\r\\nBattery charging: They are used in battery chargers to convert AC from the mains supply into DC suitable for charging batteries.\\r\\nSignal demodulation: In radio and communication systems, diode rectifiers are used to demodulate amplitude-modulated (AM) signals, separating the audio or data signal from the carrier wave.\\r\\nLED lighting: Diode rectifiers are employed in LED lighting systems to convert AC mains voltage into the DC voltage required to power the LEDs.\\r\\nMotor drives: In motor control circuits, diode rectifiers can be used to convert AC power into DC power for driving motors and controlling their speed.\\r\\nTechnical Specifications:\\r\\nThe technical specifications of a diode rectifier may vary depending on its intended application and design. However, some common specifications include:\\r\\nMaximum forward current (IF): This indicates the maximum continuous current that the diode can safely conduct in the forward direction.\\r\\nPeak inverse voltage (PIV) or peak reverse voltage (PRV): This specifies the maximum voltage that the diode can withstand in the reverse direction without breakdown.\\r\\nForward voltage drop (VF): This is the voltage drop across the diode when it is conducting current in the forward direction. It is typically around 0.7 volts for silicon diodes.\\r\\nMaximum reverse current (IR): This indicates the maximum leakage current that flows through the diode when it is reverse-biased.\\r\\nOperating temperature range: This specifies the temperature range over which the diode can safely operate without exceeding its maximum ratings.\\r\\nPackage type: Diode rectifiers are available in various package types, such as through-hole and surface-mount packages, to suit different assembly and mounting requirements.'}\n",
            "i 117\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA4C2980>, 'prompt': 'Can you make a short description about the part: Fan Blade for 3-6V motor\\r\\n\\r\\nIt should be divided into 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) technical specification', 'response': 'Description:\\r\\nThe fan blade for a 3-6V motor is a lightweight and durable component crafted to efficiently circulate air in various electronic devices and small-scale projects. Made from high-quality materials, this fan blade ensures optimal airflow while maintaining low power consumption, making it ideal for applications where energy efficiency and cooling are essential.\\r\\nApplications:\\r\\nThis versatile fan blade finds applications in a wide range of devices and projects, including but not limited to:\\r\\nCooling systems for electronic devices such as laptops, routers, and gaming consoles.\\r\\nVentilation systems in DIY projects, robotics, and small-scale automation setups.\\r\\nAir circulation in model airplanes, drones, and other hobbyist vehicles.\\r\\nTemperature regulation in enclosures for electronic components, ensuring optimal performance and longevity.\\r\\nTechnical Specification:\\r\\nCompatible Voltage: 3-6V\\r\\nBlade Material: Lightweight and durable plastic or composite material\\r\\nBlade Count: Typically designed with 2 or 3 blades for efficient airflow\\r\\nDimensions: Varied sizes available to suit different motor and project requirements\\r\\nMounting: Designed for easy attachment to compatible motor shafts or hubs\\r\\nOperating Temperature: Suitable for a wide range of environmental conditions, ensuring reliable performance under various circumstances.'}\n",
            "i 118\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA64BF40>, 'prompt': 'You have been given an IoT kit component: RGB LED. Give a description of the component having 3 sections as follows:\\n1) Description\\n2) Applications\\n3) Technical specifications', 'response': 'Description:\\r\\nAn RGB LED, or Red-Green-Blue Light Emitting Diode, is a specialized type of LED that can emit light in three primary colors: red, green, and blue. It consists of three individual LED chips, each emitting light of a specific color, combined into a single package. By varying the intensity of each color, a wide range of colors can be produced, including white light when all three colors are fully illuminated simultaneously.\\r\\nApplications:\\r\\nMood lighting: RGB LEDs are commonly used in mood lighting applications where the color of the light can be adjusted to create different atmospheres or enhance aesthetic appeal.\\r\\nDecorative lighting: They are popular in decorative lighting installations, such as holiday decorations, architectural lighting, and interior design projects.\\r\\nIndicators and displays: RGB LEDs can be used as status indicators in electronic devices or as components in alphanumeric displays and signage, where different colors convey specific information or messages.\\r\\nEntertainment and visual effects: They are widely used in stage lighting, concerts, DJ setups, and special effects applications to create dynamic and colorful lighting displays.\\r\\nTechnical specifications:\\r\\nForward Voltage: Typically around 2-3.5 volts depending on the specific LED and manufacturer.\\r\\nForward Current: Usually ranges from 10mA to 20mA per color LED.\\r\\nCommon Cathode or Common Anode: RGB LEDs may come in two configurations, common cathode (ground pin shared among all three LEDs) or common anode (positive pin shared among all three LEDs).\\r\\nViewing Angle: The angle at which the emitted light is most visible, often around 120 degrees.\\r\\nPackage Type: Available in various package types such as through-hole, surface mount, or integrated into modules for easy integration into electronic circuits.\\r\\nControl Interface: Can be controlled using pulse-width modulation (PWM) signals from microcontrollers or dedicated LED drivers to adjust the intensity of each color and create different colors and effects.'}\n",
            "i 119\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA4C1CC0>, 'prompt': 'You have been given an IoT kit component: Servo Motor SG90. Give a description of the component having 3 sections as follows:\\n1) Description\\n2) Applications\\n3) Technical specifications', 'response': 'Description:\\r\\nThe Servo Motor SG90 is a small, lightweight, and inexpensive servo motor commonly used in hobbyist and DIY electronics projects. It is designed to provide precise control of angular position, making it ideal for applications that require accurate movement and positioning. The SG90 servo motor typically comes with three wires: power (usually red), ground (usually brown or black), and control signal (usually yellow or orange).\\r\\nApplications:\\r\\nRobotics: SG90 servo motors are frequently used in robotics projects to control the movement of robot arms, grippers, and other mechanical components.\\r\\nRemote-controlled vehicles: They are commonly employed in RC cars, airplanes, boats, and drones to control steering mechanisms, throttle, and other moving parts.\\r\\nCamera gimbal stabilization: SG90 servo motors can be used to stabilize cameras and other imaging devices, providing smooth and steady movement for capturing high-quality photos and videos.\\r\\nHome automation: They can be integrated into home automation systems to control various devices such as door locks, blinds, and light switches.\\r\\nEducational purposes: The SG90 servo motor is often used in educational settings to teach students about robotics, electronics, and programming.\\r\\nTechnical specifications:\\r\\nOperating Voltage: 4.8 - 6.0V\\r\\nStall Torque: 1.8 kg/cm (4.8V), 2.2 kg/cm (6.0V)\\r\\nOperating Speed: 0.12 sec/60° (4.8V), 0.10 sec/60° (6.0V)\\r\\nDimensions: 22.2 x 11.8 x 31 mm\\r\\nWeight: 9 grams\\r\\nGear Type: Plastic\\r\\nControl Interface: PWM (Pulse Width Modulation)\\r\\nRotation: 180 degrees\\r\\nOperating Temperature: -30°C to +60°C'}\n",
            "i 120\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA64BF40>, 'prompt': 'Can you make a short description about the part: RGB LED\\r\\n\\r\\nIt should be divided into 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) technical specification', 'response': \"Description:\\r\\nAn RGB LED, short for Red, Green, Blue Light Emitting Diode, is a specialized light-emitting diode capable of emitting light in multiple colors by combining the emissions of three primary colors: red, green, and blue. Unlike traditional LEDs that emit light of a single color, RGB LEDs contain three separate LED chips within a single package, each corresponding to one of the primary colors. By adjusting the intensity of each color component, RGB LEDs can produce a wide range of colors, making them versatile light sources for various applications.\\r\\nApplications:\\r\\nRGB LEDs find widespread applications in various industries and consumer electronics. They are commonly used in decorative lighting, such as in architectural lighting, stage lighting, and signage, where vibrant colors and dynamic lighting effects are desired. In consumer electronics, RGB LEDs are often utilized in displays, backlights for LCD screens, gaming peripherals, and smart home devices. Additionally, they are popular in DIY projects, art installations, and creative endeavors where customizable lighting is essential for creating ambiance or visual impact.\\r\\nTechnical Specifications:\\r\\nVoltage: Typically operates at low voltages, commonly between 2V to 3.6V.\\r\\nCurrent: Operating current can vary depending on the LED's size and configuration but generally ranges from a few milliamps to several tens of milliamps per color channel.\\r\\nPower Consumption: Power consumption is directly proportional to the operating current and voltage of the LED.\\r\\nColor Mixing: RGB LEDs achieve color mixing by independently controlling the intensity of each primary color component. This is usually done through pulse width modulation (PWM) techniques.\\r\\nPackage Type: Available in various package types such as surface-mount device (SMD), through-hole, or chip-on-board (COB).\\r\\nLifespan: Like other LEDs, RGB LEDs have a long operational lifespan, often exceeding tens of thousands of hours.\\r\\nControl Interface: Can be controlled using dedicated RGB LED controllers, microcontrollers, or software-based platforms, allowing for precise color selection and dynamic lighting effects.\\r\\nViewing Angle: Viewing angle varies depending on the LED's design and package type, ranging from narrow to wide angles.\"}\n",
            "i 121\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA6BE4A0>, 'prompt': 'You have been given an IoT kit component: ELEGOO DS1307 RTC Module. Give a description of the component having 3 sections as follows:\\n1) Description\\n2) Applications\\n3) Technical specifications', 'response': 'Description:\\r\\nThe ELEGOO DS1307 RTC (Real-Time Clock) Module is a small electronic device designed to keep track of time accurately. It utilizes the DS1307 integrated circuit, which is a low-power, full binary-coded decimal (BCD) clock/calendar chip. The module typically consists of the DS1307 chip, a crystal oscillator for timing accuracy, and a small battery to provide backup power in case of main power loss. It communicates with microcontrollers or other devices via an I2C (Inter-Integrated Circuit) interface.\\r\\nApplications:\\r\\nThe DS1307 RTC Module finds various applications in electronics projects, IoT (Internet of Things) devices, and embedded systems where accurate timekeeping is crucial. Some common applications include:\\r\\nClocks and watches: Building digital or analog clocks with real-time display capabilities.\\r\\nData logging systems: Logging timestamps for events or sensor readings.\\r\\nAutomation systems: Scheduling tasks or events based on real-time clock information.\\r\\nSecurity systems: Timestamping events in surveillance systems or access control devices.\\r\\nIndustrial automation: Synchronizing processes or equipment based on accurate timekeeping.\\r\\nIoT devices: Providing accurate timestamps for data transmission and synchronization in IoT networks.\\r\\nTechnical Specifications:\\r\\nDS1307 RTC chip: Low-power, real-time clock/calendar chip with 56 bytes of non-volatile RAM (NV-RAM) for storing time and date information.\\r\\nOperating voltage: Typically operates at 5V DC, but can be powered by a wide range of voltages (such as 3.3V).\\r\\nCommunication interface: I2C (Inter-Integrated Circuit) interface for communication with microcontrollers or other devices.\\r\\nAccuracy: The DS1307 RTC Module can maintain accurate timekeeping within a few seconds per month under normal operating conditions.\\r\\nBackup power: Typically includes a small CR2032 coin cell battery to provide backup power for the RTC chip in case of main power loss.\\r\\nDimensions: Compact size, often in the form of a small module with standard pin headers for easy integration into electronic projects.'}\n",
            "i 122\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA64BEB0>, 'prompt': 'Can you make a short description about the part: Water Level Detection Sensor Module\\r\\n\\r\\nIt should be divided into 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) technical specification', 'response': 'Description:\\r\\nA Water Level Detection Sensor Module is a compact electronic device designed to detect the presence or absence of water at a particular level within a container or reservoir. Typically utilizing conductivity or ultrasonic technology, the sensor module can accurately determine the water level and provide corresponding signals or data outputs. It is often equipped with probes or sensors that come in contact with the water, allowing for precise detection and measurement.\\r\\nApplications:\\r\\nWater Level Detection Sensor Modules find widespread applications across various industries and settings, including:\\r\\nAutomatic irrigation systems: Ensuring optimal water levels in agricultural fields, gardens, and landscapes.\\r\\nWater tanks and reservoirs: Monitoring water levels in tanks for residential, commercial, or industrial use to prevent overflow or depletion.\\r\\nAquariums and fish tanks: Maintaining proper water levels for aquatic life, preventing damage to equipment and ensuring a healthy environment.\\r\\nIndustrial processes: Controlling water levels in manufacturing processes, cooling systems, and wastewater treatment facilities.\\r\\nFlood detection systems: Alerting homeowners or authorities to potential flooding in basements, underground spaces, or critical infrastructure.\\r\\nTechnical Specifications:\\r\\nSensing Technology: Conductivity-based or Ultrasonic\\r\\nDetection Range: Varies based on the specific module, ranging from a few millimeters to several meters\\r\\nOperating Voltage: Typically operates within a range of 3.3V to 5V DC\\r\\nOutput Interface: Analog or digital signal output, compatible with microcontrollers and other electronic devices\\r\\nEnvironmental Conditions: Designed to withstand varying temperatures and humidity levels, suitable for indoor and outdoor use\\r\\nSize and Form Factor: Compact and often modular design for easy integration into different systems and applications\\r\\nAccuracy and Precision: Provides reliable and accurate water level detection within specified tolerances, ensuring precise control and monitoring.\\r'}\n",
            "i 123\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFF1DEEF0>, 'prompt': 'You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: Female to male Dupont Wire. Give a description of the component having 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) Technical specifications', 'response': 'Description:\\r\\nFemale to male Dupont wires are cables commonly used in electronic prototyping and DIY electronics projects. They consist of a series of connectors at each end, one being a female connector and the other a male connector. The female connector typically has sockets that securely fit onto male header pins, while the male connector has protruding pins that fit into female headers or sockets. These wires are often color-coded for easy identification and organization.\\r\\nApplications:\\r\\nBreadboarding: Dupont wires are widely used in breadboarding to create connections between various electronic components such as microcontrollers, sensors, and actuators. They facilitate quick and temporary connections, allowing for rapid prototyping and testing of circuits.\\r\\nArduino Projects: In Arduino projects, Dupont wires are used to connect sensors, displays, motors, and other peripherals to the Arduino board. They provide a convenient way to establish electrical connections without the need for soldering.\\r\\nRaspberry Pi Projects: Similarly, in Raspberry Pi projects, Dupont wires are used to connect GPIO (General Purpose Input/Output) pins to external components, expanding the capabilities of the Raspberry Pi for various applications including home automation, robotics, and IoT.\\r\\nElectronic Modules: Dupont wires are often used to interface with electronic modules and breakout boards, enabling communication and power transfer between different components in a system.\\r\\nTechnical Specifications:\\r\\nConnector Type: Female to male Dupont wires typically have one end with a female connector (sockets) and the other end with a male connector (pins).\\r\\nWire Gauge: The wire gauge commonly used in Dupont wires is around 22 AWG (American Wire Gauge), providing a balance between flexibility and current-carrying capacity.\\r\\nLength: Dupont wires are available in various lengths, typically ranging from a few inches to several inches, allowing for flexibility in connecting components within a circuit.\\r\\nConnector Pitch: The pitch (spacing) between the pins or sockets on Dupont wires is standardized at 2.54mm (0.1 inch), matching the spacing of standard breadboards and electronic components.\\r\\nMaterial: The wires are usually made of stranded copper for flexibility and durability, while the connectors are commonly made of plastic with metal contacts for reliable electrical connections.'}\n",
            "i 124\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA64BE20>, 'prompt': 'Can you make a short description about the part: ULN 2003 Stepper Motor Driver Module\\r\\n\\r\\nIt should be divided into 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) technical specification\\r\\n\\r', 'response': \"Description:\\nThe ULN2003 Stepper Motor Driver Module is a compact and efficient device designed to control stepper motors easily. It integrates the ULN2003 Darlington transistor array with other necessary components to provide a simple and effective solution for driving stepper motors. With its small form factor and straightforward interface, it's suitable for a wide range of applications.\\nApplications:\\nThis module finds applications in various fields where precise control of stepper motors is required. Some common applications include robotics, CNC machines, 3D printers, automated systems, camera platforms, and electronic locks. It's also utilized in hobbyist projects and educational experiments due to its ease of use and affordability.\\nTechnical Specifications:\\nOperating Voltage: 5V DC\\nDrive Capability: Up to 500mA per channel\\nNumber of Channels: 7 (corresponding to ULN2003 Darlington transistor array)\\nCompatible Stepper Motors: 4-phase or 5-phase stepper motors\\nInput Signal Compatibility: Compatible with TTL and CMOS logic levels\\nDimensions: Compact form factor for easy integration into various projects\\nFeatures: Built-in freewheeling diodes for protection, convenient interface for motor connections, and simple control inputs for direction and step signals.\"}\n",
            "i 125\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA64BF40>, 'prompt': 'You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: 3-6V motor. Give a description of the component having 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) Technical specifications', 'response': \"Description:\\r\\nThe 3-6V motor is a versatile electromechanical component commonly used in various electronic projects and IoT applications. It typically consists of a small cylindrical casing housing a DC (Direct Current) motor with an attached shaft. The motor operates within a voltage range of 3 to 6 volts, making it compatible with a wide range of power sources commonly found in IoT kits and electronics projects. It's often equipped with wire leads for easy connectivity to power sources and control circuits.\\r\\nApplications:\\r\\nThe 3-6V motor finds applications in numerous IoT and hardware projects due to its compact size, low power consumption, and ease of integration. Some common applications include:\\r\\nRobotic Projects: Used to drive wheels, manipulate robotic arms, or actuate various components in robotics projects.\\r\\nHome Automation: Integrated into smart home systems for controlling curtains, blinds, or small appliances.\\r\\nIoT Gadgets: Employed in IoT gadgets such as automated pet feeders, smart door locks, or remote-controlled toys.\\r\\nEducational Purposes: Utilized in educational settings to teach basic electronics, mechanics, and programming concepts.\\r\\nPrototyping: Used for rapid prototyping of electronic devices and IoT prototypes due to its simplicity and versatility.\\r\\nTechnical Specifications:\\r\\nVoltage Range: 3 to 6 volts DC\\r\\nOperating Current: Typically ranges from a few milliamps to a couple of hundred milliamps, depending on the load and operating conditions.\\r\\nSpeed: The speed of the motor varies depending on the voltage applied and the load. It can typically range from a few hundred to a few thousand rotations per minute (RPM).\\r\\nTorque: The torque output of the motor depends on various factors such as voltage, current, and construction. While small in size, it can provide sufficient torque for many lightweight applications.\\r\\nDimensions: Compact size, typically ranging from a few centimeters to a few inches in length and diameter, making it suitable for integration into small-scale projects.\\r\\nConstruction: Constructed with durable materials such as metal or plastic, with precision-engineered components for reliable operation.\\r\\nControl: Can be controlled using simple electronic circuits such as switches, transistors, or motor driver ICs (Integrated Circuits).\\r\\nCompatibility: Compatible with a wide range of microcontrollers, single-board computers, and IoT platforms commonly used in electronics projects.\"}\n",
            "i 126\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFF1DEEF0>, 'prompt': 'You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: ESP Wroom 32. Give a description of the component having 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) Technical specifications', 'response': \"Description:\\r\\nThe ESP Wroom 32 is a highly versatile and powerful microcontroller module designed for Internet of Things (IoT) applications. It is based on the ESP32 system-on-chip (SoC) by Espressif Systems, known for its robust performance and rich set of features. The module integrates a dual-core processor, Wi-Fi and Bluetooth connectivity, various peripheral interfaces, and ample memory resources, making it ideal for a wide range of IoT projects. Its compact size and low power consumption make it suitable for deployment in various IoT devices and embedded systems.\\r\\nApplications:\\r\\nThe ESP Wroom 32 finds applications in diverse IoT scenarios, including:\\r\\nHome automation: Control and monitor smart home devices such as lights, thermostats, and security cameras remotely via Wi-Fi or Bluetooth.\\r\\nIndustrial automation: Collect data from sensors and machinery, and transmit it wirelessly for real-time monitoring and analysis.\\r\\nWearable devices: Develop wearable gadgets such as fitness trackers and smart watches with built-in connectivity features.\\r\\nEnvironmental monitoring: Deploy sensor networks for tracking environmental parameters like temperature, humidity, and air quality in smart cities or agricultural settings.\\r\\nIoT gateways: Serve as a gateway device to aggregate data from multiple sensors and communicate with cloud services or other IoT devices.\\r\\nTechnical specifications:\\r\\nMicrocontroller: Dual-core Tensilica LX6 processor (240 MHz)\\r\\nWi-Fi: 802.11 b/g/n (2.4 GHz) with support for WPA/WPA2 security protocols\\r\\nBluetooth: Bluetooth Low Energy (BLE) and Classic Bluetooth support\\r\\nMemory: 520 KB SRAM, 448 KB ROM, 4 MB Flash\\r\\nGPIO Pins: 36 general-purpose input/output pins\\r\\nInterfaces: SPI, I2C, UART, ADC, DAC, PWM\\r\\nOperating Voltage: 3.3V\\r\\nPower Consumption: Low power consumption with various sleep modes for energy efficiency\\r\\nDimensions: Compact form factor, typically around 25mm x 18mm\\r\\nOperating Temperature: -40°C to 125°C\\r\\nDevelopment Environment: Supports programming in C/C++ using the Arduino IDE or Espressif's native SDK (ESP-IDF)\"}\n",
            "i 127\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA64BF40>, 'prompt': 'Can you make a short description about the part: Elegoo UNO R3 controller board\\n\\nIt should be divided into 3 sections as follows:\\n1) Description\\n2) Applications\\n3) technical specification', 'response': 'Description:\\nThe Elegoo UNO R3 controller board is a versatile microcontroller board based on the Arduino UNO R3 design. It serves as the brain of numerous DIY electronics projects, offering a compact and user-friendly platform for both beginners and advanced users alike. With its robust construction and compatibility with a wide range of sensors, actuators, and modules, it empowers enthusiasts to bring their ideas to life.\\nApplications:\\nThe Elegoo UNO R3 finds applications across various fields including robotics, home automation, IoT (Internet of Things), educational projects, and prototyping. It can be used to create interactive installations, automate tasks, develop sensor-based systems, and much more. Its flexibility and ease of programming make it an ideal choice for hobbyists, students, educators, and professionals seeking to innovate in the realm of electronics and embedded systems.\\nTechnical Specifications:\\nMicrocontroller: ATmega328P\\nOperating Voltage: 5V\\nInput Voltage (recommended): 7-12V\\nDigital I/O Pins: 14 (of which 6 provide PWM output)\\nAnalog Input Pins: 6\\nFlash Memory: 32 KB (0.5 KB used by bootloader)\\nSRAM: 2 KB\\nEEPROM: 1 KB\\nClock Speed: 16 MHz\\nUSB Interface: Type-B\\nDimensions: 68.6mm x 53.4mm'}\n",
            "i 128\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA64BE20>, 'prompt': 'Can you make a short description about the part: LCD 1602 module (with pin header)\\r\\n\\r\\nIt should be divided into 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) technical specification\\r\\n\\r', 'response': 'Description:\\nThe LCD 1602 module with pin header is a compact and versatile display unit commonly used in electronic projects and prototyping. It features a 16x2 character LCD (Liquid Crystal Display) screen with an integrated backlight, controlled by a built-in HD44780 compatible controller. The module comes equipped with a pin header, facilitating easy connection to microcontrollers and other electronic devices.\\nApplications:\\nThis module finds wide applications across various projects including:\\nDIY electronics projects\\nPrototyping and experimentation\\nEmbedded systems\\nData logging devices\\nHome automation systems\\nInformation display units\\nEducational purposes, such as teaching basic electronics and programming\\nTechnical Specifications:\\nDisplay: 16x2 character LCD\\nController: HD44780 compatible\\nBacklight: Integrated backlight for improved visibility in low-light conditions\\nInterface: Standard pin header for easy connection to microcontrollers and other devices\\nOperating Voltage: Typically operates at 5V DC\\nInterface: Parallel interface, requiring minimal pins for communication\\nDimensions: Compact form factor, suitable for integration into various projects\\nContrast Adjustment: Potentiometer for adjusting the contrast of the display\\nCharacter Set: Supports a standard ASCII character set for displaying alphanumeric characters, symbols, and custom characters\\n'}\n",
            "i 129\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFB839FF0>, 'prompt': 'You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: Stepper Motor. Give a description of the component having 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) Technical specifications', 'response': \"Description:\\nA stepper motor is a type of brushless DC electric motor that divides a full rotation into a number of equal steps. Unlike conventional motors, which continuously rotate, stepper motors move in precise increments, or steps, allowing for accurate control over position, speed, and rotation. This precise control is achieved by energizing coils in a specific sequence, causing the motor to move step by step. Stepper motors are available in various sizes and configurations, with the most common types being bipolar and unipolar.\\nApplications:\\nStepper motors find applications in a wide range of industries and devices where precise motion control is required. Some common applications include:\\nRobotics: Stepper motors are widely used in robotic systems for precise control of movement in joints and actuators.\\n3D Printing: They are employed in 3D printers for controlling the movement of print heads and build platforms, ensuring accurate positioning and layering.\\nCNC Machines: Stepper motors drive the movement of axes in computer numerical control (CNC) machines, enabling precise cutting, milling, and engraving.\\nAutomated Equipment: They are utilized in various automated systems for tasks such as pick-and-place operations, conveyor belt control, and assembly line machinery.\\nCamera Systems: Stepper motors are found in camera lenses and focusing mechanisms, enabling precise control over zoom, focus, and aperture.\\nConsumer Electronics: They can be found in devices like disk drives, printers, and scanners for precise positioning and control of moving parts.\\nTechnical Specifications:\\nStep Angle: Stepper motors are characterized by their step angle, which is the angular distance moved by the motor shaft for each step. Common step angles include 1.8 degrees (200 steps per revolution) and 0.9 degrees (400 steps per revolution).\\nHolding Torque: This refers to the amount of torque the motor can generate while stationary to hold a load in position. It is typically specified in Newton-meters (Nm) or ounce-inches (oz-in).\\nOperating Voltage: The voltage required to drive the stepper motor. This can vary depending on the motor's design and winding configuration.\\nCurrent Rating: The maximum current the motor windings can handle without overheating. It is usually specified in amperes (A) or milliamperes (mA).\\nCoil Configuration: Stepper motors can be bipolar or unipolar, with different wiring configurations for each. Bipolar motors require an H-bridge or specialized driver circuit for control, while unipolar motors can be driven with simpler circuitry.\\nPhysical Dimensions: Stepper motors come in various sizes and form factors, including different shaft diameters, lengths, and mounting options. These dimensions are important considerations for integration into specific projects or applications.\"}\n",
            "i 130\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFF32E890>, 'prompt': 'Can you make a short description about the part: 1 Digit 7-segment Display\\r\\n\\r\\nIt should be divided into 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) technical specification', 'response': 'Description:\\r\\nA 1 digit 7-segment display is a simple electronic component used to visually display numerical digits (0-9) or some alphabetic characters. It consists of seven LED (Light Emitting Diode) segments arranged in a specific pattern to form the shape of numerals when activated. Each segment can be individually controlled to display the desired digit. These displays are commonly available in various sizes, from miniature to larger versions, and come in both common anode and common cathode configurations.\\r\\nApplications:\\r\\nDigital clocks and timers: 1 digit 7-segment displays are commonly used to display hours, minutes, or seconds in digital clocks and timers.\\r\\nCounters and frequency meters: They can be utilized to display counts or frequency values in various electronic circuits.\\r\\nSmall-scale instrumentation: In laboratory equipment or small-scale instrumentation, they can serve as a compact and cost-effective display solution for numerical data.\\r\\nConsumer electronics: They are found in various consumer devices like microwave ovens, calculators, and digital watches for displaying numeric information.\\r\\nTechnical Specifications:\\r\\nCommon Anode or Common Cathode: Common anode displays have all the anodes of the LED segments tied together, while common cathode displays have all the cathodes connected.\\r\\nForward Voltage: Typically around 2-2.5 volts per segment for common LED materials.\\r\\nForward Current: Varies depending on the specific LED material and desired brightness level, typically in the range of 5-20mA per segment.\\r\\nDimensions: Size varies depending on the application, ranging from miniature displays to larger ones suitable for outdoor signage.\\r\\nViewing Angle: Generally around 120 degrees for optimum visibility from different angles.\\r\\nOperating Temperature: Typically -40°C to +85°C for standard displays, though specific ranges may vary based on manufacturer specifications.\\r\\nPackaging: Available in through-hole and surface mount packages, with surface mount being more common for modern applications due to its space-saving nature.'}\n",
            "i 131\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA4C3100>, 'prompt': 'You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: HC-SR501 PIR motion sensor module. Give a description of the component having 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) Technical specifications', 'response': 'Description:\\r\\nThe HC-SR501 PIR (Passive Infrared) motion sensor module is a small electronic device that detects motion by measuring changes in infrared levels emitted by nearby objects. It consists of a pyroelectric sensor, a Fresnel lens, and control circuitry. When motion is detected, the sensor outputs a digital signal, typically used to trigger further actions in an IoT or automation system.\\r\\nApplications:\\r\\nSecurity Systems: Used in burglar alarms and surveillance systems to detect intruders or unauthorized movement.\\r\\nHome Automation: Integrated into smart home setups to trigger lights, thermostats, or other devices based on occupancy.\\r\\nEnergy Conservation: Employed in lighting systems to automatically turn lights on or off in response to motion, saving energy.\\r\\nIndustrial Automation: Utilized in factories and warehouses for automated lighting, equipment activation, and safety monitoring.\\r\\nTechnical Specifications:\\r\\nOperating Voltage: Typically operates at 5V DC.\\r\\nDetection Range: Adjustable, commonly up to 7 meters with a 110-degree detection angle.\\r\\nOutput Signal: Digital signal (usually HIGH when motion is detected, LOW otherwise).\\r\\nDelay Time: Adjustable, ranging from a few seconds to several minutes, determining how long the output remains HIGH after motion is detected.\\r\\nSensitivity: Can be adjusted to fine-tune sensitivity to motion.\\r\\nDimensions: Compact size, typically around 32mm x 24mm.\\r\\nOperating Temperature: Generally operates within a range of -15°C to +70°C.\\r\\nPower Consumption: Low power consumption, making it suitable for battery-operated devices.\\r\\nInterface: Usually features a simple interface with just three pins: VCC (power), GND (ground), and OUT (output).'}\n",
            "i 132\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFF30EB60>, 'prompt': 'You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: Water Level Detection Sensor Module. Give a description of the component having 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) Technical specifications', 'response': 'Description:\\r\\nThe Water Level Detection Sensor Module is a crucial component in IoT systems designed to monitor and manage water levels in various applications. This module typically consists of a sensor probe and accompanying circuitry enclosed in a compact housing. The sensor probe is usually composed of conductive materials or capacitive plates, enabling it to detect changes in water levels by measuring conductivity or capacitance.\\r\\nApplications:\\r\\nSmart Agriculture: In precision agriculture, this sensor module can be utilized to monitor soil moisture levels in fields or greenhouses, ensuring optimal conditions for crop growth.\\r\\nWater Management Systems: Municipalities can employ these sensors in water reservoirs, tanks, or sewer systems to monitor water levels and prevent overflow or shortage incidents.\\r\\nHome Automation: Homeowners can integrate these sensors into smart home systems to monitor water levels in sump pumps, rain barrels, or even swimming pools, providing early warnings for potential leaks or overflows.\\r\\nIndustrial Automation: Industries relying on water for manufacturing processes, cooling systems, or wastewater treatment can use these sensors to maintain optimal water levels, improving efficiency and preventing damage to equipment.\\r\\nAquarium and Aquaculture: Hobbyists and professionals can utilize these sensors to monitor water levels in aquariums, fish tanks, or aquaculture setups, ensuring a healthy environment for aquatic life.\\r\\nTechnical Specifications:\\r\\nDetection Method: The module employs either conductivity-based or capacitance-based sensing techniques to detect changes in water levels.\\r\\nOperating Voltage: Typically operates within a range of 3.3V to 5V, making it compatible with most microcontrollers and IoT platforms.\\r\\nOutput Interface: Provides a digital or analog output signal, depending on the specific module variant and application requirements.\\r\\nDetection Range: The sensor can typically detect water levels within a specified range, which may vary based on the design and calibration of the module.\\r\\nOperating Temperature: Designed to operate within a specific temperature range, ensuring reliable performance in various environmental conditions.\\r\\nInterface Compatibility: Often comes with standard interfaces such as GPIO pins, I2C, or UART for easy integration with microcontrollers and IoT development boards.\\r\\nDimensions: Compact form factor for easy installation and integration into existing systems or projects.\\r\\nAccuracy and Precision: Provides accurate and precise measurements of water levels, enabling reliable monitoring and control in diverse applications.'}\n",
            "i 133\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA4C1AB0>, 'prompt': 'Can you make a short description about the part: Stepper Motor\\n\\nIt should be divided into 3 sections as follows:\\n1) Description\\n2) Applications\\n3) technical specification', 'response': \"Description:\\nA stepper motor is an electromechanical device that converts electrical pulses into precise mechanical movements. Unlike conventional motors that rotate continuously, stepper motors move in discrete steps, making them ideal for applications requiring precise control over position and rotation. Stepper motors consist of a rotor and stator, with the rotor typically having teeth or a magnet arrangement to interact with the electromagnetic field generated by the stator.\\nApplications:\\nStepper motors find widespread use in various industrial, commercial, and consumer applications due to their precise control and reliability. Some common applications include CNC machines, 3D printers, robotics, automated manufacturing equipment, medical devices, camera positioning systems, and automotive instrumentation. They are also used in consumer electronics such as printers, scanners, disk drives, and even in household appliances like washing machines and dishwashers.\\nTechnical Specifications:\\nStep Angle: Stepper motors are characterized by their step angle, which defines the angular displacement produced by each step. Typical step angles range from 1.8 to 0.9 degrees per step, although motors with finer resolutions are available.\\nHolding Torque: This refers to the maximum torque that the motor can exert when stationary and energized. It determines the motor's ability to maintain position against external forces.\\nVoltage and Current Ratings: Stepper motors have specific voltage and current requirements, which must be matched with the driver electronics. Higher voltage ratings generally result in faster step rates and better performance.\\nPhysical Size: Stepper motors come in various sizes, ranging from small, compact designs suitable for portable devices to large, powerful motors for industrial machinery.\\nDrive Mechanism: Stepper motors can be driven in several ways, including full-step, half-step, and microstepping modes, each offering different trade-offs between resolution, torque, and smoothness of motion.\\nConstruction: Stepper motors may be constructed with various rotor and stator designs, such as permanent magnet, variable reluctance, or hybrid configurations, each suited to different applications and performance requirements.\"}\n",
            "i 134\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA64BF40>, 'prompt': 'You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: 9V 1A adapter. Give a description of the component having 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) Technical specifications', 'response': 'Description:\\r\\nThe 9V 1A adapter is a crucial component in any IoT (Internet of Things) kit. It is a power supply unit designed to convert AC (alternating current) from a standard electrical outlet into a regulated DC (direct current) output of 9 volts with a maximum current output of 1 ampere. This adapter typically features a compact design with a standard plug for easy connectivity to power sources.\\r\\nApplications:\\r\\nPowering IoT Devices: The 9V 1A adapter is commonly used to power various IoT devices such as sensors, microcontrollers, Wi-Fi modules, and small-scale electronic prototypes. It provides a stable and reliable power source to ensure continuous operation of these devices.\\r\\nPrototyping and Development: IoT enthusiasts and hardware developers utilize the adapter during the prototyping and development phase of their projects. It allows them to power their circuits and test functionalities without the need for batteries or complex power supply setups.\\r\\nHome Automation: In home automation projects, the 9V 1A adapter can be employed to power smart devices like motion sensors, temperature sensors, and smart switches. This enables the seamless integration of these devices into a centralized IoT network for remote monitoring and control.\\r\\nEducational Purposes: Educational institutions and workshops utilize the adapter to teach students about IoT concepts and hardware development. It serves as an essential tool for hands-on learning experiences, allowing students to build and experiment with IoT projects in a controlled environment.\\r\\nTechnical Specifications:\\r\\nInput Voltage: AC 100-240V, 50/60Hz\\r\\nOutput Voltage: DC 9V\\r\\nMaximum Output Current: 1A\\r\\nConnector Type: Barrel plug (typically with a 2.1mm inner diameter and 5.5mm outer diameter)\\r\\nRegulation: Voltage regulation to ensure a stable 9V output under varying load conditions\\r\\nEfficiency: High efficiency design to minimize power losses and heat generation\\r\\nProtection Features: Overcurrent protection, overvoltage protection, and short circuit protection to safeguard connected devices and the adapter itself.\\r\\nDimensions: Compact size for easy integration into IoT projects\\r\\nCertification: Compliance with safety and regulatory standards such as UL, CE, and RoHS for reliable and safe operation.'}\n",
            "i 135\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA64BE20>, 'prompt': 'You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: Button for IoT kit. Give a description of the component having 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) Technical specifications', 'response': 'Description:\\r\\nThe Button for IoT kit is a compact and versatile input device designed specifically for integration into Internet of Things (IoT) projects. It typically consists of a tactile push-button switch enclosed in a durable housing, with electrical contacts that can be easily connected to a microcontroller or IoT platform. The button provides a simple interface for users to interact with IoT systems by triggering various actions or events with a press.\\r\\nApplications:\\r\\nThe Button for IoT kit finds applications across a wide range of IoT projects, including:\\r\\nHome Automation: It can be used as a control interface for smart home devices such as lights, thermostats, and security systems. Users can press the button to turn devices on/off or to activate specific scenes or modes.\\r\\nIndustrial Monitoring: In industrial environments, the button can serve as a manual input for initiating processes, signaling alarms, or capturing data points. It can be integrated into machinery or equipment for easy access by operators.\\r\\nEnvironmental Sensing: In environmental monitoring applications, the button can be used to manually trigger data collection or initiate specific actions based on observed conditions. For example, it could be used to record environmental parameters like temperature, humidity, or air quality at predefined intervals.\\r\\nHealthcare: In healthcare settings, the button can be integrated into medical devices or wearable sensors to enable patient interaction or trigger emergency alerts. It can also be used for tracking medication adherence or monitoring vital signs.\\r\\nRetail and Hospitality: The button can enhance customer experiences in retail stores or hospitality venues by enabling interactive displays, requesting assistance, or providing feedback. It can also be integrated into point-of-sale systems for initiating transactions or loyalty programs.\\r\\nTechnical Specifications:\\r\\nType: Momentary push-button switch\\r\\nContact Configuration: Normally Open (NO) or Normally Closed (NC)\\r\\nOperating Voltage: Typically 3.3V or 5V DC\\r\\nCurrent Rating: Typically 10mA to 100mA\\r\\nOperating Temperature: -20°C to 70°C\\r\\nLifespan: Typically rated for tens of thousands to hundreds of thousands of cycles\\r\\nInterface: Typically connects via digital input/output pins or GPIO (General Purpose Input/Output)\\r\\nDimensions: Compact and lightweight, suitable for integration into various enclosures or devices\\r\\nMounting: Designed for through-hole or surface-mount installation, depending on the specific model\\r\\nCompatibility: Compatible with popular microcontrollers and IoT platforms such as Arduino, Raspberry Pi, and ESP8266/ESP32.'}\n",
            "i 136\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA4C30A0>, 'prompt': 'You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: IR Receiver module. Give a description of the component having 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) Technical specifications', 'response': 'Description:\\r\\nThe IR (Infrared) Receiver module is a vital component in IoT (Internet of Things) projects, designed to detect infrared signals emitted by remote controls or other IR transmitters. It consists of a photodiode, amplifiers, and signal processing circuitry enclosed in a compact package. When exposed to infrared radiation, the photodiode generates a small current proportional to the intensity of the received IR light. This current is then amplified and processed to produce digital signals that can be interpreted by microcontrollers or other digital devices.\\r\\nApplications:\\r\\nThe IR Receiver module finds wide-ranging applications across various industries and DIY projects:\\r\\nRemote Control Systems: It serves as the core component in IR remote control systems for TVs, air conditioners, audio systems, and other consumer electronics.\\r\\nHome Automation: Integrating IR receivers into IoT setups enables the control of household appliances such as lights, fans, and thermostats through remote commands.\\r\\nSecurity Systems: IR receivers are employed in security systems for motion detection, perimeter monitoring, and intrusion detection.\\r\\nRobotics: In robotics, IR receivers can be used for obstacle avoidance, line following, and gesture recognition.\\r\\nIndustrial Automation: They facilitate remote monitoring and control in industrial automation applications, allowing operators to manage machinery and processes from a distance.\\r\\nTechnical Specifications:\\r\\nOperating Wavelength: Typically in the range of 850nm to 950nm.\\r\\nSupply Voltage: Typically operates at 5V DC, although some modules may support a wider voltage range.\\r\\nOutput Signal: Digital output signal, usually in the form of pulses, representing the received IR data.\\r\\nDetection Range: Varies depending on the sensitivity of the photodiode and the design of the module, but typically ranges from a few centimeters to several meters.\\r\\nOperating Temperature: Generally, operates within a temperature range of -20°C to +85°C, suitable for indoor and outdoor use.\\r\\nInterface: Compatible with popular microcontroller platforms such as Arduino, Raspberry Pi, and ESP8266, usually interfaced via digital pins or communication protocols like UART or I2C.\\r\\nDimensions: Compact size for easy integration into IoT projects, typically around a few centimeters in length and width.'}\n",
            "i 137\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA64BE20>, 'prompt': 'You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: LCD 1602 module (with pin header). Give a description of the component having 3 sections as follows:\\n1) Description\\n2) Applications\\n3) Technical specifications', 'response': 'Description:\\r\\nThe LCD 1602 module, also known as a 16x2 LCD module, is a widely used alphanumeric display module in electronics projects and applications. It consists of a liquid crystal display (LCD) panel capable of displaying 16 characters per line and two lines. The module typically comes with a built-in backlight for better visibility in different lighting conditions. It is designed with a pin header for easy interfacing with microcontrollers, such as Arduino or Raspberry Pi, making it a versatile choice for various IoT (Internet of Things) and hardware projects.\\r\\nApplications:\\r\\nThe LCD 1602 module finds applications in a wide range of projects, including but not limited to:\\r\\nIoT devices: Displaying sensor data such as temperature, humidity, and pressure readings.\\r\\nHome automation: Providing status updates and control interfaces for smart home systems.\\r\\nDIY electronics: Displaying messages, prompts, and information in hobbyist projects.\\r\\nEducational purposes: Teaching basic electronics and programming concepts with interactive displays.\\r\\nIndustrial automation: Monitoring and control systems for displaying production data and alerts.\\r\\nPrototyping: Quickly visualizing data and feedback during the development of electronic systems.\\r\\nTechnical Specifications:\\r\\nDisplay: 16 characters x 2 lines\\r\\nCharacter Size: 5x8 dots\\r\\nBacklight: Typically white or blue LED backlight (color may vary)\\r\\nInterface: Parallel interface, usually using 4 or 8 data lines\\r\\nOperating Voltage: Typically operates at 5V DC, but some modules support 3.3V as well\\r\\nOperating Temperature: -20°C to +70°C\\r\\nController: Usually based on the Hitachi HD44780 or compatible controller\\r\\nDimensions: Approximately 80mm x 36mm x 13mm (L x W x H)\\r\\nPin Configuration: Typically includes 16 pins for data, control, and power connections'}\n",
            "i 138\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA4C1D20>, 'prompt': 'You have been given an IoT kit component: LCD 1602 module (with pin header). Give a description of the component having 3 sections as follows:\\n1) Description\\n2) Applications\\n3) Technical specifications', 'response': 'Description:\\r\\nThe LCD 1602 module is a liquid crystal display (LCD) component with 16 characters per line and 2 lines of text, hence the name \"1602.\" It typically comes with a pin header for easy connection to other electronic components such as microcontrollers. The module includes a backlight for visibility in low-light conditions and a contrast adjustment potentiometer for adjusting the display\\'s contrast.\\r\\nApplications:\\r\\nEmbedded Systems: The LCD 1602 module is commonly used in embedded systems for displaying information such as sensor readings, system status, or user prompts.\\r\\nDIY Electronics Projects: It\\'s popular in DIY electronics projects for displaying various kinds of information, from temperature and humidity readings to messages and alerts.\\r\\nEducation: It\\'s often used in educational settings to teach programming and electronics concepts, as it provides a tangible output for students to interact with.\\r\\nTechnical Specifications:\\r\\nDisplay Type: 16x2 character LCD display\\r\\nNumber of Characters: 16 characters per line, 2 lines\\r\\nBacklight: Typically includes a backlight for improved visibility\\r\\nInterface: Usually interfaces via a parallel interface, commonly using 4 or 8 data lines\\r\\nPower Supply: Typically operates on 5V DC power supply\\r\\nDimensions: Dimensions vary but are typically around 80mm x 35mm x 11mm (L x W x H)\\r\\nContrast Adjustment: Includes a potentiometer for adjusting display contrast\\r\\nCompatibility: Can be interfaced with various microcontrollers and development boards such as Arduino, Raspberry Pi, etc.'}\n",
            "i 139\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA64BEB0>, 'prompt': 'Can you make a short description about the part: ELEGOO Remote Control\\r\\n\\r\\nIt should be divided into 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) technical specification', 'response': \"Description:\\nThe ELEGOO Remote Control is a versatile and user-friendly device designed to provide seamless control over a variety of electronic devices. With its ergonomic design and intuitive interface, it offers convenience and efficiency for users of all levels. Whether you're controlling robots, drones, or smart home appliances, this remote ensures smooth operation and precise command execution.\\nApplications:\\nThe ELEGOO Remote Control finds applications across various domains, including robotics, home automation, and entertainment. In robotics, it serves as a vital tool for controlling robotic arms, vehicles, and other mechanized systems with precision and ease. For home automation enthusiasts, it seamlessly integrates with smart devices, allowing users to manage lighting, temperature, and security systems effortlessly. Additionally, it enhances the entertainment experience by offering intuitive control over drones, RC cars, and multimedia devices.\\nTechnical Specifications:\\nWireless Connectivity: Utilizes advanced wireless technology for reliable and responsive control.\\nCompatibility: Compatible with a wide range of electronic devices, including robots, drones, and smart home appliances.\\nErgonomic Design: Features an ergonomic design for comfortable handling and prolonged use.\\nIntuitive Interface: Equipped with an intuitive interface for easy navigation and operation.\\nRange: Offers an impressive operating range, ensuring seamless control from a distance.\\nBattery Life: Long-lasting battery life for extended usage without frequent recharging.\\nCompatibility: Compatible with both Android and iOS devices, providing versatility and flexibility in usage.\\nDimensions: Compact and lightweight design for portability and convenience.\\nAdditional Features: Includes additional features such as customizable buttons and programmable functions for enhanced versatility.\"}\n",
            "i 140\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA4C2A10>, 'prompt': 'Can you make a short description about the part: USA A to USB C\\n\\nIt should be divided into 3 sections as follows:\\n1) Description\\n2) Applications\\n3) technical specification', 'response': \"Description:\\nUSA A to USB C adapter is a small, compact accessory that allows devices with traditional USB-A ports to connect to devices featuring the modern USB-C interface. The adapter typically has a USB-A male connector on one end and a USB-C female port on the other. Its sleek design and plug-and-play functionality make it a convenient solution for bridging the gap between older and newer USB standards.\\nApplications:\\nThis adapter opens up a range of possibilities for users who own devices with different USB configurations. It enables connectivity between legacy devices such as laptops, desktops, and peripherals (like printers and keyboards) with USB-A ports, and newer gadgets like smartphones, tablets, and laptops equipped with USB-C ports. Users can transfer data, charge devices, or even connect peripherals seamlessly, regardless of the port types involved. It's particularly handy for individuals transitioning between older and newer technology ecosystems.\\nTechnical Specifications:\\nConnector 1: USB-A Male\\nConnector 2: USB-C Female\\nCompatibility: Works with devices supporting USB-A (USB 3.0/2.0) and USB-C standards\\nData Transfer Speed: Supports data transfer rates up to USB 3.1 Gen 2 (10 Gbps), ensuring fast and reliable data transmission.\\nPower Delivery: Supports power delivery protocols, allowing for charging of USB-C devices with appropriate power supplies.\\nMaterial: Constructed from durable materials to ensure long-lasting performance and reliability.\\nCompact Design: Small and lightweight for easy portability, making it convenient to carry in laptop bags, backpacks, or pockets for on-the-go use.\\nPlug-and-Play: Requires no additional drivers or software installation, making it effortless to use with compatible devices.\"}\n",
            "i 141\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA4C1D20>, 'prompt': 'You have been given an IoT kit component: 9V battery. Give a description of the component having 3 sections as follows:\\n1) Description\\n2) Applications\\n3) Technical specifications', 'response': 'Description:\\r\\nA 9V battery is a small, portable power source commonly used in various electronic devices. It typically consists of six cylindrical or rectangular cells arranged in series within a single unit. The outer casing is usually made of metal or plastic, providing protection and insulation for the internal components. The battery is designed to deliver a stable voltage of around 9 volts when fully charged, making it suitable for powering a wide range of low to medium power electronic devices.\\r\\nApplications:\\r\\nPortable electronic devices: 9V batteries are commonly used to power devices such as smoke detectors, handheld radios, portable audio equipment, and small electronic toys.\\r\\nIoT (Internet of Things) projects: In IoT applications, 9V batteries can be used to provide power to sensor nodes, microcontrollers, and other low-power devices that require wireless connectivity.\\r\\nEmergency backup power: 9V batteries can serve as backup power sources for critical equipment such as emergency lighting, alarm systems, and medical devices.\\r\\nDIY electronics projects: Hobbyists and enthusiasts often use 9V batteries to power small-scale electronics projects, prototypes, and experiments due to their compact size and convenience.\\r\\nTechnical specifications:\\r\\nVoltage: Typically around 9 volts when fully charged, gradually decreasing as the battery is depleted.\\r\\nCapacity: The capacity of a 9V battery is usually measured in milliampere-hours (mAh), indicating the amount of current the battery can deliver over a specific period. Common capacities range from around 400mAh to 1200mAh, depending on the battery chemistry and manufacturer.\\r\\nChemistry: 9V batteries are available in various chemistries, including alkaline, lithium, and rechargeable (NiMH or Li-ion). Each chemistry offers different performance characteristics in terms of capacity, discharge rate, and shelf life.\\r\\nSize and weight: The physical dimensions of a 9V battery can vary slightly depending on the manufacturer and chemistry, but they are generally compact and lightweight, making them suitable for portable applications. Typical dimensions are around 48.5mm x 26.5mm x 17.5mm, and weights range from 30 to 50 grams.'}\n",
            "i 142\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA4C3010>, 'prompt': 'You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: MAX7219 Module. Give a description of the component having 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) Technical specifications', 'response': 'Description:\\r\\nThe MAX7219 Module is a versatile integrated circuit (IC) primarily used for driving LED matrices and 7-segment displays. It acts as a serially controlled LED driver, capable of cascading multiple devices for larger displays. The module typically consists of the MAX7219 IC along with necessary supporting components like resistors and capacitors, all integrated onto a compact PCB (Printed Circuit Board). It enables users to control a significant number of LEDs with minimal microcontroller pins, making it ideal for various display applications in IoT projects.\\r\\nApplications:\\r\\nDisplay Systems: The MAX7219 Module is commonly used in various display systems such as digital clocks, scoreboards, and signage.\\r\\nIoT Devices: It finds extensive applications in IoT devices for displaying sensor data, notifications, and status indicators.\\r\\nEducation: Due to its ease of use and versatility, the MAX7219 Module is often employed in educational projects to teach electronics and programming concepts related to LED displays.\\r\\nGaming: It can be utilized in gaming peripherals like scoreboards or as part of DIY game consoles for displaying game-related information.\\r\\nTechnical Specifications:\\r\\nMax Display Resolution: 8 x 8 LEDs (64 LEDs per module)\\r\\nCommunication Protocol: Serial (SPI - Serial Peripheral Interface)\\r\\nMax Cascaded Devices: Multiple modules can be cascaded together to create larger displays.\\r\\nVoltage Range: Typically operates at 5V DC, compatible with most microcontrollers.\\r\\nCurrent Consumption: Varies based on the number of LEDs lit and the brightness settings.\\r\\nDriver IC: MAX7219, capable of multiplexing and driving LEDs efficiently.\\r\\nSupports Various Display Modes: Including static, blinking, and scanning modes for dynamic displays.\\r\\nCompact Form Factor: Typically comes in a small PCB module, making it easy to integrate into projects.'}\n",
            "i 143\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA4C1960>, 'prompt': 'You have been given an IoT kit component: 5V Relay. Give a description of the component having 3 sections as follows:\\n1) Description\\n2) Applications\\n3) Technical specifications', 'response': 'Description:\\r\\nA 5V relay is an electromechanical switch operated by an electric current to control a larger electrical circuit. It consists of a coil, an armature, a spring, and one or more sets of contacts. When the coil is energized, it creates a magnetic field that attracts the armature, causing the contacts to close or open, depending on the relay type. The relay provides isolation between the control circuit (low-voltage side) and the load circuit (high-voltage side), making it suitable for switching high-power devices using low-power control signals.\\r\\nApplications:\\r\\nHome automation: Controlling lights, fans, and appliances remotely.\\r\\nIndustrial automation: Operating machinery, motors, and pumps based on sensor inputs.\\r\\nIoT projects: Integrating with microcontrollers and sensors to create smart devices.\\r\\nAutomotive: In automotive applications, relays are used for controlling various functions such as headlights, wipers, and power windows.\\r\\nSecurity systems: Activating alarms, door locks, and surveillance cameras.\\r\\nTechnical Specifications:\\r\\nInput Voltage: 5V DC (typical, may vary depending on the relay model)\\r\\nMaximum Current Rating: This varies based on the relay model but typically ranges from a few amperes to tens of amperes.\\r\\nContact Configuration: Normally Open (NO), Normally Closed (NC), or Changeover (CO) depending on the specific relay.\\r\\nCoil Resistance: Typically in the range of tens to hundreds of ohms.\\r\\nMaximum Switching Voltage: The maximum voltage the relay contacts can handle, usually ranging from 30V DC to 250V AC.\\r\\nMaximum Switching Current: The maximum current the relay contacts can handle, typically ranging from a few milliamperes to tens of amperes.\\r\\nMechanical Endurance: The number of operations the relay can withstand before failure, usually specified in millions of cycles.'}\n",
            "i 144\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA4C2F50>, 'prompt': 'You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: 5V Relay. Give a description of the component having 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) Technical specifications', 'response': 'Description:\\r\\nA 5V Relay is an electromechanical switch that operates with a 5-volt DC input signal. It consists of a coil, an armature, a spring, and one or more sets of contacts. When the coil is energized, it creates a magnetic field that pulls the armature, closing or opening the contacts, depending on the relay type. This allows the relay to control a higher voltage circuit with a lower voltage signal.\\r\\nApplications:\\r\\nHome automation: Controlling lights, fans, and other appliances remotely.\\r\\nIndustrial automation: Integrating with PLCs (Programmable Logic Controllers) to control machinery and processes.\\r\\nIoT devices: Enabling remote control of various electronic devices and sensors.\\r\\nAutomotive applications: Controlling automotive circuits such as headlights, wipers, and power windows.\\r\\nSecurity systems: Activating alarms, door locks, and surveillance cameras.\\r\\nTechnical specifications:\\r\\nInput Voltage: 5V DC\\r\\nCoil Power Consumption: Typically around 0.4W to 1W\\r\\nContact Rating: Typically up to 10A at 250VAC or 30VDC\\r\\nContact Form: Normally Open (NO), Normally Closed (NC), or Changeover (CO)\\r\\nSwitching Time: Usually in the range of milliseconds\\r\\nMounting: Through-hole or surface mount options available\\r\\nSize: Various sizes available, typically ranging from small signal relays to larger power relays.\\r\\nOperating Temperature: Varies depending on the specific relay model, typically between -40°C to 85°C\\r\\nLifespan: Typically rated for tens of thousands to millions of switching cycles, depending on the quality and usage conditions.'}\n",
            "i 145\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA4C2EC0>, 'prompt': 'You have been given an IoT kit component: 830 Tie-Points Breadboard. Give a description of the component having 3 sections as follows:\\n1) Description\\n2) Applications\\n3) Technical specifications', 'response': 'Description:\\r\\nThe 830 Tie-Points Breadboard is a common component used in electronics prototyping and experimentation. It provides a platform for creating temporary circuits without the need for soldering. The breadboard consists of a plastic base with numerous evenly spaced holes into which electronic components can be inserted. These holes are connected internally in a grid pattern, allowing components to be easily interconnected using jumper wires.\\r\\nApplications:\\r\\nPrototyping electronic circuits: Engineers and hobbyists use breadboards to quickly assemble and test electronic circuits before soldering them onto a permanent circuit board.\\r\\nEducational purposes: Breadboards are commonly used in electronics education to teach students about circuit design and component interconnections.\\r\\nRapid experimentation: With a breadboard, users can quickly modify and iterate on circuit designs without the need for specialized tools or equipment.\\r\\nTechnical Specifications:\\r\\nNumber of tie-points: 830\\r\\nGrid pattern: Typically organized in rows and columns with each row containing interconnected tie-points\\r\\nMaterial: Plastic base with metal clips inside for connectivity\\r\\nDimensions: Standard size with dimensions typically around 16.5 cm x 5.5 cm x 1 cm (length x width x height)\\r\\nConnection method: Components are inserted into the holes on the breadboard, and connectivity is achieved through metal clips underneath the surface of the board\\r\\nCompatibility: Compatible with various electronic components such as resistors, capacitors, integrated circuits (ICs), and jumper wires'}\n",
            "i 146\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA4C3010>, 'prompt': 'You have been given an IoT kit component: Breadboard Jumper Wire. Give a description of the component having 3 sections as follows:\\n1) Description\\n2) Applications\\n3) Technical specifications', 'response': 'Description:\\r\\nBreadboard jumper wires are essential components in electronics prototyping. They are flexible wires with connectors at both ends, usually male pins or alligator clips, designed to be easily inserted into breadboards for making connections between components.\\r\\nApplications:\\r\\nPrototyping circuits: Jumper wires are commonly used to create temporary connections between electronic components on a breadboard, allowing engineers and hobbyists to quickly prototype and test circuit designs.\\r\\nEducation: They are frequently used in educational settings to teach electronics and circuitry concepts due to their simplicity and versatility.\\r\\nTroubleshooting: Jumper wires can also be used for troubleshooting purposes to quickly test connections and isolate issues within a circuit.\\r\\nDIY projects: Hobbyists and makers often use jumper wires in various DIY electronics projects, from simple LED circuits to more complex microcontroller-based systems.\\r\\nTechnical Specifications:\\r\\nLength: Breadboard jumper wires come in various lengths, typically ranging from a few centimeters to several inches, allowing for flexibility in circuit layout.\\r\\nWire gauge: The gauge of the wire determines its thickness and current-carrying capacity. Common gauges for jumper wires range from 22 AWG to 26 AWG.\\r\\nConnector types: Jumper wires may have different types of connectors at each end, such as male pins, female sockets, or alligator clips, to accommodate different types of components and connections.\\r\\nInsulation material: The insulation material used for jumper wires is usually PVC or silicone, providing electrical insulation and flexibility.\\r\\nColor coding: Jumper wires often come in different colors, which can be helpful for organizing and identifying connections within a circuit.'}\n",
            "i 147\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA4C2B00>, 'prompt': 'You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: 1 Digit 7-segment Display. Give a description of the component having 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) Technical specifications', 'response': 'Description:\\r\\nA Digit 7-segment Display is a common electronic component used to visually represent numeric digits from 0 to 9, as well as some alphanumeric characters (like letters A-F when used in hexadecimal displays). It consists of seven individual LED (Light Emitting Diode) segments arranged in a pattern resembling the number 8, with an additional LED segment for the decimal point if needed. Each segment can be individually controlled to display different digits or characters.\\r\\nApplications:\\r\\nDigit 7-segment Displays find applications in various electronic devices where numerical or limited alphanumeric information needs to be displayed. Some common applications include:\\r\\nDigital clocks and timers\\r\\nCounters and frequency meters\\r\\nDigital meters (such as voltage, current, temperature displays)\\r\\nPortable instruments and multimeters\\r\\nScoreboards and timers in sports events\\r\\nIndustrial process monitoring and control panels\\r\\nHome automation systems for displaying time, temperature, or other sensor readings\\r\\nTechnical Specifications:\\r\\nCommon Anode or Common Cathode: 7-segment displays come in two configurations: common anode and common cathode. In common anode displays, all the positive terminals of the LEDs are tied together, while in common cathode displays, all the negative terminals are tied together.\\r\\nForward Voltage (Vf): Typical operating voltage required for each LED segment, usually around 2V to 2.5V.\\r\\nForward Current (If): Maximum current allowed through each LED segment, often in the range of 5mA to 20mA.\\r\\nSize: Available in different sizes, commonly ranging from 0.3 inches to several inches diagonally.\\r\\nColor: Available in different colors such as red, green, blue, yellow, etc.\\r\\nPin Configuration: Typically, 7-segment displays have 10 pins, with either a common anode or common cathode pin and individual pins for each segment (a-g) and possibly a pin for the decimal point.\\r\\nMultiplexing Capability: Some displays support multiplexing, allowing multiple displays to be controlled using fewer pins by quickly switching between them.\\r\\nViewing Angle: Angle from which the display can be viewed clearly.\\r\\nRefresh Rate: How quickly the display can update its content, often measured in Hertz (Hz).'}\n",
            "i 148\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA4C3010>, 'prompt': 'You have been given an IoT kit component: Resistor. Give a description of the component having 3 sections as follows:\\n1) Description\\n2) Applications\\n3) Technical specifications', 'response': 'Description:\\r\\nA resistor is a passive two-terminal electrical component that limits or regulates the flow of electric current in a circuit. It is typically constructed using a material with high resistivity, such as carbon or metal, and is designed to provide a specific amount of resistance to the flow of current. Resistors come in various shapes and sizes, including axial lead resistors (cylindrical with wire leads), surface mount resistors (flat, soldered directly onto circuit boards), and variable resistors (potentiometers or rheostats that allow for adjustable resistance).\\r\\nApplications:\\r\\nResistors are used in a wide range of electronic circuits and applications, including:\\r\\nVoltage dividers: dividing the voltage in a circuit into smaller portions.\\r\\nCurrent limiting: preventing excessive current flow through components such as LEDs and transistors.\\r\\nSignal conditioning: shaping or modifying electronic signals for proper operation of circuits.\\r\\nBiasing: setting the operating point of active electronic components like transistors.\\r\\nFilter circuits: shaping the frequency response of circuits to pass or block specific frequencies.\\r\\nPull-up and pull-down resistors: ensuring stable logic levels in digital circuits.\\r\\nTemperature sensors: using the resistance change of certain materials with temperature to measure temperature variations.\\r\\nTechnical Specifications:\\r\\nResistors are characterized by several technical specifications, including:\\r\\nResistance value (measured in ohms, Ω): indicates how much resistance the component provides to the flow of current.\\r\\nTolerance: defines the range within which the actual resistance value may vary from the specified nominal value.\\r\\nPower rating (measured in watts, W): indicates the maximum amount of power the resistor can dissipate without overheating.\\r\\nTemperature coefficient of resistance (TCR): specifies how much the resistance of the resistor changes with temperature.\\r\\nOperating temperature range: defines the range of temperatures over which the resistor can safely operate without performance degradation.\\r\\nPackage type: determines the physical form factor and mounting method of the resistor, such as through-hole, surface mount, or axial lead.'}\n",
            "i 149\n",
            "item:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4032x3024 at 0x7BEFFA4C2EC0>, 'prompt': 'Can you make a short description about the part: Breadboard Jumper Wire\\r\\n\\r\\nIt should be divided into 3 sections as follows:\\r\\n1) Description\\r\\n2) Applications\\r\\n3) technical specification', 'response': \"Description:\\r\\nBreadboard jumper wires are essential components in electronics prototyping. They are flexible wires with connectors at each end, designed to easily plug into the holes of a breadboard. Typically, they come in various lengths and colors, allowing for efficient circuit building and organization.\\r\\nApplications:\\r\\nBreadboard jumper wires are widely used in electronics projects, especially in prototyping and experimentation phases. They facilitate the connection of electronic components on a breadboard, enabling rapid testing and iteration of circuit designs. They are commonly employed in hobbyist projects, educational settings, and professional development environments.\\r\\nTechnical Specifications:\\r\\nLength: Breadboard jumper wires are available in various lengths, typically ranging from a few inches to several inches long.\\r\\nConnector Type: The connectors at each end of the jumper wires are often male pin headers or female sockets, compatible with standard breadboard layouts.\\r\\nWire Gauge: The gauge of the wire varies, but it's usually thin enough to fit comfortably into the breadboard's holes while still carrying the necessary current for the components being connected.\\r\\nMaterial: Jumper wires are typically made from flexible insulated wire, such as copper or tinned copper, to ensure durability and ease of use.\\r\\nColor Coding: Many sets of jumper wires come in different colors, allowing for easy identification and organization of connections within a circuit.\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Genai Project/VLM/LLAVA_zip/LLaVA-main/\n",
        "!pwd\n",
        "!pip install -e ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmAt1dX3YuK9",
        "outputId": "f7523fa8-cd39-417c-bf67-adc6c357aa17"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1euUzSZa1IjWGSY7kHFLr2B_d6lpqAzvE/Genai Project/VLM/LLAVA_zip/LLaVA-main\n",
            "/content/drive/.shortcut-targets-by-id/1euUzSZa1IjWGSY7kHFLr2B_d6lpqAzvE/Genai Project/VLM/LLAVA_zip/LLaVA-main\n",
            "Obtaining file:///content/drive/.shortcut-targets-by-id/1euUzSZa1IjWGSY7kHFLr2B_d6lpqAzvE/Genai%20Project/VLM/LLAVA_zip/LLaVA-main\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch==2.1.2 (from llava==1.2.2.post1)\n",
            "  Downloading torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.16.2 (from llava==1.2.2.post1)\n",
            "  Downloading torchvision-0.16.2-cp310-cp310-manylinux1_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m105.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers==4.37.2 (from llava==1.2.2.post1)\n",
            "  Downloading transformers-4.37.2-py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m101.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers==0.15.1 (from llava==1.2.2.post1)\n",
            "  Downloading tokenizers-0.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sentencepiece==0.1.99 in /usr/local/lib/python3.10/dist-packages (from llava==1.2.2.post1) (0.1.99)\n",
            "Collecting shortuuid (from llava==1.2.2.post1)\n",
            "  Downloading shortuuid-1.0.13-py3-none-any.whl (10 kB)\n",
            "Collecting accelerate==0.21.0 (from llava==1.2.2.post1)\n",
            "  Downloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting peft (from llava==1.2.2.post1)\n",
            "  Downloading peft-0.10.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitsandbytes (from llava==1.2.2.post1)\n",
            "  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from llava==1.2.2.post1) (2.7.1)\n",
            "Collecting markdown2[all] (from llava==1.2.2.post1)\n",
            "  Downloading markdown2-2.4.13-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llava==1.2.2.post1) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn==1.2.2 in /usr/local/lib/python3.10/dist-packages (from llava==1.2.2.post1) (1.2.2)\n",
            "Collecting gradio==4.16.0 (from llava==1.2.2.post1)\n",
            "  Downloading gradio-4.16.0-py3-none-any.whl (16.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m85.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gradio-client==0.8.1 (from llava==1.2.2.post1)\n",
            "  Downloading gradio_client-0.8.1-py3-none-any.whl (305 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.2/305.2 kB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from llava==1.2.2.post1) (2.31.0)\n",
            "Collecting httpx==0.24.0 (from llava==1.2.2.post1)\n",
            "  Downloading httpx-0.24.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.3/75.3 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn (from llava==1.2.2.post1)\n",
            "  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi (from llava==1.2.2.post1)\n",
            "  Downloading fastapi-0.110.3-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.8/91.8 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops==0.6.1 (from llava==1.2.2.post1)\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops-exts==0.0.4 (from llava==1.2.2.post1)\n",
            "  Downloading einops_exts-0.0.4-py3-none-any.whl (3.9 kB)\n",
            "Collecting timm==0.6.13 (from llava==1.2.2.post1)\n",
            "  Downloading timm-0.6.13-py3-none-any.whl (549 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.1/549.1 kB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0->llava==1.2.2.post1) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0->llava==1.2.2.post1) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0->llava==1.2.2.post1) (6.0.1)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio==4.16.0->llava==1.2.2.post1)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0->llava==1.2.2.post1) (4.2.2)\n",
            "Collecting ffmpy (from gradio==4.16.0->llava==1.2.2.post1)\n",
            "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0->llava==1.2.2.post1) (0.20.3)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0->llava==1.2.2.post1) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0->llava==1.2.2.post1) (3.1.3)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0->llava==1.2.2.post1) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0->llava==1.2.2.post1) (3.7.1)\n",
            "Collecting orjson~=3.0 (from gradio==4.16.0->llava==1.2.2.post1)\n",
            "  Downloading orjson-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0->llava==1.2.2.post1) (2.0.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0->llava==1.2.2.post1) (9.4.0)\n",
            "Collecting pydub (from gradio==4.16.0->llava==1.2.2.post1)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart (from gradio==4.16.0->llava==1.2.2.post1)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Collecting ruff>=0.1.7 (from gradio==4.16.0->llava==1.2.2.post1)\n",
            "  Downloading ruff-0.4.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m113.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from gradio==4.16.0->llava==1.2.2.post1)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio==4.16.0->llava==1.2.2.post1)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typer[all]<1.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0->llava==1.2.2.post1) (0.9.4)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0->llava==1.2.2.post1) (4.11.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.8.1->llava==1.2.2.post1) (2023.6.0)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==0.8.1->llava==1.2.2.post1)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.24.0->llava==1.2.2.post1) (2024.2.2)\n",
            "Collecting httpcore<0.18.0,>=0.15.0 (from httpx==0.24.0->llava==1.2.2.post1)\n",
            "  Downloading httpcore-0.17.3-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx==0.24.0->llava==1.2.2.post1) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.24.0->llava==1.2.2.post1) (1.3.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.2->llava==1.2.2.post1) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.2->llava==1.2.2.post1) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.2->llava==1.2.2.post1) (3.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->llava==1.2.2.post1) (3.13.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->llava==1.2.2.post1) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->llava==1.2.2.post1) (3.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.1.2->llava==1.2.2.post1)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.1.2->llava==1.2.2.post1)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.1.2->llava==1.2.2.post1)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.1.2->llava==1.2.2.post1)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.1.2->llava==1.2.2.post1)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.1.2->llava==1.2.2.post1)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.1.2->llava==1.2.2.post1)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.1.2->llava==1.2.2.post1)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.1.2->llava==1.2.2.post1)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.18.1 (from torch==2.1.2->llava==1.2.2.post1)\n",
            "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.1.2->llava==1.2.2.post1)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Collecting triton==2.1.0 (from torch==2.1.2->llava==1.2.2.post1)\n",
            "  Downloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2->llava==1.2.2.post1) (2023.12.25)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2->llava==1.2.2.post1) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2->llava==1.2.2.post1) (4.66.2)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.2->llava==1.2.2.post1)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->llava==1.2.2.post1) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic->llava==1.2.2.post1) (2.18.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn->llava==1.2.2.post1) (8.1.7)\n",
            "Collecting h11>=0.8 (from uvicorn->llava==1.2.2.post1)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting starlette<0.38.0,>=0.37.2 (from fastapi->llava==1.2.2.post1)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pygments>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from markdown2[all]->llava==1.2.2.post1) (2.16.1)\n",
            "Collecting wavedrom (from markdown2[all]->llava==1.2.2.post1)\n",
            "  Downloading wavedrom-2.0.3.post3.tar.gz (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.7/137.7 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->llava==1.2.2.post1) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->llava==1.2.2.post1) (2.0.7)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==4.16.0->llava==1.2.2.post1) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==4.16.0->llava==1.2.2.post1) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==4.16.0->llava==1.2.2.post1) (0.12.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx==0.24.0->llava==1.2.2.post1) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.16.0->llava==1.2.2.post1) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.16.0->llava==1.2.2.post1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.16.0->llava==1.2.2.post1) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.16.0->llava==1.2.2.post1) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.16.0->llava==1.2.2.post1) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.16.0->llava==1.2.2.post1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio==4.16.0->llava==1.2.2.post1) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio==4.16.0->llava==1.2.2.post1) (2024.1)\n",
            "Collecting colorama<0.5.0,>=0.4.3 (from typer[all]<1.0,>=0.9->gradio==4.16.0->llava==1.2.2.post1)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting shellingham<2.0.0,>=1.3.0 (from typer[all]<1.0,>=0.9->gradio==4.16.0->llava==1.2.2.post1)\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio==4.16.0->llava==1.2.2.post1) (13.7.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.2->llava==1.2.2.post1) (1.3.0)\n",
            "Collecting svgwrite (from wavedrom->markdown2[all]->llava==1.2.2.post1)\n",
            "  Downloading svgwrite-1.4.3-py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.1/67.1 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from wavedrom->markdown2[all]->llava==1.2.2.post1) (1.16.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->httpcore<0.18.0,>=0.15.0->httpx==0.24.0->llava==1.2.2.post1) (1.2.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.16.0->llava==1.2.2.post1) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.16.0->llava==1.2.2.post1) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.16.0->llava==1.2.2.post1) (0.35.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.16.0->llava==1.2.2.post1) (0.18.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio==4.16.0->llava==1.2.2.post1) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio==4.16.0->llava==1.2.2.post1) (0.1.2)\n",
            "Building wheels for collected packages: llava, ffmpy, wavedrom\n",
            "  Building editable for llava (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llava: filename=llava-1.2.2.post1-0.editable-py3-none-any.whl size=18545 sha256=c53846dc4d5727593ad7253761e59493cc98506f7be36737081820482705db6a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-qthkrxeb/wheels/d1/4d/f2/0035185df49c8a654948c57e8a3e6d3dcb3297da95d417f7df\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=615faebaaa0eda87bad46d0321a26f26ea10c168ce83b09ad09df6ef0d6dd02b\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
            "  Building wheel for wavedrom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wavedrom: filename=wavedrom-2.0.3.post3-py2.py3-none-any.whl size=30055 sha256=1fc266959a37ecaa9533a1631d09182ca9f949a902f397135462dd2bf3393adb\n",
            "  Stored in directory: /root/.cache/pip/wheels/9c/52/8c/38b454b42f712f325e26f633287484c7dc1ad469e1580c5954\n",
            "Successfully built llava ffmpy wavedrom\n",
            "Installing collected packages: pydub, ffmpy, websockets, triton, tomlkit, svgwrite, shortuuid, shellingham, semantic-version, ruff, python-multipart, orjson, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, markdown2, h11, einops, colorama, aiofiles, wavedrom, uvicorn, starlette, nvidia-cusparse-cu12, nvidia-cudnn-cu12, httpcore, einops-exts, tokenizers, nvidia-cusolver-cu12, httpx, fastapi, transformers, torch, gradio-client, torchvision, gradio, bitsandbytes, accelerate, timm, peft, llava\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.2.0\n",
            "    Uninstalling triton-2.2.0:\n",
            "      Successfully uninstalled triton-2.2.0\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.19.1\n",
            "    Uninstalling tokenizers-0.19.1:\n",
            "      Successfully uninstalled tokenizers-0.19.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.40.1\n",
            "    Uninstalling transformers-4.40.1:\n",
            "      Successfully uninstalled transformers-4.40.1\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.2.1+cu121\n",
            "    Uninstalling torch-2.2.1+cu121:\n",
            "      Successfully uninstalled torch-2.2.1+cu121\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.17.1+cu121\n",
            "    Uninstalling torchvision-0.17.1+cu121:\n",
            "      Successfully uninstalled torchvision-0.17.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.2.1+cu121 requires torch==2.2.1, but you have torch 2.1.2 which is incompatible.\n",
            "torchtext 0.17.1 requires torch==2.2.1, but you have torch 2.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.21.0 aiofiles-23.2.1 bitsandbytes-0.43.1 colorama-0.4.6 einops-0.6.1 einops-exts-0.0.4 fastapi-0.110.3 ffmpy-0.3.2 gradio-4.16.0 gradio-client-0.8.1 h11-0.14.0 httpcore-0.17.3 httpx-0.24.0 llava-1.2.2.post1 markdown2-2.4.13 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 orjson-3.10.1 peft-0.10.0 pydub-0.25.1 python-multipart-0.0.9 ruff-0.4.2 semantic-version-2.10.0 shellingham-1.5.4 shortuuid-1.0.13 starlette-0.37.2 svgwrite-1.4.3 timm-0.6.13 tokenizers-0.15.1 tomlkit-0.12.0 torch-2.1.2 torchvision-0.16.2 transformers-4.37.2 triton-2.1.0 uvicorn-0.29.0 wavedrom-2.0.3.post3 websockets-11.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -e \".[train]\"\n",
        "!pip install flash-attn --no-build-isolation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5-s1ft7ZZrp",
        "outputId": "99c13034-b120-4e9a-ce2a-8fc6c8fe4575"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/drive/.shortcut-targets-by-id/1euUzSZa1IjWGSY7kHFLr2B_d6lpqAzvE/Genai%20Project/VLM/LLAVA_zip/LLaVA-main\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch==2.1.2 in /usr/local/lib/python3.10/dist-packages (from llava==1.2.2.post1) (2.1.2)\n",
            "Requirement already satisfied: torchvision==0.16.2 in /usr/local/lib/python3.10/dist-packages (from llava==1.2.2.post1) (0.16.2)\n",
            "Requirement already satisfied: transformers==4.37.2 in /usr/local/lib/python3.10/dist-packages (from llava==1.2.2.post1) (4.37.2)\n",
            "Requirement already satisfied: tokenizers==0.15.1 in /usr/local/lib/python3.10/dist-packages (from llava==1.2.2.post1) (0.15.1)\n",
            "Requirement already satisfied: sentencepiece==0.1.99 in /usr/local/lib/python3.10/dist-packages (from llava==1.2.2.post1) (0.1.99)\n",
            "Requirement already satisfied: shortuuid in /usr/local/lib/python3.10/dist-packages (from llava==1.2.2.post1) (1.0.13)\n",
            "Requirement already satisfied: accelerate==0.21.0 in /usr/local/lib/python3.10/dist-packages (from llava==1.2.2.post1) (0.21.0)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (from llava==1.2.2.post1) (0.10.0)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (from llava==1.2.2.post1) (0.43.1)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from llava==1.2.2.post1) (2.7.1)\n",
            "Requirement already satisfied: markdown2[all] in /usr/local/lib/python3.10/dist-packages (from llava==1.2.2.post1) (2.4.13)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llava==1.2.2.post1) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn==1.2.2 in /usr/local/lib/python3.10/dist-packages (from llava==1.2.2.post1) (1.2.2)\n",
            "Requirement already satisfied: gradio==4.16.0 in /usr/local/lib/python3.10/dist-packages (from llava==1.2.2.post1) (4.16.0)\n",
            "Requirement already satisfied: gradio-client==0.8.1 in /usr/local/lib/python3.10/dist-packages (from llava==1.2.2.post1) (0.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from llava==1.2.2.post1) (2.31.0)\n",
            "Requirement already satisfied: httpx==0.24.0 in /usr/local/lib/python3.10/dist-packages (from llava==1.2.2.post1) (0.24.0)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.10/dist-packages (from llava==1.2.2.post1) (0.29.0)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from llava==1.2.2.post1) (0.110.3)\n",
            "Requirement already satisfied: einops==0.6.1 in /usr/local/lib/python3.10/dist-packages (from llava==1.2.2.post1) (0.6.1)\n",
            "Requirement already satisfied: einops-exts==0.0.4 in /usr/local/lib/python3.10/dist-packages (from llava==1.2.2.post1) (0.0.4)\n",
            "Requirement already satisfied: timm==0.6.13 in /usr/local/lib/python3.10/dist-packages (from llava==1.2.2.post1) (0.6.13)\n",
            "Collecting deepspeed==0.12.6 (from llava==1.2.2.post1)\n",
            "  Downloading deepspeed-0.12.6.tar.gz (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ninja (from llava==1.2.2.post1)\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wandb (from llava==1.2.2.post1)\n",
            "  Downloading wandb-0.16.6-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0->llava==1.2.2.post1) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0->llava==1.2.2.post1) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0->llava==1.2.2.post1) (6.0.1)\n",
            "Collecting hjson (from deepspeed==0.12.6->llava==1.2.2.post1)\n",
            "  Downloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.12.6->llava==1.2.2.post1) (9.0.0)\n",
            "Collecting pynvml (from deepspeed==0.12.6->llava==1.2.2.post1)\n",
            "  Downloading pynvml-11.5.0-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.12.6->llava==1.2.2.post1) (4.66.2)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0->llava==1.2.2.post1) (23.2.1)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0->llava==1.2.2.post1) (4.2.2)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0->llava==1.2.2.post1) (0.3.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0->llava==1.2.2.post1) (0.20.3)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0->llava==1.2.2.post1) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0->llava==1.2.2.post1) (3.1.3)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0->llava==1.2.2.post1) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0->llava==1.2.2.post1) (3.7.1)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0->llava==1.2.2.post1) (3.10.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0->llava==1.2.2.post1) (2.0.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0->llava==1.2.2.post1) (9.4.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0->llava==1.2.2.post1) (0.25.1)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0->llava==1.2.2.post1) (0.0.9)\n",
            "Requirement already satisfied: ruff>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0->llava==1.2.2.post1) (0.4.2)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0->llava==1.2.2.post1) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0->llava==1.2.2.post1) (0.12.0)\n",
            "Requirement already satisfied: typer[all]<1.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0->llava==1.2.2.post1) (0.9.4)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0->llava==1.2.2.post1) (4.11.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.8.1->llava==1.2.2.post1) (2023.6.0)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.8.1->llava==1.2.2.post1) (11.0.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.24.0->llava==1.2.2.post1) (2024.2.2)\n",
            "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from httpx==0.24.0->llava==1.2.2.post1) (0.17.3)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx==0.24.0->llava==1.2.2.post1) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.24.0->llava==1.2.2.post1) (1.3.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.2->llava==1.2.2.post1) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.2->llava==1.2.2.post1) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.2->llava==1.2.2.post1) (3.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->llava==1.2.2.post1) (3.13.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->llava==1.2.2.post1) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->llava==1.2.2.post1) (3.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->llava==1.2.2.post1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->llava==1.2.2.post1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->llava==1.2.2.post1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->llava==1.2.2.post1) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->llava==1.2.2.post1) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->llava==1.2.2.post1) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->llava==1.2.2.post1) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->llava==1.2.2.post1) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->llava==1.2.2.post1) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->llava==1.2.2.post1) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->llava==1.2.2.post1) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->llava==1.2.2.post1) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2->llava==1.2.2.post1) (2023.12.25)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2->llava==1.2.2.post1) (0.4.3)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.2->llava==1.2.2.post1) (12.4.127)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->llava==1.2.2.post1) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic->llava==1.2.2.post1) (2.18.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn->llava==1.2.2.post1) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn->llava==1.2.2.post1) (0.14.0)\n",
            "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi->llava==1.2.2.post1) (0.37.2)\n",
            "Requirement already satisfied: pygments>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from markdown2[all]->llava==1.2.2.post1) (2.16.1)\n",
            "Requirement already satisfied: wavedrom in /usr/local/lib/python3.10/dist-packages (from markdown2[all]->llava==1.2.2.post1) (2.0.3.post3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->llava==1.2.2.post1) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->llava==1.2.2.post1) (2.0.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb->llava==1.2.2.post1)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentry-sdk>=1.0.0 (from wandb->llava==1.2.2.post1)\n",
            "  Downloading sentry_sdk-2.0.1-py2.py3-none-any.whl (266 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.8/266.8 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb->llava==1.2.2.post1)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting setproctitle (from wandb->llava==1.2.2.post1)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb->llava==1.2.2.post1) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb->llava==1.2.2.post1) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb->llava==1.2.2.post1) (3.20.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==4.16.0->llava==1.2.2.post1) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==4.16.0->llava==1.2.2.post1) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==4.16.0->llava==1.2.2.post1) (0.12.1)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb->llava==1.2.2.post1) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb->llava==1.2.2.post1)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx==0.24.0->llava==1.2.2.post1) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.16.0->llava==1.2.2.post1) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.16.0->llava==1.2.2.post1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.16.0->llava==1.2.2.post1) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.16.0->llava==1.2.2.post1) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.16.0->llava==1.2.2.post1) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.16.0->llava==1.2.2.post1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio==4.16.0->llava==1.2.2.post1) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio==4.16.0->llava==1.2.2.post1) (2024.1)\n",
            "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio==4.16.0->llava==1.2.2.post1) (0.4.6)\n",
            "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio==4.16.0->llava==1.2.2.post1) (1.5.4)\n",
            "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio==4.16.0->llava==1.2.2.post1) (13.7.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.2->llava==1.2.2.post1) (1.3.0)\n",
            "Requirement already satisfied: svgwrite in /usr/local/lib/python3.10/dist-packages (from wavedrom->markdown2[all]->llava==1.2.2.post1) (1.4.3)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->httpcore<0.18.0,>=0.15.0->httpx==0.24.0->llava==1.2.2.post1) (1.2.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->llava==1.2.2.post1)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.16.0->llava==1.2.2.post1) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.16.0->llava==1.2.2.post1) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.16.0->llava==1.2.2.post1) (0.35.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.16.0->llava==1.2.2.post1) (0.18.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio==4.16.0->llava==1.2.2.post1) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio==4.16.0->llava==1.2.2.post1) (0.1.2)\n",
            "Building wheels for collected packages: deepspeed, llava\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepspeed: filename=deepspeed-0.12.6-py3-none-any.whl size=1306731 sha256=228d27ff8260826ccaa391fe5ba0437d5062885c723bedc07869f08cc18f9419\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/dc/a2/f585faaed4dec84108916dcc8e8a7c129a216df8202ca32984\n",
            "  Building editable for llava (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llava: filename=llava-1.2.2.post1-0.editable-py3-none-any.whl size=18545 sha256=807c1b9bc6805a2f68061202910b6ed64fbdbe20c0a25a209712d417ffdbccb2\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-8g4jiz3e/wheels/d1/4d/f2/0035185df49c8a654948c57e8a3e6d3dcb3297da95d417f7df\n",
            "Successfully built deepspeed llava\n",
            "Installing collected packages: ninja, hjson, smmap, setproctitle, sentry-sdk, pynvml, docker-pycreds, gitdb, GitPython, wandb, deepspeed, llava\n",
            "  Attempting uninstall: llava\n",
            "    Found existing installation: llava 1.2.2.post1\n",
            "    Uninstalling llava-1.2.2.post1:\n",
            "      Successfully uninstalled llava-1.2.2.post1\n",
            "Successfully installed GitPython-3.1.43 deepspeed-0.12.6 docker-pycreds-0.4.0 gitdb-4.0.11 hjson-3.1.0 llava-1.2.2.post1 ninja-1.11.1.1 pynvml-11.5.0 sentry-sdk-2.0.1 setproctitle-1.3.3 smmap-5.0.1 wandb-0.16.6\n",
            "Collecting flash-attn\n",
            "  Downloading flash_attn-2.5.8.tar.gz (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from flash-attn) (2.1.2)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from flash-attn) (0.6.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from flash-attn) (24.0)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from flash-attn) (1.11.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->flash-attn) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->flash-attn) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->flash-attn) (1.3.0)\n",
            "Building wheels for collected packages: flash-attn\n",
            "  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flash-attn: filename=flash_attn-2.5.8-cp310-cp310-linux_x86_64.whl size=120616671 sha256=1e782463ba32d2193924771c940805d74c365435d4142df18a261fc5a2fdff82\n",
            "  Stored in directory: /root/.cache/pip/wheels/9b/5b/2b/dea8af4e954161c49ef1941938afcd91bb93689371ed12a226\n",
            "Successfully built flash-attn\n",
            "Installing collected packages: flash-attn\n",
            "Successfully installed flash-attn-2.5.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !deepspeed llava/train/train_mem.py \\\n",
        "#     --lora_enable True --lora_r 128 --lora_alpha 256 --mm_projector_lr 2e-5 \\\n",
        "#     --deepspeed ./scripts/zero3.json \\\n",
        "#     --model_name_or_path lmsys/vicuna-13b-v1.5 \\\n",
        "#     --version v1 \\\n",
        "#     --data_path ./playground/data/llava_v1_5_mix665k.json \\\n",
        "#     --image_folder ./playground/data \\\n",
        "#     --vision_tower openai/clip-vit-large-patch14-336 \\\n",
        "#     --pretrain_mm_mlp_adapter ./checkpoints/llava-v1.5-13b-pretrain/mm_projector.bin \\\n",
        "#     --mm_projector_type mlp2x_gelu \\\n",
        "#     --mm_vision_select_layer -2 \\\n",
        "#     --mm_use_im_start_end False \\\n",
        "#     --mm_use_im_patch_token False \\\n",
        "#     --image_aspect_ratio pad \\\n",
        "#     --group_by_modality_length True \\\n",
        "#     --bf16 False \\\n",
        "#     --output_dir ./checkpoints/llava-v1.5-13b-lora \\\n",
        "#     --num_train_epochs 1 \\\n",
        "#     --per_device_train_batch_size 16 \\\n",
        "#     --per_device_eval_batch_size 4 \\\n",
        "#     --gradient_accumulation_steps 1 \\\n",
        "#     --evaluation_strategy \"no\" \\\n",
        "#     --save_strategy \"steps\" \\\n",
        "#     --save_steps 50000 \\\n",
        "#     --save_total_limit 1 \\\n",
        "#     --learning_rate 2e-4 \\\n",
        "#     --weight_decay 0. \\\n",
        "#     --warmup_ratio 0.03 \\\n",
        "#     --lr_scheduler_type \"cosine\" \\\n",
        "#     --logging_steps 1 \\\n",
        "#     --tf32 False \\\n",
        "#     --model_max_length 2048 \\\n",
        "#     --gradient_checkpointing True \\\n",
        "#     --dataloader_num_workers 4 \\\n",
        "#     --lazy_preprocess True \\\n",
        "#     --report_to wandb\n",
        "\n",
        "#Set true if using A100 GPU: bf16 and tf32"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkqThpb9cJrG",
        "outputId": "e3f577c5-e5fe-4d62-daad-859c5fcaffd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-04-28 20:47:05,722] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "2024-04-28 20:47:08.305456: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-28 20:47:08.305504: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-28 20:47:08.306779: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-28 20:47:09.479440: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "[2024-04-28 20:47:10,466] [WARNING] [runner.py:202:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n",
            "[2024-04-28 20:47:10,466] [INFO] [runner.py:571:main] cmd = /usr/bin/python3 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None llava/train/train_mem.py --lora_enable True --lora_r 128 --lora_alpha 256 --mm_projector_lr 2e-5 --deepspeed ./scripts/zero3.json --model_name_or_path lmsys/vicuna-13b-v1.5 --version v1 --data_path ./playground/data/llava_v1_5_mix665k.json --image_folder ./playground/data --vision_tower openai/clip-vit-large-patch14-336 --pretrain_mm_mlp_adapter ./checkpoints/llava-v1.5-13b-pretrain/mm_projector.bin --mm_projector_type mlp2x_gelu --mm_vision_select_layer -2 --mm_use_im_start_end False --mm_use_im_patch_token False --image_aspect_ratio pad --group_by_modality_length True --bf16 False --output_dir ./checkpoints/llava-v1.5-13b-lora --num_train_epochs 1 --per_device_train_batch_size 16 --per_device_eval_batch_size 4 --gradient_accumulation_steps 1 --evaluation_strategy no --save_strategy steps --save_steps 50000 --save_total_limit 1 --learning_rate 2e-4 --weight_decay 0. --warmup_ratio 0.03 --lr_scheduler_type cosine --logging_steps 1 --tf32 False --model_max_length 2048 --gradient_checkpointing True --dataloader_num_workers 4 --lazy_preprocess True --report_to wandb\n",
            "[2024-04-28 20:47:12,737] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "2024-04-28 20:47:16.452895: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-28 20:47:16.452946: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-28 20:47:16.454090: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-28 20:47:17.613286: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "[2024-04-28 20:47:18,607] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE=libnccl-dev=2.19.3-1+cuda12.2\n",
            "[2024-04-28 20:47:18,607] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE_VERSION=2.19.3-1\n",
            "[2024-04-28 20:47:18,607] [INFO] [launch.py:138:main] 0 NCCL_VERSION=2.19.3-1\n",
            "[2024-04-28 20:47:18,608] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE_NAME=libnccl-dev\n",
            "[2024-04-28 20:47:18,608] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE=libnccl2=2.19.3-1+cuda12.2\n",
            "[2024-04-28 20:47:18,608] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE_NAME=libnccl2\n",
            "[2024-04-28 20:47:18,608] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE_VERSION=2.19.3-1\n",
            "[2024-04-28 20:47:18,608] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0]}\n",
            "[2024-04-28 20:47:18,608] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=1, node_rank=0\n",
            "[2024-04-28 20:47:18,608] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})\n",
            "[2024-04-28 20:47:18,608] [INFO] [launch.py:163:main] dist_world_size=1\n",
            "[2024-04-28 20:47:18,608] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0\n",
            "[2024-04-28 20:47:22,363] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "2024-04-28 20:47:23.657722: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-28 20:47:23.657766: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-28 20:47:23.659099: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-28 20:47:24.804891: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "[2024-04-28 20:47:25,925] [INFO] [comm.py:637:init_distributed] cdb=None\n",
            "[2024-04-28 20:47:25,925] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
            "config.json: 100% 638/638 [00:00<00:00, 3.04MB/s]\n",
            "You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n",
            "pytorch_model.bin.index.json: 100% 33.4k/33.4k [00:00<00:00, 89.7MB/s]\n",
            "Downloading shards:   0% 0/3 [00:00<?, ?it/s]\n",
            "pytorch_model-00001-of-00003.bin:   0% 0.00/9.95G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   0% 31.5M/9.95G [00:00<00:33, 296MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   1% 83.9M/9.95G [00:00<00:25, 394MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   1% 126M/9.95G [00:00<00:29, 334MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   2% 168M/9.95G [00:00<00:32, 301MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   2% 199M/9.95G [00:00<00:32, 304MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   2% 231M/9.95G [00:00<00:32, 299MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   3% 262M/9.95G [00:00<00:32, 301MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   3% 304M/9.95G [00:00<00:30, 321MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   3% 346M/9.95G [00:01<00:38, 251MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   4% 377M/9.95G [00:01<00:46, 208MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   4% 419M/9.95G [00:01<00:39, 243MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   5% 461M/9.95G [00:01<00:35, 271MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   5% 503M/9.95G [00:01<00:32, 291MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   5% 535M/9.95G [00:01<00:35, 266MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   6% 566M/9.95G [00:02<00:36, 258MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   6% 598M/9.95G [00:02<00:36, 254MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   6% 629M/9.95G [00:02<00:38, 242MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   7% 661M/9.95G [00:02<00:37, 247MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   7% 703M/9.95G [00:02<00:34, 272MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   7% 744M/9.95G [00:02<00:31, 294MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   8% 786M/9.95G [00:02<00:29, 306MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   8% 828M/9.95G [00:02<00:29, 314MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   9% 870M/9.95G [00:03<00:28, 322MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   9% 912M/9.95G [00:03<00:27, 325MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  10% 954M/9.95G [00:03<00:27, 321MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  10% 996M/9.95G [00:03<00:28, 313MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  10% 1.03G/9.95G [00:03<00:31, 285MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  11% 1.06G/9.95G [00:03<00:30, 290MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  11% 1.09G/9.95G [00:03<00:31, 279MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  11% 1.12G/9.95G [00:03<00:32, 270MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  12% 1.15G/9.95G [00:04<00:33, 265MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  12% 1.18G/9.95G [00:04<00:33, 262MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  12% 1.22G/9.95G [00:04<00:33, 257MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  13% 1.25G/9.95G [00:04<00:35, 244MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  13% 1.28G/9.95G [00:04<00:33, 255MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  13% 1.31G/9.95G [00:04<00:34, 254MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  13% 1.34G/9.95G [00:04<00:34, 251MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  14% 1.37G/9.95G [00:04<00:33, 255MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  14% 1.41G/9.95G [00:05<00:34, 248MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  14% 1.44G/9.95G [00:05<00:33, 251MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  15% 1.47G/9.95G [00:05<00:33, 254MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  15% 1.50G/9.95G [00:05<00:33, 250MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  15% 1.53G/9.95G [00:05<00:33, 255MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  16% 1.56G/9.95G [00:05<00:33, 253MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  16% 1.59G/9.95G [00:05<00:32, 254MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  16% 1.63G/9.95G [00:05<00:33, 252MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  17% 1.66G/9.95G [00:06<00:32, 252MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  17% 1.69G/9.95G [00:06<00:33, 249MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  17% 1.72G/9.95G [00:06<00:32, 253MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  18% 1.75G/9.95G [00:06<00:33, 245MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  18% 1.78G/9.95G [00:06<00:39, 206MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  18% 1.81G/9.95G [00:06<00:49, 166MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  18% 1.84G/9.95G [00:07<00:48, 168MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  19% 1.87G/9.95G [00:07<00:43, 186MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  19% 1.89G/9.95G [00:07<00:42, 188MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  19% 1.92G/9.95G [00:07<00:41, 193MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  20% 1.95G/9.95G [00:07<00:38, 210MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  20% 1.98G/9.95G [00:08<01:14, 107MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  20% 2.02G/9.95G [00:08<00:54, 145MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  21% 2.06G/9.95G [00:08<00:54, 144MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  21% 2.08G/9.95G [00:08<00:53, 146MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  21% 2.10G/9.95G [00:08<00:53, 147MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  21% 2.12G/9.95G [00:08<00:49, 158MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  22% 2.14G/9.95G [00:09<00:48, 162MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  22% 2.16G/9.95G [00:09<00:47, 165MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  22% 2.19G/9.95G [00:09<00:42, 182MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  22% 2.21G/9.95G [00:09<00:42, 180MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  23% 2.24G/9.95G [00:09<00:38, 199MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  23% 2.26G/9.95G [00:11<03:24, 37.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  23% 2.29G/9.95G [00:11<02:41, 47.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  23% 2.31G/9.95G [00:11<02:22, 53.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  23% 2.33G/9.95G [00:12<02:06, 60.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  24% 2.35G/9.95G [00:12<01:57, 64.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  24% 2.37G/9.95G [00:12<01:57, 64.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  24% 2.39G/9.95G [00:12<01:38, 77.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  24% 2.41G/9.95G [00:13<01:30, 83.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  24% 2.43G/9.95G [00:13<01:31, 82.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  25% 2.45G/9.95G [00:13<01:30, 82.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  25% 2.47G/9.95G [00:13<01:25, 87.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  25% 2.49G/9.95G [00:13<01:26, 86.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  25% 2.50G/9.95G [00:13<01:26, 86.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  25% 2.51G/9.95G [00:14<01:25, 86.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  25% 2.53G/9.95G [00:14<01:09, 107MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  26% 2.56G/9.95G [00:14<00:48, 152MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  26% 2.60G/9.95G [00:14<00:35, 206MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  26% 2.63G/9.95G [00:16<02:57, 41.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  27% 2.66G/9.95G [00:16<02:11, 55.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  27% 2.68G/9.95G [00:16<01:56, 62.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  27% 2.71G/9.95G [00:16<01:39, 72.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  28% 2.74G/9.95G [00:17<01:15, 95.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  28% 2.77G/9.95G [00:17<00:59, 121MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  28% 2.79G/9.95G [00:17<00:54, 130MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  28% 2.81G/9.95G [00:17<00:50, 141MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  29% 2.85G/9.95G [00:18<01:39, 71.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  29% 2.88G/9.95G [00:18<01:17, 91.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  29% 2.90G/9.95G [00:18<01:12, 96.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  29% 2.93G/9.95G [00:18<01:08, 102MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  30% 2.96G/9.95G [00:19<00:55, 126MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  30% 2.99G/9.95G [00:19<00:46, 149MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  30% 3.01G/9.95G [00:19<00:47, 147MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  31% 3.04G/9.95G [00:19<00:39, 174MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  31% 3.06G/9.95G [00:19<01:09, 98.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  31% 3.09G/9.95G [00:20<00:54, 127MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  31% 3.11G/9.95G [00:20<00:54, 126MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  32% 3.14G/9.95G [00:20<00:54, 124MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  32% 3.16G/9.95G [00:20<00:48, 139MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  32% 3.19G/9.95G [00:20<00:41, 165MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  32% 3.21G/9.95G [00:20<00:40, 167MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  32% 3.23G/9.95G [00:20<00:39, 168MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  33% 3.27G/9.95G [00:21<01:03, 106MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  33% 3.30G/9.95G [00:21<00:51, 129MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  34% 3.33G/9.95G [00:21<00:44, 150MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  34% 3.37G/9.95G [00:21<00:39, 167MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  34% 3.40G/9.95G [00:21<00:35, 185MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  34% 3.43G/9.95G [00:22<00:32, 198MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  35% 3.46G/9.95G [00:22<00:31, 207MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  35% 3.49G/9.95G [00:22<00:28, 230MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  36% 3.53G/9.95G [00:22<00:24, 259MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  36% 3.57G/9.95G [00:22<00:25, 250MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  36% 3.60G/9.95G [00:22<00:36, 174MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  36% 3.63G/9.95G [00:23<00:40, 157MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  37% 3.65G/9.95G [00:23<00:38, 164MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  37% 3.68G/9.95G [00:26<03:39, 28.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  37% 3.70G/9.95G [00:26<03:01, 34.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  37% 3.72G/9.95G [00:26<02:33, 40.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  38% 3.75G/9.95G [00:26<01:49, 56.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  38% 3.79G/9.95G [00:27<01:20, 76.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  38% 3.81G/9.95G [00:27<01:20, 76.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  38% 3.83G/9.95G [00:27<01:07, 90.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  39% 3.86G/9.95G [00:27<00:50, 121MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  39% 3.89G/9.95G [00:27<00:39, 152MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  40% 3.93G/9.95G [00:27<00:30, 194MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  40% 3.97G/9.95G [00:27<00:25, 231MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  40% 4.02G/9.95G [00:27<00:22, 261MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  41% 4.05G/9.95G [00:28<00:21, 272MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  41% 4.09G/9.95G [00:28<00:20, 290MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  42% 4.13G/9.95G [00:28<00:20, 278MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  42% 4.16G/9.95G [00:28<00:21, 266MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  42% 4.19G/9.95G [00:28<00:21, 263MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  42% 4.23G/9.95G [00:28<00:22, 259MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  43% 4.26G/9.95G [00:28<00:21, 259MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  43% 4.29G/9.95G [00:29<00:22, 257MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  43% 4.32G/9.95G [00:29<00:22, 254MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  44% 4.35G/9.95G [00:29<00:22, 248MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  44% 4.38G/9.95G [00:29<00:21, 255MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  44% 4.41G/9.95G [00:29<00:21, 252MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  45% 4.45G/9.95G [00:29<00:21, 251MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  45% 4.48G/9.95G [00:29<00:21, 250MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  45% 4.51G/9.95G [00:29<00:21, 252MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  46% 4.54G/9.95G [00:30<00:21, 252MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  46% 4.57G/9.95G [00:30<00:21, 251MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  46% 4.60G/9.95G [00:30<00:21, 250MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  47% 4.63G/9.95G [00:30<00:21, 247MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  47% 4.67G/9.95G [00:30<00:20, 252MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  47% 4.70G/9.95G [00:30<00:20, 254MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  48% 4.73G/9.95G [00:30<00:21, 247MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  48% 4.76G/9.95G [00:30<00:20, 254MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  48% 4.79G/9.95G [00:31<00:20, 252MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  48% 4.82G/9.95G [00:31<00:20, 252MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  49% 4.85G/9.95G [00:31<00:19, 255MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  49% 4.89G/9.95G [00:31<00:20, 252MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  49% 4.92G/9.95G [00:31<00:20, 251MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  50% 4.95G/9.95G [00:31<00:28, 177MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  50% 4.97G/9.95G [00:31<00:27, 182MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  50% 5.00G/9.95G [00:32<00:25, 197MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  51% 5.03G/9.95G [00:32<00:23, 213MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  51% 5.06G/9.95G [00:32<00:24, 203MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  51% 5.10G/9.95G [00:32<00:21, 222MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  52% 5.13G/9.95G [00:32<00:21, 222MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  52% 5.16G/9.95G [00:32<00:19, 242MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  52% 5.20G/9.95G [00:32<00:17, 269MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  53% 5.24G/9.95G [00:32<00:16, 283MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  53% 5.28G/9.95G [00:33<00:15, 297MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  54% 5.33G/9.95G [00:33<00:15, 297MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  54% 5.36G/9.95G [00:33<00:15, 302MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  54% 5.40G/9.95G [00:33<00:14, 314MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  55% 5.44G/9.95G [00:33<00:14, 300MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  55% 5.47G/9.95G [00:33<00:15, 292MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  55% 5.51G/9.95G [00:33<00:16, 274MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  56% 5.54G/9.95G [00:33<00:16, 267MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  56% 5.57G/9.95G [00:34<00:16, 265MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  56% 5.60G/9.95G [00:34<00:16, 257MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  57% 5.63G/9.95G [00:34<00:17, 245MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  57% 5.66G/9.95G [00:34<00:17, 244MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  57% 5.69G/9.95G [00:34<00:17, 246MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  58% 5.73G/9.95G [00:34<00:17, 235MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  58% 5.76G/9.95G [00:34<00:18, 231MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  58% 5.79G/9.95G [00:35<00:17, 235MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  58% 5.82G/9.95G [00:35<00:17, 233MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  59% 5.85G/9.95G [00:35<00:18, 222MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  59% 5.88G/9.95G [00:35<00:19, 212MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  59% 5.91G/9.95G [00:35<00:21, 185MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  60% 5.93G/9.95G [00:35<00:22, 181MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  60% 5.96G/9.95G [00:35<00:21, 185MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  60% 5.99G/9.95G [00:36<00:19, 199MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  60% 6.01G/9.95G [00:36<00:19, 198MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  61% 6.03G/9.95G [00:36<00:21, 182MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  61% 6.05G/9.95G [00:36<00:27, 141MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  61% 6.07G/9.95G [00:36<00:28, 137MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  61% 6.09G/9.95G [00:36<00:31, 122MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  61% 6.11G/9.95G [00:37<00:35, 108MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  62% 6.13G/9.95G [00:37<00:42, 89.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  62% 6.14G/9.95G [00:37<00:43, 88.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  62% 6.16G/9.95G [00:37<00:42, 88.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  62% 6.18G/9.95G [00:37<00:40, 93.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  62% 6.19G/9.95G [00:38<00:40, 94.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  62% 6.20G/9.95G [00:38<00:48, 78.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  62% 6.21G/9.95G [00:38<00:45, 82.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  63% 6.22G/9.95G [00:38<00:47, 78.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  63% 6.24G/9.95G [00:38<00:41, 89.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  63% 6.27G/9.95G [00:38<00:27, 132MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  63% 6.31G/9.95G [00:38<00:19, 187MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  64% 6.34G/9.95G [00:39<00:17, 204MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  64% 6.38G/9.95G [00:39<00:15, 223MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  65% 6.42G/9.95G [00:39<00:13, 256MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  65% 6.45G/9.95G [00:39<00:18, 192MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  65% 6.48G/9.95G [00:39<00:22, 155MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  65% 6.51G/9.95G [00:40<00:19, 179MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  66% 6.54G/9.95G [00:40<00:18, 188MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  66% 6.59G/9.95G [00:40<00:14, 225MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  67% 6.62G/9.95G [00:41<00:31, 106MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  67% 6.66G/9.95G [00:41<00:24, 134MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  67% 6.69G/9.95G [00:41<00:23, 140MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  67% 6.71G/9.95G [00:41<00:22, 144MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  68% 6.74G/9.95G [00:41<00:19, 162MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  68% 6.76G/9.95G [00:41<00:18, 171MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  68% 6.79G/9.95G [00:41<00:16, 188MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  69% 6.83G/9.95G [00:42<00:17, 176MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  69% 6.85G/9.95G [00:42<00:18, 167MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  69% 6.88G/9.95G [00:42<00:15, 197MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  70% 6.92G/9.95G [00:42<00:12, 235MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  70% 6.95G/9.95G [00:42<00:13, 215MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  70% 6.98G/9.95G [00:42<00:15, 196MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  71% 7.01G/9.95G [00:42<00:13, 213MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  71% 7.06G/9.95G [00:43<00:11, 243MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  71% 7.10G/9.95G [00:43<00:10, 261MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  72% 7.14G/9.95G [00:43<00:10, 278MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  72% 7.17G/9.95G [00:43<00:09, 281MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  72% 7.20G/9.95G [00:43<00:09, 280MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  73% 7.24G/9.95G [00:43<00:09, 285MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  73% 7.27G/9.95G [00:43<00:09, 290MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  73% 7.31G/9.95G [00:43<00:08, 300MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  74% 7.35G/9.95G [00:44<00:08, 315MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  74% 7.39G/9.95G [00:44<00:08, 314MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  75% 7.43G/9.95G [00:44<00:07, 324MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  75% 7.48G/9.95G [00:44<00:08, 299MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  75% 7.51G/9.95G [00:44<00:08, 284MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  76% 7.54G/9.95G [00:44<00:08, 273MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  76% 7.57G/9.95G [00:44<00:08, 272MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  76% 7.60G/9.95G [00:44<00:08, 264MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  77% 7.63G/9.95G [00:45<00:08, 261MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  77% 7.67G/9.95G [00:45<00:09, 253MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  77% 7.70G/9.95G [00:45<00:09, 250MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  78% 7.73G/9.95G [00:45<00:08, 256MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  78% 7.76G/9.95G [00:45<00:08, 250MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  78% 7.79G/9.95G [00:45<00:08, 250MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  79% 7.82G/9.95G [00:45<00:08, 247MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  79% 7.85G/9.95G [00:45<00:08, 253MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  79% 7.89G/9.95G [00:46<00:08, 254MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  80% 7.92G/9.95G [00:46<00:08, 252MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  80% 7.95G/9.95G [00:46<00:07, 258MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  80% 7.98G/9.95G [00:46<00:07, 255MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  81% 8.01G/9.95G [00:46<00:07, 254MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  81% 8.04G/9.95G [00:46<00:07, 255MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  81% 8.07G/9.95G [00:46<00:07, 238MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  81% 8.11G/9.95G [00:47<00:08, 213MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  82% 8.14G/9.95G [00:47<00:09, 193MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  82% 8.16G/9.95G [00:47<00:09, 196MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  82% 8.19G/9.95G [00:47<00:08, 205MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  83% 8.22G/9.95G [00:47<00:08, 206MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  83% 8.24G/9.95G [00:48<00:18, 94.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  83% 8.26G/9.95G [00:48<00:18, 89.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  83% 8.29G/9.95G [00:48<00:14, 118MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  84% 8.33G/9.95G [00:48<00:10, 148MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  84% 8.36G/9.95G [00:48<00:10, 151MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  84% 8.38G/9.95G [00:49<00:09, 159MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  84% 8.40G/9.95G [00:49<00:09, 167MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  85% 8.42G/9.95G [00:49<00:09, 158MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  85% 8.44G/9.95G [00:49<00:20, 73.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  85% 8.46G/9.95G [00:50<00:16, 89.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  85% 8.48G/9.95G [00:50<00:14, 102MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  85% 8.50G/9.95G [00:50<00:12, 116MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  86% 8.52G/9.95G [00:50<00:10, 132MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  86% 8.56G/9.95G [00:50<00:08, 164MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  86% 8.59G/9.95G [00:50<00:06, 198MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  87% 8.62G/9.95G [00:50<00:06, 197MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  87% 8.65G/9.95G [00:51<00:17, 76.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  87% 8.67G/9.95G [00:51<00:15, 80.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  87% 8.69G/9.95G [00:52<00:15, 79.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  88% 8.71G/9.95G [00:52<00:14, 82.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  88% 8.73G/9.95G [00:52<00:14, 86.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  88% 8.76G/9.95G [00:52<00:14, 83.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  88% 8.78G/9.95G [00:53<00:11, 101MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  89% 8.81G/9.95G [00:53<00:08, 134MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  89% 8.84G/9.95G [00:53<00:06, 161MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  89% 8.87G/9.95G [00:53<00:05, 192MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  89% 8.90G/9.95G [00:53<00:04, 217MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  90% 8.94G/9.95G [00:53<00:03, 252MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  90% 8.99G/9.95G [00:53<00:03, 272MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  91% 9.03G/9.95G [00:53<00:03, 296MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  91% 9.07G/9.95G [00:53<00:02, 293MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  92% 9.11G/9.95G [00:54<00:02, 291MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  92% 9.14G/9.95G [00:54<00:02, 293MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  92% 9.18G/9.95G [00:54<00:02, 281MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  93% 9.21G/9.95G [00:54<00:02, 266MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  93% 9.24G/9.95G [00:54<00:02, 256MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  93% 9.27G/9.95G [00:54<00:02, 269MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  93% 9.30G/9.95G [00:54<00:02, 257MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  94% 9.33G/9.95G [00:55<00:02, 254MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  94% 9.36G/9.95G [00:55<00:02, 241MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  94% 9.40G/9.95G [00:55<00:02, 238MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  95% 9.44G/9.95G [00:55<00:01, 264MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  95% 9.47G/9.95G [00:55<00:01, 241MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  95% 9.50G/9.95G [00:55<00:02, 215MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  96% 9.53G/9.95G [00:55<00:01, 222MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  96% 9.57G/9.95G [00:56<00:01, 252MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  97% 9.60G/9.95G [00:56<00:01, 258MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  97% 9.65G/9.95G [00:56<00:01, 280MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  97% 9.68G/9.95G [00:56<00:01, 258MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  98% 9.71G/9.95G [00:56<00:00, 262MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  98% 9.75G/9.95G [00:56<00:00, 267MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  98% 9.78G/9.95G [00:56<00:00, 264MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  99% 9.81G/9.95G [00:56<00:00, 222MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  99% 9.85G/9.95G [00:57<00:00, 177MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  99% 9.87G/9.95G [00:57<00:00, 180MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  99% 9.90G/9.95G [00:57<00:00, 207MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin: 100% 9.95G/9.95G [00:57<00:00, 172MB/s]\n",
            "Downloading shards:  33% 1/3 [00:58<01:56, 58.01s/it]\n",
            "pytorch_model-00002-of-00003.bin:   0% 0.00/9.90G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   0% 41.9M/9.90G [00:00<00:23, 417MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   1% 83.9M/9.90G [00:00<00:25, 390MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   1% 126M/9.90G [00:00<00:26, 368MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   2% 168M/9.90G [00:00<00:29, 326MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   2% 210M/9.90G [00:03<05:08, 31.5MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   2% 241M/9.90G [00:04<03:59, 40.4MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   3% 273M/9.90G [00:04<03:02, 52.7MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   3% 304M/9.90G [00:04<02:18, 69.4MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   3% 336M/9.90G [00:04<01:53, 84.4MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   4% 367M/9.90G [00:04<01:29, 106MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   4% 409M/9.90G [00:04<01:07, 140MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   4% 440M/9.90G [00:04<00:59, 158MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   5% 472M/9.90G [00:05<00:59, 158MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   5% 503M/9.90G [00:05<00:53, 174MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   5% 535M/9.90G [00:05<00:48, 192MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   6% 566M/9.90G [00:05<00:45, 204MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   6% 598M/9.90G [00:05<00:44, 209MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   6% 629M/9.90G [00:05<00:41, 222MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   7% 661M/9.90G [00:05<00:38, 241MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   7% 692M/9.90G [00:06<00:38, 240MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   7% 724M/9.90G [00:06<00:40, 227MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   8% 755M/9.90G [00:06<00:37, 247MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   8% 786M/9.90G [00:06<00:34, 262MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   8% 818M/9.90G [00:06<00:50, 180MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   9% 849M/9.90G [00:06<00:52, 174MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   9% 881M/9.90G [00:07<00:47, 188MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   9% 912M/9.90G [00:07<00:49, 181MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   9% 933M/9.90G [00:07<01:05, 136MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  10% 954M/9.90G [00:07<01:00, 147MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  10% 975M/9.90G [00:08<02:51, 52.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  10% 1.01G/9.90G [00:08<02:05, 71.2MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  10% 1.03G/9.90G [00:09<01:46, 83.6MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  11% 1.05G/9.90G [00:09<01:34, 93.9MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  11% 1.08G/9.90G [00:09<01:13, 120MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  11% 1.10G/9.90G [00:09<01:07, 131MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  11% 1.12G/9.90G [00:09<01:05, 134MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  12% 1.14G/9.90G [00:09<01:21, 108MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  12% 1.16G/9.90G [00:10<01:13, 119MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  12% 1.20G/9.90G [00:10<00:57, 152MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  12% 1.23G/9.90G [00:10<00:49, 177MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  13% 1.25G/9.90G [00:10<00:50, 172MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  13% 1.27G/9.90G [00:10<00:52, 164MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  13% 1.29G/9.90G [00:10<00:50, 170MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  13% 1.33G/9.90G [00:10<00:37, 226MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  14% 1.38G/9.90G [00:10<00:30, 276MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  14% 1.42G/9.90G [00:11<00:31, 267MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  15% 1.45G/9.90G [00:11<00:33, 255MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  15% 1.48G/9.90G [00:11<00:33, 253MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  15% 1.51G/9.90G [00:11<00:31, 263MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  16% 1.54G/9.90G [00:11<00:31, 265MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  16% 1.57G/9.90G [00:11<00:33, 252MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  16% 1.60G/9.90G [00:11<00:38, 217MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  17% 1.64G/9.90G [00:11<00:35, 232MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  17% 1.67G/9.90G [00:12<00:34, 238MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  17% 1.71G/9.90G [00:12<00:31, 264MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  18% 1.75G/9.90G [00:12<00:28, 287MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  18% 1.79G/9.90G [00:12<00:27, 296MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  19% 1.84G/9.90G [00:12<00:26, 308MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  19% 1.87G/9.90G [00:12<00:26, 306MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  19% 1.90G/9.90G [00:12<00:27, 294MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  20% 1.94G/9.90G [00:12<00:26, 304MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  20% 1.97G/9.90G [00:13<00:27, 294MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  20% 2.00G/9.90G [00:13<00:27, 283MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  21% 2.03G/9.90G [00:13<00:29, 267MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  21% 2.07G/9.90G [00:13<00:29, 264MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  21% 2.10G/9.90G [00:13<00:30, 260MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  21% 2.13G/9.90G [00:13<00:29, 263MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  22% 2.16G/9.90G [00:13<00:31, 248MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  22% 2.19G/9.90G [00:13<00:31, 249MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  22% 2.22G/9.90G [00:14<00:30, 249MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  23% 2.25G/9.90G [00:14<00:29, 261MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  23% 2.29G/9.90G [00:14<00:29, 259MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  23% 2.32G/9.90G [00:14<00:30, 248MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  24% 2.35G/9.90G [00:14<00:29, 254MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  24% 2.38G/9.90G [00:14<00:29, 253MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  24% 2.41G/9.90G [00:14<00:30, 249MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  25% 2.44G/9.90G [00:14<00:29, 253MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  25% 2.47G/9.90G [00:15<00:29, 252MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  25% 2.51G/9.90G [00:15<00:28, 258MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  26% 2.54G/9.90G [00:15<00:29, 246MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  26% 2.57G/9.90G [00:15<00:29, 250MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  26% 2.60G/9.90G [00:15<00:28, 254MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  27% 2.63G/9.90G [00:15<00:28, 256MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  27% 2.66G/9.90G [00:15<00:28, 254MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  27% 2.69G/9.90G [00:15<00:28, 249MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  28% 2.73G/9.90G [00:16<00:28, 248MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  28% 2.76G/9.90G [00:16<00:28, 251MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  28% 2.79G/9.90G [00:16<00:29, 239MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  28% 2.82G/9.90G [00:16<00:30, 231MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  29% 2.85G/9.90G [00:16<00:33, 209MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  29% 2.88G/9.90G [00:16<00:34, 202MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  29% 2.90G/9.90G [00:16<00:35, 200MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  30% 2.94G/9.90G [00:17<00:32, 213MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  30% 2.97G/9.90G [00:17<00:32, 212MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  30% 3.00G/9.90G [00:17<00:31, 217MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  31% 3.04G/9.90G [00:17<00:27, 249MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  31% 3.07G/9.90G [00:17<00:25, 263MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  31% 3.10G/9.90G [00:17<00:24, 275MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  32% 3.15G/9.90G [00:17<00:22, 299MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  32% 3.18G/9.90G [00:17<00:22, 294MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  32% 3.21G/9.90G [00:18<00:24, 278MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  33% 3.24G/9.90G [00:18<00:25, 264MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  33% 3.27G/9.90G [00:18<00:25, 261MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  33% 3.30G/9.90G [00:18<00:26, 248MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  34% 3.33G/9.90G [00:18<00:27, 237MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  34% 3.37G/9.90G [00:18<00:28, 231MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  34% 3.40G/9.90G [00:18<00:27, 235MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  35% 3.43G/9.90G [00:19<00:28, 229MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  35% 3.46G/9.90G [00:19<00:28, 229MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  35% 3.49G/9.90G [00:19<00:29, 218MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  36% 3.52G/9.90G [00:19<00:30, 211MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  36% 3.55G/9.90G [00:19<00:29, 216MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  36% 3.59G/9.90G [00:19<00:28, 219MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  37% 3.62G/9.90G [00:19<00:28, 220MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  37% 3.65G/9.90G [00:20<00:28, 218MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  37% 3.68G/9.90G [00:20<00:28, 220MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  37% 3.71G/9.90G [00:20<00:26, 236MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  38% 3.74G/9.90G [00:20<00:24, 254MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  38% 3.77G/9.90G [00:20<00:27, 225MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  38% 3.81G/9.90G [00:20<00:25, 242MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  39% 3.85G/9.90G [00:20<00:23, 253MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  39% 3.88G/9.90G [00:20<00:22, 264MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  40% 3.92G/9.90G [00:21<00:21, 280MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  40% 3.95G/9.90G [00:21<00:22, 261MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  40% 3.98G/9.90G [00:21<00:26, 220MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  41% 4.02G/9.90G [00:21<00:24, 241MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  41% 4.05G/9.90G [00:21<00:23, 250MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  41% 4.08G/9.90G [00:21<00:22, 260MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  42% 4.11G/9.90G [00:21<00:24, 241MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  42% 4.14G/9.90G [00:22<00:26, 214MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  42% 4.17G/9.90G [00:22<00:25, 224MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  42% 4.20G/9.90G [00:22<00:23, 243MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  43% 4.24G/9.90G [00:22<00:25, 225MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  43% 4.27G/9.90G [00:22<00:24, 231MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  43% 4.30G/9.90G [00:22<00:22, 244MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  44% 4.33G/9.90G [00:22<00:23, 241MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  44% 4.36G/9.90G [00:22<00:22, 247MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  44% 4.39G/9.90G [00:23<00:21, 255MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  45% 4.42G/9.90G [00:23<00:22, 246MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  45% 4.46G/9.90G [00:23<00:21, 258MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  45% 4.49G/9.90G [00:23<00:20, 266MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  46% 4.52G/9.90G [00:23<00:19, 278MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  46% 4.57G/9.90G [00:23<00:16, 328MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  47% 4.61G/9.90G [00:23<00:16, 318MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  47% 4.66G/9.90G [00:23<00:18, 284MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  47% 4.69G/9.90G [00:24<00:19, 263MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  48% 4.72G/9.90G [00:26<01:49, 47.4MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  48% 4.76G/9.90G [00:26<01:17, 66.8MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  48% 4.79G/9.90G [00:26<01:02, 81.2MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  49% 4.82G/9.90G [00:26<00:52, 96.9MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  49% 4.85G/9.90G [00:26<00:44, 114MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  49% 4.89G/9.90G [00:27<00:39, 128MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  50% 4.91G/9.90G [00:27<00:36, 136MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  50% 4.93G/9.90G [00:27<00:34, 145MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  50% 4.95G/9.90G [00:31<04:33, 18.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  50% 4.99G/9.90G [00:31<02:43, 30.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  51% 5.02G/9.90G [00:31<01:57, 41.7MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  51% 5.05G/9.90G [00:31<01:27, 55.3MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  51% 5.09G/9.90G [00:31<01:06, 72.8MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  52% 5.12G/9.90G [00:32<00:54, 87.5MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  52% 5.15G/9.90G [00:33<01:32, 51.4MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  52% 5.17G/9.90G [00:36<03:41, 21.4MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  53% 5.20G/9.90G [00:36<02:37, 29.9MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  53% 5.22G/9.90G [00:36<02:08, 36.4MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  53% 5.25G/9.90G [00:36<01:31, 50.6MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  53% 5.28G/9.90G [00:36<01:07, 68.6MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  54% 5.31G/9.90G [00:37<00:57, 79.6MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  54% 5.34G/9.90G [00:37<00:43, 105MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  54% 5.37G/9.90G [00:37<00:35, 126MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  55% 5.40G/9.90G [00:37<00:29, 154MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  55% 5.43G/9.90G [00:37<00:24, 183MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  55% 5.46G/9.90G [00:37<00:21, 209MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  55% 5.49G/9.90G [00:37<00:19, 227MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  56% 5.54G/9.90G [00:37<00:17, 256MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  56% 5.58G/9.90G [00:37<00:15, 277MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  57% 5.61G/9.90G [00:38<00:14, 286MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  57% 5.64G/9.90G [00:38<00:14, 293MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  57% 5.67G/9.90G [00:38<00:14, 284MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  58% 5.70G/9.90G [00:38<00:14, 280MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  58% 5.74G/9.90G [00:38<00:15, 269MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  58% 5.77G/9.90G [00:38<00:15, 263MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  59% 5.80G/9.90G [00:38<00:16, 255MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  59% 5.83G/9.90G [00:38<00:15, 257MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  59% 5.86G/9.90G [00:39<00:15, 256MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  60% 5.89G/9.90G [00:39<00:15, 264MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  60% 5.92G/9.90G [00:39<00:15, 257MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  60% 5.96G/9.90G [00:39<00:15, 257MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  60% 5.99G/9.90G [00:39<00:15, 251MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  61% 6.02G/9.90G [00:39<00:15, 253MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  61% 6.05G/9.90G [00:39<00:15, 250MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  61% 6.08G/9.90G [00:39<00:15, 250MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  62% 6.11G/9.90G [00:40<00:15, 248MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  62% 6.14G/9.90G [00:40<00:14, 255MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  62% 6.18G/9.90G [00:40<00:14, 258MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  63% 6.21G/9.90G [00:40<00:15, 238MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  63% 6.24G/9.90G [00:40<00:20, 183MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  63% 6.27G/9.90G [00:40<00:18, 193MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  64% 6.30G/9.90G [00:40<00:17, 211MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  64% 6.33G/9.90G [00:41<00:18, 196MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  64% 6.35G/9.90G [00:41<00:18, 194MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  65% 6.40G/9.90G [00:41<00:14, 237MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  65% 6.43G/9.90G [00:41<00:18, 193MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  65% 6.46G/9.90G [00:41<00:16, 207MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  66% 6.49G/9.90G [00:41<00:15, 217MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  66% 6.52G/9.90G [00:42<00:16, 200MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  66% 6.56G/9.90G [00:45<01:52, 29.8MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  66% 6.59G/9.90G [00:46<01:54, 29.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  67% 6.62G/9.90G [00:46<01:23, 39.5MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  67% 6.65G/9.90G [00:46<01:01, 52.9MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  67% 6.68G/9.90G [00:46<00:46, 69.6MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  68% 6.70G/9.90G [00:46<00:39, 81.5MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  68% 6.73G/9.90G [00:46<00:30, 104MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  68% 6.76G/9.90G [00:47<00:25, 125MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  69% 6.79G/9.90G [00:47<00:21, 144MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  69% 6.83G/9.90G [00:47<00:19, 161MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  69% 6.86G/9.90G [00:47<00:16, 180MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  70% 6.89G/9.90G [00:47<00:16, 187MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  70% 6.92G/9.90G [00:47<00:14, 201MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  70% 6.95G/9.90G [00:47<00:13, 214MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  71% 6.98G/9.90G [00:48<00:13, 210MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  71% 7.01G/9.90G [00:48<00:15, 192MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  71% 7.04G/9.90G [00:48<00:14, 196MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  71% 7.06G/9.90G [00:50<01:19, 35.9MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  72% 7.09G/9.90G [00:50<00:55, 50.4MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  72% 7.11G/9.90G [00:50<00:47, 59.3MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  72% 7.13G/9.90G [00:50<00:39, 71.0MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  72% 7.16G/9.90G [00:51<00:28, 95.8MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  73% 7.19G/9.90G [00:51<00:22, 122MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  73% 7.22G/9.90G [00:51<00:20, 132MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  73% 7.27G/9.90G [00:51<00:15, 167MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  74% 7.30G/9.90G [00:51<00:14, 182MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  74% 7.33G/9.90G [00:51<00:13, 193MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  74% 7.36G/9.90G [00:51<00:12, 205MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  75% 7.39G/9.90G [00:52<00:13, 186MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  75% 7.44G/9.90G [00:52<00:10, 241MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  75% 7.48G/9.90G [00:52<00:10, 233MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  76% 7.51G/9.90G [00:53<00:38, 62.8MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  76% 7.53G/9.90G [00:56<01:27, 27.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  76% 7.57G/9.90G [00:56<00:56, 41.0MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  77% 7.60G/9.90G [00:56<00:44, 51.7MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  77% 7.62G/9.90G [00:56<00:37, 60.9MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  77% 7.64G/9.90G [00:56<00:31, 70.9MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  77% 7.68G/9.90G [00:57<00:24, 92.6MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  78% 7.71G/9.90G [00:57<00:23, 93.2MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  78% 7.74G/9.90G [00:57<00:18, 118MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  79% 7.78G/9.90G [00:57<00:13, 154MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  79% 7.81G/9.90G [00:57<00:11, 179MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  79% 7.84G/9.90G [00:57<00:10, 203MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  80% 7.87G/9.90G [00:57<00:09, 219MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  80% 7.91G/9.90G [00:58<00:08, 238MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  80% 7.94G/9.90G [00:58<00:07, 255MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  80% 7.97G/9.90G [00:58<00:07, 261MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  81% 8.00G/9.90G [00:58<00:07, 268MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  81% 8.03G/9.90G [00:58<00:07, 259MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  81% 8.06G/9.90G [00:58<00:07, 249MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  82% 8.10G/9.90G [00:58<00:07, 243MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  82% 8.13G/9.90G [00:58<00:07, 248MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  82% 8.16G/9.90G [00:59<00:07, 239MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  83% 8.19G/9.90G [00:59<00:07, 240MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  83% 8.22G/9.90G [00:59<00:07, 238MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  83% 8.25G/9.90G [00:59<00:07, 235MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  84% 8.28G/9.90G [00:59<00:06, 232MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  84% 8.32G/9.90G [00:59<00:06, 228MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  84% 8.35G/9.90G [00:59<00:07, 221MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  85% 8.38G/9.90G [01:00<00:07, 215MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  85% 8.41G/9.90G [01:00<00:06, 222MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  85% 8.44G/9.90G [01:00<00:06, 219MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  86% 8.47G/9.90G [01:00<00:06, 218MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  86% 8.50G/9.90G [01:00<00:06, 230MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  86% 8.54G/9.90G [01:00<00:05, 230MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  86% 8.57G/9.90G [01:00<00:05, 234MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  87% 8.60G/9.90G [01:00<00:05, 245MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  87% 8.63G/9.90G [01:01<00:05, 246MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  87% 8.66G/9.90G [01:01<00:05, 239MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  88% 8.69G/9.90G [01:01<00:05, 240MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  88% 8.72G/9.90G [01:01<00:04, 246MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  88% 8.76G/9.90G [01:01<00:04, 241MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  89% 8.79G/9.90G [01:01<00:04, 243MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  89% 8.82G/9.90G [01:01<00:04, 240MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  89% 8.85G/9.90G [01:02<00:04, 241MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  90% 8.88G/9.90G [01:02<00:04, 245MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  90% 8.92G/9.90G [01:02<00:03, 272MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  90% 8.95G/9.90G [01:02<00:03, 246MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  91% 8.99G/9.90G [01:02<00:04, 227MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  91% 9.02G/9.90G [01:02<00:03, 225MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  91% 9.05G/9.90G [01:02<00:03, 224MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  92% 9.08G/9.90G [01:03<00:03, 222MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  92% 9.11G/9.90G [01:03<00:03, 224MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  92% 9.15G/9.90G [01:03<00:02, 252MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  93% 9.19G/9.90G [01:03<00:02, 261MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  93% 9.22G/9.90G [01:03<00:02, 271MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  93% 9.25G/9.90G [01:03<00:02, 271MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  94% 9.28G/9.90G [01:03<00:02, 278MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  94% 9.31G/9.90G [01:03<00:02, 286MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  94% 9.34G/9.90G [01:03<00:01, 291MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  95% 9.38G/9.90G [01:04<00:01, 304MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  95% 9.43G/9.90G [01:04<00:01, 313MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  96% 9.47G/9.90G [01:04<00:01, 321MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  96% 9.51G/9.90G [01:04<00:01, 309MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  96% 9.54G/9.90G [01:04<00:01, 292MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  97% 9.57G/9.90G [01:04<00:01, 278MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  97% 9.60G/9.90G [01:04<00:01, 274MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  97% 9.64G/9.90G [01:04<00:01, 259MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  98% 9.67G/9.90G [01:05<00:00, 265MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  98% 9.70G/9.90G [01:05<00:00, 244MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  98% 9.73G/9.90G [01:05<00:00, 252MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  99% 9.76G/9.90G [01:05<00:00, 261MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  99% 9.79G/9.90G [01:05<00:00, 257MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  99% 9.83G/9.90G [01:05<00:00, 257MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin: 100% 9.86G/9.90G [01:05<00:00, 259MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin: 100% 9.90G/9.90G [01:06<00:00, 150MB/s]\n",
            "Downloading shards:  67% 2/3 [02:04<01:02, 62.89s/it]\n",
            "pytorch_model-00003-of-00003.bin:   0% 0.00/6.18G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:   1% 41.9M/6.18G [00:00<00:19, 307MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:   1% 83.9M/6.18G [00:00<00:20, 293MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:   2% 126M/6.18G [00:00<00:19, 316MB/s] \u001b[A\n",
            "pytorch_model-00003-of-00003.bin:   3% 168M/6.18G [00:00<00:20, 299MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:   3% 199M/6.18G [00:00<00:20, 286MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:   4% 231M/6.18G [00:00<00:23, 251MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:   4% 262M/6.18G [00:00<00:23, 256MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:   5% 294M/6.18G [00:01<00:23, 248MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:   5% 336M/6.18G [00:01<00:21, 266MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:   6% 367M/6.18G [00:01<00:21, 271MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:   6% 398M/6.18G [00:01<00:20, 278MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:   7% 440M/6.18G [00:01<00:19, 295MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:   8% 482M/6.18G [00:01<00:18, 313MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:   8% 524M/6.18G [00:01<00:17, 319MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:   9% 566M/6.18G [00:01<00:18, 307MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  10% 598M/6.18G [00:02<00:28, 193MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  10% 629M/6.18G [00:02<00:26, 208MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  11% 671M/6.18G [00:02<00:23, 233MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  11% 703M/6.18G [00:02<00:22, 245MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  12% 744M/6.18G [00:02<00:20, 264MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  13% 786M/6.18G [00:02<00:19, 282MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  13% 818M/6.18G [00:03<00:18, 288MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  14% 849M/6.18G [00:03<00:18, 289MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  14% 891M/6.18G [00:03<00:17, 306MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  15% 923M/6.18G [00:03<00:17, 297MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  15% 954M/6.18G [00:03<00:19, 267MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  16% 996M/6.18G [00:03<00:18, 274MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  17% 1.03G/6.18G [00:03<00:19, 270MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  17% 1.06G/6.18G [00:03<00:19, 257MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  18% 1.09G/6.18G [00:04<00:19, 262MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  18% 1.12G/6.18G [00:04<00:21, 241MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  19% 1.15G/6.18G [00:04<00:23, 218MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  19% 1.18G/6.18G [00:04<00:24, 206MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  20% 1.22G/6.18G [00:04<00:23, 208MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  20% 1.25G/6.18G [00:04<00:23, 208MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  21% 1.28G/6.18G [00:05<00:25, 191MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  21% 1.31G/6.18G [00:05<00:22, 213MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  22% 1.36G/6.18G [00:05<00:19, 242MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  23% 1.39G/6.18G [00:05<00:21, 224MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  23% 1.43G/6.18G [00:05<00:22, 213MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  24% 1.46G/6.18G [00:05<00:22, 212MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  24% 1.49G/6.18G [00:06<00:24, 189MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  24% 1.51G/6.18G [00:10<03:30, 22.1MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  25% 1.55G/6.18G [00:10<02:15, 34.2MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  26% 1.58G/6.18G [00:10<01:41, 45.5MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  26% 1.60G/6.18G [00:10<01:24, 53.9MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  26% 1.63G/6.18G [00:10<01:10, 64.5MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  27% 1.65G/6.18G [00:10<00:58, 77.8MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  27% 1.67G/6.18G [00:10<00:49, 91.4MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  27% 1.70G/6.18G [00:10<00:38, 116MB/s] \u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  28% 1.72G/6.18G [00:11<00:34, 127MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  28% 1.74G/6.18G [00:11<00:33, 134MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  29% 1.76G/6.18G [00:14<03:29, 21.0MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  29% 1.80G/6.18G [00:14<02:01, 36.1MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  30% 1.84G/6.18G [00:14<01:27, 49.9MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  30% 1.87G/6.18G [00:14<01:04, 67.1MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  31% 1.90G/6.18G [00:14<00:50, 85.3MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  31% 1.93G/6.18G [00:15<00:42, 98.9MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  32% 1.97G/6.18G [00:15<00:31, 135MB/s] \u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  33% 2.01G/6.18G [00:15<00:23, 176MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  33% 2.04G/6.18G [00:15<00:25, 165MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  34% 2.08G/6.18G [00:15<00:24, 170MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  34% 2.11G/6.18G [00:15<00:22, 184MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  35% 2.14G/6.18G [00:15<00:22, 179MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  35% 2.17G/6.18G [00:20<02:47, 24.0MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  35% 2.19G/6.18G [00:20<02:14, 29.6MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  36% 2.22G/6.18G [00:20<01:37, 40.7MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  36% 2.25G/6.18G [00:20<01:11, 54.9MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  37% 2.29G/6.18G [00:20<00:53, 73.3MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  38% 2.32G/6.18G [00:20<00:41, 93.8MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  38% 2.35G/6.18G [00:20<00:32, 119MB/s] \u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  39% 2.38G/6.18G [00:21<00:31, 121MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  39% 2.41G/6.18G [00:21<00:26, 140MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  40% 2.44G/6.18G [00:21<00:25, 149MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  40% 2.47G/6.18G [00:21<00:22, 165MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  41% 2.51G/6.18G [00:21<00:19, 191MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  41% 2.55G/6.18G [00:21<00:16, 226MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  42% 2.59G/6.18G [00:21<00:14, 246MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  42% 2.62G/6.18G [00:21<00:14, 250MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  43% 2.65G/6.18G [00:22<00:13, 261MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  44% 2.69G/6.18G [00:22<00:12, 285MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  44% 2.74G/6.18G [00:22<00:11, 295MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  45% 2.78G/6.18G [00:22<00:11, 306MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  46% 2.82G/6.18G [00:22<00:10, 315MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  46% 2.86G/6.18G [00:22<00:11, 297MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  47% 2.89G/6.18G [00:22<00:11, 288MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  47% 2.93G/6.18G [00:23<00:11, 275MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  48% 2.96G/6.18G [00:23<00:11, 269MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  48% 2.99G/6.18G [00:23<00:12, 260MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  49% 3.02G/6.18G [00:23<00:12, 259MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  49% 3.05G/6.18G [00:23<00:12, 260MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  50% 3.08G/6.18G [00:23<00:12, 252MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  50% 3.11G/6.18G [00:23<00:12, 254MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  51% 3.15G/6.18G [00:23<00:11, 256MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  51% 3.18G/6.18G [00:24<00:11, 255MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  52% 3.21G/6.18G [00:24<00:12, 234MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  52% 3.24G/6.18G [00:24<00:11, 252MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  53% 3.27G/6.18G [00:24<00:16, 179MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  53% 3.30G/6.18G [00:24<00:14, 204MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  54% 3.34G/6.18G [00:24<00:11, 237MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  55% 3.38G/6.18G [00:24<00:11, 235MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  55% 3.41G/6.18G [00:25<00:28, 98.2MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  56% 3.46G/6.18G [00:25<00:18, 145MB/s] \u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  57% 3.50G/6.18G [00:25<00:15, 174MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  57% 3.53G/6.18G [00:26<00:14, 182MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  58% 3.57G/6.18G [00:26<00:12, 201MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  58% 3.60G/6.18G [00:26<00:11, 222MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  59% 3.63G/6.18G [00:26<00:10, 237MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  59% 3.67G/6.18G [00:26<00:09, 262MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  60% 3.71G/6.18G [00:26<00:09, 272MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  61% 3.75G/6.18G [00:26<00:08, 287MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  61% 3.80G/6.18G [00:26<00:08, 297MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  62% 3.83G/6.18G [00:27<00:08, 286MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  62% 3.86G/6.18G [00:27<00:07, 293MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  63% 3.89G/6.18G [00:27<00:07, 295MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  63% 3.92G/6.18G [00:27<00:07, 287MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  64% 3.95G/6.18G [00:27<00:07, 283MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  64% 3.98G/6.18G [00:27<00:08, 267MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  65% 4.02G/6.18G [00:27<00:08, 259MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  66% 4.05G/6.18G [00:27<00:08, 260MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  66% 4.08G/6.18G [00:28<00:07, 264MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  67% 4.11G/6.18G [00:28<00:08, 251MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  67% 4.14G/6.18G [00:28<00:08, 247MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  68% 4.17G/6.18G [00:28<00:07, 256MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  68% 4.20G/6.18G [00:28<00:07, 255MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  69% 4.24G/6.18G [00:28<00:07, 251MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  69% 4.27G/6.18G [00:28<00:07, 253MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  70% 4.30G/6.18G [00:28<00:07, 257MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  70% 4.33G/6.18G [00:29<00:07, 249MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  71% 4.36G/6.18G [00:29<00:07, 251MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  71% 4.39G/6.18G [00:29<00:07, 253MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  72% 4.42G/6.18G [00:29<00:06, 257MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  72% 4.46G/6.18G [00:29<00:06, 254MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  73% 4.49G/6.18G [00:29<00:06, 252MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  73% 4.52G/6.18G [00:29<00:06, 254MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  74% 4.55G/6.18G [00:29<00:06, 253MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  74% 4.58G/6.18G [00:30<00:06, 249MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  75% 4.61G/6.18G [00:30<00:06, 245MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  75% 4.65G/6.18G [00:30<00:06, 249MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  76% 4.68G/6.18G [00:30<00:05, 252MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  76% 4.71G/6.18G [00:30<00:05, 245MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  77% 4.74G/6.18G [00:30<00:05, 244MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  77% 4.77G/6.18G [00:30<00:05, 246MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  78% 4.80G/6.18G [00:31<00:06, 200MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  78% 4.83G/6.18G [00:31<00:06, 199MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  79% 4.87G/6.18G [00:31<00:06, 204MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  79% 4.90G/6.18G [00:31<00:06, 198MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  80% 4.92G/6.18G [00:31<00:06, 192MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  80% 4.94G/6.18G [00:32<00:16, 73.0MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  80% 4.96G/6.18G [00:33<00:34, 35.7MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  81% 4.99G/6.18G [00:34<00:23, 50.3MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  81% 5.01G/6.18G [00:34<00:19, 61.4MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  81% 5.03G/6.18G [00:34<00:15, 73.4MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  82% 5.06G/6.18G [00:34<00:11, 95.9MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  82% 5.10G/6.18G [00:34<00:09, 118MB/s] \u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  83% 5.12G/6.18G [00:34<00:08, 121MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  83% 5.14G/6.18G [00:35<00:18, 57.4MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  84% 5.18G/6.18G [00:35<00:11, 88.9MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  84% 5.21G/6.18G [00:35<00:08, 113MB/s] \u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  85% 5.24G/6.18G [00:36<00:07, 131MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  85% 5.27G/6.18G [00:36<00:08, 112MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  86% 5.33G/6.18G [00:36<00:05, 163MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  87% 5.36G/6.18G [00:36<00:04, 183MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  87% 5.39G/6.18G [00:36<00:04, 181MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  88% 5.42G/6.18G [00:40<00:29, 26.1MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  88% 5.45G/6.18G [00:40<00:20, 35.4MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  89% 5.48G/6.18G [00:40<00:14, 47.2MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  89% 5.52G/6.18G [00:41<00:11, 58.9MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  90% 5.54G/6.18G [00:41<00:09, 67.8MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  90% 5.56G/6.18G [00:41<00:07, 80.3MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  90% 5.59G/6.18G [00:41<00:05, 104MB/s] \u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  91% 5.61G/6.18G [00:41<00:04, 118MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  91% 5.64G/6.18G [00:41<00:03, 137MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  92% 5.67G/6.18G [00:41<00:03, 164MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  92% 5.71G/6.18G [00:42<00:02, 204MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  93% 5.75G/6.18G [00:42<00:01, 222MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  94% 5.78G/6.18G [00:42<00:01, 239MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  94% 5.81G/6.18G [00:42<00:01, 257MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  95% 5.84G/6.18G [00:42<00:01, 270MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  95% 5.87G/6.18G [00:42<00:01, 280MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  96% 5.90G/6.18G [00:42<00:00, 282MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  96% 5.93G/6.18G [00:42<00:00, 287MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  97% 5.97G/6.18G [00:42<00:00, 270MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  97% 6.00G/6.18G [00:43<00:00, 263MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  98% 6.03G/6.18G [00:43<00:00, 263MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  98% 6.06G/6.18G [00:43<00:00, 260MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  99% 6.09G/6.18G [00:43<00:00, 258MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  99% 6.12G/6.18G [00:43<00:00, 252MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin: 100% 6.18G/6.18G [00:43<00:00, 141MB/s]\n",
            "Downloading shards: 100% 3/3 [02:48<00:00, 56.13s/it]\n",
            "You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour\n",
            "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
            "Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes. No dtype was provided, you should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator.\n",
            "Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes. No dtype was provided, you should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator.\n",
            "[2024-04-28 20:50:20,718] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 98, num_elems = 3.65B\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/.shortcut-targets-by-id/1euUzSZa1IjWGSY7kHFLr2B_d6lpqAzvE/Genai Project/VLM/LLAVA_zip/LLaVA-main/llava/train/train_mem.py\", line 4, in <module>\n",
            "    train(attn_implementation=\"flash_attention_2\")\n",
            "  File \"/content/drive/.shortcut-targets-by-id/1euUzSZa1IjWGSY7kHFLr2B_d6lpqAzvE/Genai Project/VLM/LLAVA_zip/LLaVA-main/llava/train/train.py\", line 827, in train\n",
            "    model = LlavaLlamaForCausalLM.from_pretrained(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\", line 3594, in from_pretrained\n",
            "    model = cls(config, *model_args, **model_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/deepspeed/runtime/zero/partition_parameters.py\", line 459, in wrapper\n",
            "    f(module, *args, **kwargs)\n",
            "  File \"/content/drive/.shortcut-targets-by-id/1euUzSZa1IjWGSY7kHFLr2B_d6lpqAzvE/Genai Project/VLM/LLAVA_zip/LLaVA-main/llava/model/language_model/llava_llama.py\", line 46, in __init__\n",
            "    self.model = LlavaLlamaModel(config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/deepspeed/runtime/zero/partition_parameters.py\", line 459, in wrapper\n",
            "    f(module, *args, **kwargs)\n",
            "  File \"/content/drive/.shortcut-targets-by-id/1euUzSZa1IjWGSY7kHFLr2B_d6lpqAzvE/Genai Project/VLM/LLAVA_zip/LLaVA-main/llava/model/language_model/llava_llama.py\", line 38, in __init__\n",
            "    super(LlavaLlamaModel, self).__init__(config)\n",
            "  File \"/content/drive/.shortcut-targets-by-id/1euUzSZa1IjWGSY7kHFLr2B_d6lpqAzvE/Genai Project/VLM/LLAVA_zip/LLaVA-main/llava/model/llava_arch.py\", line 32, in __init__\n",
            "    super(LlavaMetaModel, self).__init__(config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/deepspeed/runtime/zero/partition_parameters.py\", line 459, in wrapper\n",
            "    f(module, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\", line 958, in __init__\n",
            "    [LlamaDecoderLayer(config, layer_idx) for layer_idx in range(config.num_hidden_layers)]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\", line 958, in <listcomp>\n",
            "    [LlamaDecoderLayer(config, layer_idx) for layer_idx in range(config.num_hidden_layers)]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/deepspeed/runtime/zero/partition_parameters.py\", line 459, in wrapper\n",
            "    f(module, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\", line 760, in __init__\n",
            "    self.mlp = LlamaMLP(config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/deepspeed/runtime/zero/partition_parameters.py\", line 459, in wrapper\n",
            "    f(module, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\", line 247, in __init__\n",
            "    self.down_proj = nn.Linear(self.intermediate_size, self.hidden_size, bias=False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/deepspeed/runtime/zero/partition_parameters.py\", line 466, in wrapper\n",
            "    self._post_init_method(module)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/deepspeed/runtime/zero/partition_parameters.py\", line 1000, in _post_init_method\n",
            "    self._zero_init_param(param)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/deepspeed/runtime/zero/partition_parameters.py\", line 959, in _zero_init_param\n",
            "    param.partition()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/deepspeed/runtime/zero/partition_parameters.py\", line 1275, in partition\n",
            "    self._partition(param_list, has_been_updated=has_been_updated)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/deepspeed/runtime/zero/partition_parameters.py\", line 1424, in _partition\n",
            "    self._partition_param(param, has_been_updated=has_been_updated)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
            "    ret_val = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/deepspeed/runtime/zero/partition_parameters.py\", line 1489, in _partition_param\n",
            "    partitioned_tensor = torch.empty(partition_size, dtype=param.dtype, device=device)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/deepspeed/runtime/zero/partition_parameters.py\", line 244, in wrapped_fn\n",
            "    tensor: Tensor = fn(*args, **kwargs)\n",
            "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 270.00 MiB. GPU 0 has a total capacty of 14.75 GiB of which 167.06 MiB is free. Process 61221 has 14.58 GiB memory in use. Of the allocated memory 13.65 GiB is allocated by PyTorch, and 683.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "[2024-04-28 20:50:23,558] [INFO] [launch.py:315:sigkill_handler] Killing subprocess 5654\n",
            "[2024-04-28 20:50:23,559] [ERROR] [launch.py:321:sigkill_handler] ['/usr/bin/python3', '-u', 'llava/train/train_mem.py', '--local_rank=0', '--lora_enable', 'True', '--lora_r', '128', '--lora_alpha', '256', '--mm_projector_lr', '2e-5', '--deepspeed', './scripts/zero3.json', '--model_name_or_path', 'lmsys/vicuna-13b-v1.5', '--version', 'v1', '--data_path', './playground/data/llava_v1_5_mix665k.json', '--image_folder', './playground/data', '--vision_tower', 'openai/clip-vit-large-patch14-336', '--pretrain_mm_mlp_adapter', './checkpoints/llava-v1.5-13b-pretrain/mm_projector.bin', '--mm_projector_type', 'mlp2x_gelu', '--mm_vision_select_layer', '-2', '--mm_use_im_start_end', 'False', '--mm_use_im_patch_token', 'False', '--image_aspect_ratio', 'pad', '--group_by_modality_length', 'True', '--bf16', 'False', '--output_dir', './checkpoints/llava-v1.5-13b-lora', '--num_train_epochs', '1', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '1', '--evaluation_strategy', 'no', '--save_strategy', 'steps', '--save_steps', '50000', '--save_total_limit', '1', '--learning_rate', '2e-4', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--lr_scheduler_type', 'cosine', '--logging_steps', '1', '--tf32', 'False', '--model_max_length', '2048', '--gradient_checkpointing', 'True', '--dataloader_num_workers', '4', '--lazy_preprocess', 'True', '--report_to', 'wandb'] exits with return code = 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !deepspeed llava/train/train_mem.py \\\n",
        "#     --deepspeed scripts/zero2.json \\\n",
        "#     --lora_enable True \\\n",
        "#     --lora_r 128 \\\n",
        "#     --lora_alpha 256 \\\n",
        "#     --mm_projector_lr 2e-5 \\\n",
        "#     -- bits 4 \\\n",
        "#     --model_name_or_path liuhaotian/llava-v1.5-7b \\\n",
        "#     --version llava_llama_2 \\\n",
        "#     --data_path ../../dataset/train/dataset.json \\\n",
        "#     --image_folder ../../dataset/images/ \\\n",
        "#     --vision_tower openai/clip-vit-large-patch14-336 \\\n",
        "#     --mm_projector_type mlp2x_gelu \\\n",
        "#     --mm_vision_select_layer -2 \\\n",
        "#     --mm_use_im_start_end False \\\n",
        "#     --mm_use_im_patch_token False \\\n",
        "#     --image_aspect_ratio pad \\\n",
        "#     --group_by_modality_length True \\\n",
        "#     --bf16 True \\\n",
        "#     --output_dir llava/checkpoints/llava-v1.5-7b-lora \\\n",
        "#     --num_train_epochs 2 \\\n",
        "#     --per_device_train_batch_size 8 \\\n",
        "#     --per_device_eval_batch_size 8 \\\n",
        "#     --gradient_accumulation_steps 16 \\\n",
        "#     --evaluation_strategy 'no' \\\n",
        "#     --save_strategy \"steps\" \\\n",
        "#     --save_steps 50000 \\\n",
        "#     --save_total_limit 1 \\\n",
        "#     --learning_rate 2e-4 \\\n",
        "#     --weight_decay 0. \\\n",
        "#     --warmup_ratio 0.03 \\\n",
        "#     --lr_scheduler_type \"cosine\" \\\n",
        "#     --logging_steps 1 \\\n",
        "#     --tf32 True \\\n",
        "#     --model_max_length 2048 \\\n",
        "#     --gradient_checkpointing True \\\n",
        "#     --dataloader_num_workers 4 \\\n",
        "#     --lazy_preprocess True \\\n",
        "#     --report_to wandb"
      ],
      "metadata": {
        "id": "mP3bdxZ7YXwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!deepspeed llava/train/train_mem.py \\\n",
        "    --deepspeed scripts/zero2.json \\\n",
        "    --lora_enable True \\\n",
        "    --lora_r 64 \\\n",
        "    --lora_alpha 128 \\\n",
        "    --mm_projector_lr 2e-5 \\\n",
        "    --model_name_or_path liuhaotian/llava-v1.5-7b \\\n",
        "    --version llava_llama_2 \\\n",
        "    --data_path ../../dataset/train/dataset.json \\\n",
        "    --image_folder ../../dataset/images/ \\\n",
        "    --vision_tower openai/clip-vit-large-patch14-336 \\\n",
        "    --mm_projector_type mlp2x_gelu \\\n",
        "    --mm_vision_select_layer -2 \\\n",
        "    --mm_use_im_start_end False \\\n",
        "    --mm_use_im_patch_token False \\\n",
        "    --image_aspect_ratio pad \\\n",
        "    --group_by_modality_length True \\\n",
        "    --bf16 True \\\n",
        "    --output_dir llava/checkpoints/llava-v1.5-7b-lora \\\n",
        "    --num_train_epochs 10 \\\n",
        "    --per_device_train_batch_size 4 \\\n",
        "    --per_device_eval_batch_size 4 \\\n",
        "    --gradient_accumulation_steps 32 \\\n",
        "    --evaluation_strategy 'no' \\\n",
        "    --save_strategy \"steps\" \\\n",
        "    --save_steps 50000 \\\n",
        "    --save_total_limit 1 \\\n",
        "    --learning_rate 2e-4 \\\n",
        "    --weight_decay 0. \\\n",
        "    --warmup_ratio 0.03 \\\n",
        "    --lr_scheduler_type \"cosine\" \\\n",
        "    --logging_steps 1 \\\n",
        "    --tf32 True \\\n",
        "    --model_max_length 2048 \\\n",
        "    --gradient_checkpointing True \\\n",
        "    --dataloader_num_workers 4 \\\n",
        "    --lazy_preprocess True \\\n",
        "    --report_to wandb\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awWRtHpeew6G",
        "outputId": "ea10dd0c-fdf3-4fc4-d687-d68dbd300f58"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-04-30 21:12:52,621] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "2024-04-30 21:12:56.099896: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-30 21:12:56.099952: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-30 21:12:56.101789: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-30 21:12:57.320925: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "[2024-04-30 21:12:58,351] [WARNING] [runner.py:202:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n",
            "[2024-04-30 21:12:58,352] [INFO] [runner.py:571:main] cmd = /usr/bin/python3 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None llava/train/train_mem.py --deepspeed scripts/zero2.json --lora_enable True --lora_r 64 --lora_alpha 128 --mm_projector_lr 2e-5 --model_name_or_path liuhaotian/llava-v1.5-7b --version llava_llama_2 --data_path ../../dataset/train/dataset.json --image_folder ../../dataset/images/ --vision_tower openai/clip-vit-large-patch14-336 --mm_projector_type mlp2x_gelu --mm_vision_select_layer -2 --mm_use_im_start_end False --mm_use_im_patch_token False --image_aspect_ratio pad --group_by_modality_length True --bf16 True --output_dir llava/checkpoints/llava-v1.5-7b-lora --num_train_epochs 10 --per_device_train_batch_size 4 --per_device_eval_batch_size 4 --gradient_accumulation_steps 32 --evaluation_strategy no --save_strategy steps --save_steps 50000 --save_total_limit 1 --learning_rate 2e-4 --weight_decay 0. --warmup_ratio 0.03 --lr_scheduler_type cosine --logging_steps 1 --tf32 True --model_max_length 2048 --gradient_checkpointing True --dataloader_num_workers 4 --lazy_preprocess True --report_to wandb\n",
            "[2024-04-30 21:13:00,777] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "2024-04-30 21:13:03.640802: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-30 21:13:03.640856: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-30 21:13:03.641995: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-30 21:13:04.814792: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "[2024-04-30 21:13:05,793] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE=libnccl-dev=2.19.3-1+cuda12.2\n",
            "[2024-04-30 21:13:05,793] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE_VERSION=2.19.3-1\n",
            "[2024-04-30 21:13:05,793] [INFO] [launch.py:138:main] 0 NCCL_VERSION=2.19.3-1\n",
            "[2024-04-30 21:13:05,793] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE_NAME=libnccl-dev\n",
            "[2024-04-30 21:13:05,793] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE=libnccl2=2.19.3-1+cuda12.2\n",
            "[2024-04-30 21:13:05,793] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE_NAME=libnccl2\n",
            "[2024-04-30 21:13:05,793] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE_VERSION=2.19.3-1\n",
            "[2024-04-30 21:13:05,793] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0]}\n",
            "[2024-04-30 21:13:05,793] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=1, node_rank=0\n",
            "[2024-04-30 21:13:05,793] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})\n",
            "[2024-04-30 21:13:05,793] [INFO] [launch.py:163:main] dist_world_size=1\n",
            "[2024-04-30 21:13:05,793] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0\n",
            "[2024-04-30 21:13:13,223] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "2024-04-30 21:13:14.656546: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-30 21:13:14.656595: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-30 21:13:14.657798: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-30 21:13:15.917226: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "[2024-04-30 21:13:22,122] [INFO] [comm.py:637:init_distributed] cdb=None\n",
            "[2024-04-30 21:13:22,122] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
            "config.json: 100% 1.16k/1.16k [00:00<00:00, 6.65MB/s]\n",
            "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n",
            "pytorch_model.bin.index.json: 100% 27.1k/27.1k [00:00<00:00, 97.1MB/s]\n",
            "Downloading shards:   0% 0/2 [00:00<?, ?it/s]\n",
            "pytorch_model-00001-of-00002.bin:   0% 0.00/9.98G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   0% 21.0M/9.98G [00:00<00:55, 179MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   1% 52.4M/9.98G [00:00<00:41, 239MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   1% 83.9M/9.98G [00:00<00:37, 265MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   1% 115M/9.98G [00:00<00:35, 277MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   1% 147M/9.98G [00:00<00:34, 284MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   2% 178M/9.98G [00:00<00:35, 277MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   2% 210M/9.98G [00:00<00:34, 284MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   2% 241M/9.98G [00:00<00:33, 288MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   3% 273M/9.98G [00:00<00:33, 290MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   3% 304M/9.98G [00:01<00:33, 291MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   3% 336M/9.98G [00:01<00:32, 293MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   4% 367M/9.98G [00:01<00:32, 294MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   4% 398M/9.98G [00:01<00:32, 294MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   4% 430M/9.98G [00:01<00:32, 295MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   5% 461M/9.98G [00:01<00:32, 295MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   5% 493M/9.98G [00:01<00:32, 296MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   5% 524M/9.98G [00:01<00:31, 296MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   6% 556M/9.98G [00:01<00:31, 295MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   6% 587M/9.98G [00:02<00:31, 295MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   6% 619M/9.98G [00:02<00:31, 294MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   7% 650M/9.98G [00:02<00:32, 291MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   7% 682M/9.98G [00:02<00:32, 289MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   7% 713M/9.98G [00:02<00:32, 288MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   7% 744M/9.98G [00:02<00:32, 288MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   8% 776M/9.98G [00:02<00:33, 272MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   8% 807M/9.98G [00:02<00:34, 264MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   8% 839M/9.98G [00:02<00:35, 255MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   9% 870M/9.98G [00:03<00:35, 255MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   9% 902M/9.98G [00:03<00:35, 253MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   9% 933M/9.98G [00:03<00:35, 254MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  10% 965M/9.98G [00:03<00:35, 252MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  10% 996M/9.98G [00:03<00:35, 254MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  10% 1.03G/9.98G [00:03<00:35, 255MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.06G/9.98G [00:03<00:34, 256MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.09G/9.98G [00:03<00:34, 257MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.12G/9.98G [00:04<00:34, 256MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.15G/9.98G [00:04<00:34, 257MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.18G/9.98G [00:04<00:33, 264MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.22G/9.98G [00:04<00:32, 270MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.25G/9.98G [00:04<00:31, 275MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.28G/9.98G [00:04<00:31, 279MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.31G/9.98G [00:04<00:30, 280MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.34G/9.98G [00:04<00:30, 282MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.37G/9.98G [00:04<00:30, 284MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.41G/9.98G [00:05<00:30, 283MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.44G/9.98G [00:05<00:30, 285MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.47G/9.98G [00:05<00:29, 285MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.50G/9.98G [00:05<00:29, 286MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.53G/9.98G [00:05<00:29, 285MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.56G/9.98G [00:05<00:29, 285MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.59G/9.98G [00:05<00:29, 285MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.63G/9.98G [00:05<00:30, 272MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.66G/9.98G [00:06<00:30, 275MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.69G/9.98G [00:06<00:29, 277MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.72G/9.98G [00:06<00:29, 278MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.75G/9.98G [00:06<00:29, 281MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.78G/9.98G [00:06<00:29, 282MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.81G/9.98G [00:06<00:29, 281MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.85G/9.98G [00:06<00:28, 283MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.88G/9.98G [00:06<00:28, 281MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.91G/9.98G [00:06<00:29, 277MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.94G/9.98G [00:07<00:28, 278MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  20% 1.97G/9.98G [00:07<00:29, 269MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  20% 2.00G/9.98G [00:07<00:30, 260MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  20% 2.03G/9.98G [00:07<00:31, 255MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  21% 2.07G/9.98G [00:07<00:31, 253MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  21% 2.10G/9.98G [00:07<00:30, 255MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  21% 2.13G/9.98G [00:07<00:30, 255MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.16G/9.98G [00:07<00:30, 256MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.19G/9.98G [00:08<00:30, 255MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.22G/9.98G [00:08<00:30, 253MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.25G/9.98G [00:08<00:30, 254MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.29G/9.98G [00:08<00:30, 254MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.32G/9.98G [00:08<00:30, 253MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.35G/9.98G [00:08<00:29, 255MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.38G/9.98G [00:08<00:29, 257MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.41G/9.98G [00:08<00:29, 258MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.44G/9.98G [00:08<00:29, 256MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.47G/9.98G [00:09<00:28, 260MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.51G/9.98G [00:09<00:27, 267MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.54G/9.98G [00:09<00:27, 271MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.57G/9.98G [00:09<00:27, 274MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.60G/9.98G [00:09<00:26, 277MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.63G/9.98G [00:09<00:26, 279MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.66G/9.98G [00:09<00:26, 280MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.69G/9.98G [00:09<00:25, 281MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.73G/9.98G [00:10<00:25, 281MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.76G/9.98G [00:10<00:25, 281MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.79G/9.98G [00:10<00:25, 282MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.82G/9.98G [00:10<00:25, 282MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.85G/9.98G [00:10<00:25, 282MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.88G/9.98G [00:10<00:25, 282MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.92G/9.98G [00:10<00:24, 283MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  30% 2.95G/9.98G [00:10<00:24, 283MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  30% 2.98G/9.98G [00:10<00:24, 283MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  30% 3.01G/9.98G [00:11<00:24, 283MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  30% 3.04G/9.98G [00:11<00:24, 278MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.07G/9.98G [00:11<00:24, 280MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.10G/9.98G [00:11<00:24, 278MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.14G/9.98G [00:11<00:24, 281MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.17G/9.98G [00:11<00:23, 284MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.20G/9.98G [00:11<00:23, 285MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.23G/9.98G [00:11<00:23, 286MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.26G/9.98G [00:11<00:23, 285MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.29G/9.98G [00:12<00:27, 246MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.32G/9.98G [00:12<00:26, 250MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.36G/9.98G [00:12<00:25, 255MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.39G/9.98G [00:12<00:24, 264MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.42G/9.98G [00:12<00:24, 268MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  35% 3.45G/9.98G [00:12<00:23, 274MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  35% 3.48G/9.98G [00:12<00:23, 279MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  35% 3.51G/9.98G [00:12<00:22, 283MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  36% 3.54G/9.98G [00:12<00:22, 286MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  36% 3.58G/9.98G [00:13<00:22, 288MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  36% 3.61G/9.98G [00:13<00:22, 289MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  36% 3.64G/9.98G [00:13<00:21, 289MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  37% 3.67G/9.98G [00:13<00:21, 287MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  37% 3.70G/9.98G [00:13<00:21, 287MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  37% 3.73G/9.98G [00:13<00:21, 289MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.76G/9.98G [00:13<00:22, 280MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.80G/9.98G [00:13<00:21, 284MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.83G/9.98G [00:13<00:21, 287MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  39% 3.86G/9.98G [00:14<00:21, 285MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  39% 3.89G/9.98G [00:14<00:21, 285MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  39% 3.92G/9.98G [00:14<00:21, 284MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  40% 3.95G/9.98G [00:14<00:21, 286MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  40% 3.98G/9.98G [00:14<00:20, 288MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  40% 4.02G/9.98G [00:14<00:20, 289MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  41% 4.05G/9.98G [00:14<00:20, 287MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  41% 4.08G/9.98G [00:14<00:20, 289MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  41% 4.11G/9.98G [00:14<00:20, 290MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.14G/9.98G [00:15<00:20, 286MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.17G/9.98G [00:15<00:20, 285MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.20G/9.98G [00:15<00:20, 286MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.24G/9.98G [00:15<00:20, 285MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  43% 4.27G/9.98G [00:15<00:20, 285MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  43% 4.30G/9.98G [00:15<00:20, 284MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  43% 4.33G/9.98G [00:15<00:20, 271MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  44% 4.36G/9.98G [00:15<00:21, 262MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  44% 4.39G/9.98G [00:15<00:21, 254MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  44% 4.42G/9.98G [00:16<00:21, 255MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  45% 4.46G/9.98G [00:16<00:21, 255MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  45% 4.49G/9.98G [00:16<00:21, 256MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  45% 4.52G/9.98G [00:16<00:21, 256MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  46% 4.55G/9.98G [00:16<00:25, 214MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  46% 4.58G/9.98G [00:16<00:23, 230MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  46% 4.61G/9.98G [00:16<00:22, 237MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  47% 4.65G/9.98G [00:17<00:21, 251MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  47% 4.68G/9.98G [00:17<00:20, 263MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  47% 4.71G/9.98G [00:17<00:19, 271MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.74G/9.98G [00:17<00:19, 275MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.77G/9.98G [00:17<00:18, 279MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.80G/9.98G [00:17<00:18, 281MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.83G/9.98G [00:17<00:18, 283MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  49% 4.87G/9.98G [00:17<00:18, 284MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  49% 4.90G/9.98G [00:17<00:17, 285MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  49% 4.93G/9.98G [00:18<00:17, 285MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  50% 4.96G/9.98G [00:18<00:17, 285MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  50% 4.99G/9.98G [00:18<00:17, 285MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  50% 5.02G/9.98G [00:18<00:17, 285MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  51% 5.05G/9.98G [00:18<00:17, 286MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  51% 5.09G/9.98G [00:18<00:17, 287MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  51% 5.12G/9.98G [00:18<00:16, 286MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.15G/9.98G [00:18<00:16, 286MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.18G/9.98G [00:18<00:16, 286MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.21G/9.98G [00:18<00:16, 286MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.24G/9.98G [00:19<00:17, 277MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.27G/9.98G [00:19<00:17, 270MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.31G/9.98G [00:19<00:17, 273MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.34G/9.98G [00:19<00:18, 256MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  54% 5.37G/9.98G [00:19<00:17, 265MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  54% 5.40G/9.98G [00:19<00:16, 273MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  54% 5.43G/9.98G [00:19<00:16, 278MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.46G/9.98G [00:19<00:16, 281MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.49G/9.98G [00:20<00:15, 283MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.53G/9.98G [00:20<00:15, 285MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  56% 5.56G/9.98G [00:20<00:15, 285MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  56% 5.59G/9.98G [00:20<00:15, 285MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  56% 5.62G/9.98G [00:20<00:15, 286MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.65G/9.98G [00:20<00:15, 286MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.68G/9.98G [00:20<00:14, 287MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.71G/9.98G [00:20<00:14, 287MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  58% 5.75G/9.98G [00:20<00:14, 286MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  58% 5.78G/9.98G [00:21<00:14, 287MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  58% 5.81G/9.98G [00:21<00:14, 287MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.84G/9.98G [00:21<00:14, 287MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.87G/9.98G [00:21<00:14, 287MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.90G/9.98G [00:21<00:14, 287MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.93G/9.98G [00:21<00:14, 287MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  60% 5.97G/9.98G [00:21<00:13, 287MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  60% 6.00G/9.98G [00:21<00:13, 286MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  60% 6.03G/9.98G [00:21<00:13, 286MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.06G/9.98G [00:22<00:14, 274MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.09G/9.98G [00:22<00:14, 268MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.12G/9.98G [00:22<00:14, 259MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.16G/9.98G [00:22<00:15, 254MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.19G/9.98G [00:22<00:15, 252MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.22G/9.98G [00:22<00:15, 249MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.25G/9.98G [00:22<00:15, 247MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.28G/9.98G [00:22<00:15, 246MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.31G/9.98G [00:23<00:14, 247MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.34G/9.98G [00:23<00:14, 248MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.38G/9.98G [00:23<00:14, 242MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.41G/9.98G [00:23<00:14, 246MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  65% 6.44G/9.98G [00:23<00:14, 248MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  65% 6.47G/9.98G [00:23<00:14, 247MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  65% 6.50G/9.98G [00:23<00:14, 244MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  65% 6.53G/9.98G [00:23<00:13, 248MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.56G/9.98G [00:24<00:13, 250MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.60G/9.98G [00:24<00:13, 253MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.63G/9.98G [00:24<00:13, 254MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.66G/9.98G [00:24<00:12, 264MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.69G/9.98G [00:24<00:12, 266MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.72G/9.98G [00:24<00:12, 271MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.75G/9.98G [00:24<00:11, 276MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.78G/9.98G [00:24<00:11, 280MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.82G/9.98G [00:24<00:11, 283MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  69% 6.85G/9.98G [00:25<00:10, 285MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  69% 6.88G/9.98G [00:25<00:10, 287MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  69% 6.91G/9.98G [00:25<00:10, 288MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  70% 6.94G/9.98G [00:25<00:10, 289MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  70% 6.97G/9.98G [00:25<00:10, 290MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  70% 7.00G/9.98G [00:25<00:10, 291MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.04G/9.98G [00:25<00:10, 291MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.07G/9.98G [00:25<00:09, 292MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.10G/9.98G [00:25<00:09, 291MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.13G/9.98G [00:26<00:09, 292MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  72% 7.16G/9.98G [00:26<00:09, 292MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  72% 7.19G/9.98G [00:26<00:09, 290MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  72% 7.22G/9.98G [00:26<00:09, 287MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.26G/9.98G [00:26<00:09, 286MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.29G/9.98G [00:26<00:09, 286MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.32G/9.98G [00:26<00:09, 285MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  74% 7.35G/9.98G [00:26<00:09, 278MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  74% 7.38G/9.98G [00:26<00:09, 274MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  74% 7.41G/9.98G [00:27<00:09, 268MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  75% 7.44G/9.98G [00:27<00:09, 266MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  75% 7.48G/9.98G [00:27<00:09, 262MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  75% 7.51G/9.98G [00:27<00:09, 262MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  76% 7.54G/9.98G [00:27<00:09, 262MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  76% 7.57G/9.98G [00:27<00:09, 260MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  76% 7.60G/9.98G [00:27<00:09, 256MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.63G/9.98G [00:27<00:09, 249MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.67G/9.98G [00:28<00:09, 248MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.70G/9.98G [00:28<00:09, 248MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.73G/9.98G [00:28<00:09, 246MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.76G/9.98G [00:28<00:09, 244MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.79G/9.98G [00:28<00:08, 245MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.82G/9.98G [00:28<00:08, 245MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  79% 7.85G/9.98G [00:28<00:08, 247MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  79% 7.89G/9.98G [00:28<00:08, 246MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  79% 7.92G/9.98G [00:29<00:08, 249MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  80% 7.95G/9.98G [00:29<00:08, 252MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  80% 7.98G/9.98G [00:29<00:07, 259MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  80% 8.01G/9.98G [00:29<00:07, 269MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  81% 8.04G/9.98G [00:29<00:07, 274MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  81% 8.07G/9.98G [00:29<00:06, 279MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  81% 8.11G/9.98G [00:29<00:06, 283MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  82% 8.14G/9.98G [00:29<00:06, 286MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  82% 8.17G/9.98G [00:29<00:06, 286MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  82% 8.20G/9.98G [00:30<00:06, 286MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.23G/9.98G [00:30<00:06, 285MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.26G/9.98G [00:30<00:06, 284MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.29G/9.98G [00:30<00:05, 285MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.33G/9.98G [00:30<00:05, 284MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.36G/9.98G [00:30<00:05, 285MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.39G/9.98G [00:30<00:05, 285MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.42G/9.98G [00:30<00:05, 286MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.45G/9.98G [00:30<00:05, 286MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.48G/9.98G [00:31<00:05, 285MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.51G/9.98G [00:31<00:05, 285MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.55G/9.98G [00:31<00:05, 285MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.58G/9.98G [00:31<00:05, 268MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.61G/9.98G [00:31<00:05, 243MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.64G/9.98G [00:31<00:05, 254MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.67G/9.98G [00:31<00:05, 259MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.70G/9.98G [00:31<00:04, 267MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.73G/9.98G [00:32<00:04, 267MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.77G/9.98G [00:32<00:04, 264MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.80G/9.98G [00:32<00:04, 256MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.83G/9.98G [00:32<00:04, 255MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  89% 8.86G/9.98G [00:32<00:04, 253MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  89% 8.89G/9.98G [00:32<00:04, 251MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  89% 8.92G/9.98G [00:32<00:04, 246MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  90% 8.95G/9.98G [00:32<00:04, 251MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  90% 8.99G/9.98G [00:33<00:03, 254MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  90% 9.02G/9.98G [00:33<00:03, 255MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.05G/9.98G [00:33<00:03, 255MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.08G/9.98G [00:33<00:03, 255MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.11G/9.98G [00:33<00:03, 254MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.14G/9.98G [00:33<00:03, 253MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.18G/9.98G [00:33<00:03, 253MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.21G/9.98G [00:33<00:03, 255MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.24G/9.98G [00:34<00:02, 255MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.27G/9.98G [00:34<00:02, 256MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.30G/9.98G [00:34<00:02, 255MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.33G/9.98G [00:34<00:02, 266MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.36G/9.98G [00:34<00:02, 274MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.40G/9.98G [00:34<00:03, 178MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.43G/9.98G [00:34<00:02, 202MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.46G/9.98G [00:35<00:02, 223MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.49G/9.98G [00:35<00:02, 240MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.52G/9.98G [00:35<00:01, 255MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.55G/9.98G [00:35<00:01, 265MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.58G/9.98G [00:35<00:01, 273MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.62G/9.98G [00:35<00:01, 279MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  97% 9.65G/9.98G [00:35<00:01, 283MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  97% 9.68G/9.98G [00:35<00:01, 286MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  97% 9.71G/9.98G [00:35<00:00, 288MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  98% 9.74G/9.98G [00:36<00:00, 291MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  98% 9.77G/9.98G [00:36<00:00, 291MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  98% 9.80G/9.98G [00:36<00:00, 293MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  99% 9.84G/9.98G [00:36<00:00, 292MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  99% 9.87G/9.98G [00:36<00:00, 289MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  99% 9.90G/9.98G [00:36<00:00, 288MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin: 100% 9.93G/9.98G [00:36<00:00, 282MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin: 100% 9.98G/9.98G [00:36<00:00, 271MB/s]\n",
            "Downloading shards:  50% 1/2 [00:37<00:37, 37.11s/it]\n",
            "pytorch_model-00002-of-00002.bin:   0% 0.00/3.54G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   0% 10.5M/3.54G [00:00<01:19, 44.6MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   1% 21.0M/3.54G [00:00<01:05, 53.8MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   1% 31.5M/3.54G [00:00<00:52, 66.7MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   1% 41.9M/3.54G [00:00<00:46, 75.3MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   2% 62.9M/3.54G [00:00<00:36, 94.6MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   2% 83.9M/3.54G [00:00<00:30, 115MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   3% 105M/3.54G [00:01<00:25, 134MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   4% 126M/3.54G [00:01<00:23, 148MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   4% 147M/3.54G [00:01<00:21, 156MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   5% 168M/3.54G [00:01<00:20, 165MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   5% 189M/3.54G [00:01<00:19, 170MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   6% 210M/3.54G [00:01<00:19, 172MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   7% 231M/3.54G [00:01<00:18, 176MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   7% 252M/3.54G [00:01<00:18, 179MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   8% 273M/3.54G [00:01<00:18, 181MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   8% 294M/3.54G [00:02<00:17, 182MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   9% 315M/3.54G [00:02<00:17, 182MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   9% 336M/3.54G [00:02<00:18, 174MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  10% 357M/3.54G [00:02<00:17, 177MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  11% 377M/3.54G [00:02<00:17, 179MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  11% 398M/3.54G [00:02<00:17, 178MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  12% 419M/3.54G [00:02<00:17, 180MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  12% 440M/3.54G [00:02<00:17, 179MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  13% 461M/3.54G [00:03<00:17, 176MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  14% 482M/3.54G [00:03<00:17, 180MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  14% 503M/3.54G [00:03<00:16, 181MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  15% 524M/3.54G [00:03<00:16, 180MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  15% 545M/3.54G [00:03<00:16, 180MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  16% 566M/3.54G [00:03<00:16, 182MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  17% 587M/3.54G [00:03<00:16, 177MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  17% 608M/3.54G [00:03<00:16, 179MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  18% 629M/3.54G [00:03<00:16, 181MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  18% 650M/3.54G [00:04<00:16, 180MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  19% 671M/3.54G [00:04<00:15, 184MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  20% 692M/3.54G [00:04<00:15, 184MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  20% 713M/3.54G [00:04<00:15, 181MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  21% 734M/3.54G [00:04<00:15, 176MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  21% 755M/3.54G [00:04<00:15, 183MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  22% 776M/3.54G [00:04<00:15, 180MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  22% 797M/3.54G [00:04<00:15, 174MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  23% 818M/3.54G [00:05<00:15, 170MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  24% 839M/3.54G [00:05<00:14, 180MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  24% 860M/3.54G [00:05<00:15, 178MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  25% 881M/3.54G [00:05<00:14, 180MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  25% 902M/3.54G [00:05<00:14, 181MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  26% 923M/3.54G [00:05<00:14, 182MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  27% 944M/3.54G [00:05<00:14, 184MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  27% 965M/3.54G [00:05<00:14, 183MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  28% 986M/3.54G [00:05<00:13, 183MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  28% 1.01G/3.54G [00:06<00:13, 181MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  29% 1.03G/3.54G [00:06<00:13, 182MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  30% 1.05G/3.54G [00:06<00:13, 182MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  30% 1.07G/3.54G [00:06<00:13, 181MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  31% 1.09G/3.54G [00:06<00:13, 183MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  31% 1.11G/3.54G [00:06<00:13, 186MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  32% 1.13G/3.54G [00:06<00:13, 180MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  33% 1.15G/3.54G [00:06<00:13, 181MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  33% 1.17G/3.54G [00:06<00:12, 183MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  34% 1.20G/3.54G [00:07<00:12, 184MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  34% 1.22G/3.54G [00:07<00:12, 184MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  35% 1.24G/3.54G [00:07<00:12, 184MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  36% 1.26G/3.54G [00:07<00:13, 175MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  36% 1.28G/3.54G [00:07<00:12, 175MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  37% 1.30G/3.54G [00:07<00:12, 177MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  37% 1.32G/3.54G [00:07<00:12, 179MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  38% 1.34G/3.54G [00:07<00:12, 181MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  38% 1.36G/3.54G [00:08<00:12, 179MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  39% 1.38G/3.54G [00:08<00:12, 174MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  40% 1.41G/3.54G [00:08<00:12, 177MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  40% 1.43G/3.54G [00:08<00:11, 179MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  41% 1.45G/3.54G [00:08<00:11, 181MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  41% 1.47G/3.54G [00:08<00:11, 183MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  42% 1.49G/3.54G [00:08<00:11, 183MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  43% 1.51G/3.54G [00:08<00:11, 183MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  43% 1.53G/3.54G [00:08<00:11, 183MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  44% 1.55G/3.54G [00:09<00:10, 184MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  44% 1.57G/3.54G [00:09<00:10, 183MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  45% 1.59G/3.54G [00:09<00:10, 182MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  46% 1.61G/3.54G [00:09<00:10, 180MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  46% 1.64G/3.54G [00:09<00:10, 182MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  47% 1.66G/3.54G [00:09<00:10, 181MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  47% 1.68G/3.54G [00:09<00:10, 183MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  48% 1.70G/3.54G [00:09<00:10, 183MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  49% 1.72G/3.54G [00:09<00:10, 180MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  49% 1.74G/3.54G [00:10<00:11, 156MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  50% 1.76G/3.54G [00:10<00:14, 127MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  50% 1.78G/3.54G [00:10<00:17, 103MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  51% 1.80G/3.54G [00:11<00:19, 89.2MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  51% 1.81G/3.54G [00:11<00:19, 88.5MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  52% 1.82G/3.54G [00:11<00:20, 81.9MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  52% 1.84G/3.54G [00:11<00:22, 75.2MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  52% 1.85G/3.54G [00:11<00:21, 80.0MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  52% 1.86G/3.54G [00:11<00:22, 75.4MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  53% 1.87G/3.54G [00:11<00:23, 70.9MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  53% 1.88G/3.54G [00:12<00:21, 77.3MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  54% 1.90G/3.54G [00:12<00:16, 98.6MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  54% 1.91G/3.54G [00:12<00:18, 90.4MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  54% 1.92G/3.54G [00:12<00:21, 75.7MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  54% 1.93G/3.54G [00:12<00:20, 76.9MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  55% 1.94G/3.54G [00:12<00:21, 73.8MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  55% 1.95G/3.54G [00:12<00:21, 73.9MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  55% 1.96G/3.54G [00:13<00:24, 64.8MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  56% 1.97G/3.54G [00:13<00:23, 67.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  56% 1.98G/3.54G [00:13<00:22, 68.7MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  56% 1.99G/3.54G [00:13<00:20, 74.7MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  57% 2.00G/3.54G [00:13<00:24, 63.7MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  57% 2.01G/3.54G [00:13<00:24, 63.3MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  57% 2.02G/3.54G [00:14<00:23, 64.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  57% 2.03G/3.54G [00:14<00:21, 69.6MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  58% 2.04G/3.54G [00:14<00:23, 64.3MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  58% 2.06G/3.54G [00:14<00:26, 56.3MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  58% 2.07G/3.54G [00:14<00:24, 60.7MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  59% 2.08G/3.54G [00:14<00:22, 65.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  59% 2.09G/3.54G [00:15<00:24, 58.7MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  59% 2.11G/3.54G [00:15<00:17, 83.9MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  60% 2.13G/3.54G [00:15<00:16, 86.4MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  60% 2.14G/3.54G [00:15<00:16, 83.2MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  61% 2.16G/3.54G [00:15<00:13, 104MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  62% 2.18G/3.54G [00:15<00:10, 124MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  62% 2.20G/3.54G [00:15<00:09, 139MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  63% 2.22G/3.54G [00:16<00:08, 150MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  63% 2.24G/3.54G [00:16<00:08, 160MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  64% 2.26G/3.54G [00:16<00:07, 167MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  65% 2.29G/3.54G [00:16<00:11, 114MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  65% 2.32G/3.54G [00:16<00:08, 149MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  66% 2.34G/3.54G [00:16<00:07, 154MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  67% 2.36G/3.54G [00:16<00:07, 161MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  67% 2.38G/3.54G [00:17<00:07, 162MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  68% 2.40G/3.54G [00:17<00:06, 165MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  68% 2.42G/3.54G [00:17<00:06, 172MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  69% 2.44G/3.54G [00:17<00:06, 175MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  70% 2.46G/3.54G [00:17<00:06, 175MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  70% 2.49G/3.54G [00:17<00:06, 175MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  71% 2.51G/3.54G [00:17<00:05, 179MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  71% 2.53G/3.54G [00:17<00:05, 182MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  72% 2.55G/3.54G [00:18<00:05, 169MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  73% 2.57G/3.54G [00:18<00:05, 172MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  73% 2.59G/3.54G [00:18<00:05, 161MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  74% 2.61G/3.54G [00:18<00:05, 162MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  74% 2.63G/3.54G [00:18<00:05, 166MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  75% 2.65G/3.54G [00:18<00:05, 174MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  75% 2.67G/3.54G [00:18<00:04, 176MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  76% 2.69G/3.54G [00:18<00:04, 178MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  77% 2.72G/3.54G [00:19<00:04, 180MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  77% 2.74G/3.54G [00:19<00:04, 176MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  78% 2.76G/3.54G [00:19<00:04, 179MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  78% 2.78G/3.54G [00:19<00:04, 182MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  79% 2.80G/3.54G [00:19<00:04, 184MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  80% 2.82G/3.54G [00:19<00:03, 181MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  80% 2.84G/3.54G [00:19<00:03, 181MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  81% 2.86G/3.54G [00:19<00:03, 182MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  81% 2.88G/3.54G [00:19<00:03, 186MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  82% 2.90G/3.54G [00:20<00:03, 185MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  83% 2.93G/3.54G [00:20<00:03, 186MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  83% 2.95G/3.54G [00:20<00:03, 186MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  84% 2.97G/3.54G [00:20<00:03, 182MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  84% 2.99G/3.54G [00:20<00:03, 183MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  85% 3.01G/3.54G [00:20<00:02, 180MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  86% 3.03G/3.54G [00:20<00:02, 181MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  86% 3.05G/3.54G [00:20<00:02, 182MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  87% 3.07G/3.54G [00:20<00:02, 183MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  87% 3.09G/3.54G [00:21<00:02, 183MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  88% 3.11G/3.54G [00:21<00:02, 181MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  89% 3.14G/3.54G [00:21<00:02, 179MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  89% 3.16G/3.54G [00:21<00:02, 172MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  90% 3.18G/3.54G [00:21<00:02, 170MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  90% 3.20G/3.54G [00:21<00:01, 178MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  91% 3.22G/3.54G [00:21<00:01, 177MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  91% 3.24G/3.54G [00:21<00:01, 180MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  92% 3.26G/3.54G [00:22<00:01, 183MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  93% 3.28G/3.54G [00:22<00:01, 184MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  93% 3.30G/3.54G [00:22<00:01, 183MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  94% 3.32G/3.54G [00:22<00:01, 183MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  94% 3.34G/3.54G [00:22<00:01, 181MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  95% 3.37G/3.54G [00:22<00:00, 182MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  96% 3.39G/3.54G [00:22<00:00, 184MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  96% 3.41G/3.54G [00:22<00:00, 185MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  97% 3.43G/3.54G [00:22<00:00, 184MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  97% 3.45G/3.54G [00:23<00:00, 182MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  98% 3.47G/3.54G [00:23<00:00, 181MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  99% 3.49G/3.54G [00:23<00:00, 182MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  99% 3.51G/3.54G [00:23<00:00, 178MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin: 100% 3.54G/3.54G [00:23<00:00, 150MB/s]\n",
            "Downloading shards: 100% 2/2 [01:00<00:00, 30.42s/it]\n",
            "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
            "config.json: 100% 4.76k/4.76k [00:00<00:00, 21.5MB/s]\n",
            "Loading checkpoint shards:   0% 0/2 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "Loading checkpoint shards: 100% 2/2 [00:03<00:00,  1.56s/it]\n",
            "generation_config.json: 100% 124/124 [00:00<00:00, 795kB/s]\n",
            "Adding LoRA adapters...\n",
            "tokenizer_config.json: 100% 749/749 [00:00<00:00, 4.99MB/s]\n",
            "tokenizer.model: 100% 500k/500k [00:00<00:00, 325MB/s]\n",
            "special_tokens_map.json: 100% 438/438 [00:00<00:00, 3.02MB/s]\n",
            "preprocessor_config.json: 100% 316/316 [00:00<00:00, 1.16MB/s]\n",
            "pytorch_model.bin: 100% 1.71G/1.71G [00:06<00:00, 260MB/s]\n",
            "Formatting inputs...Skip in lazy mode\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/.shortcut-targets-by-id/1euUzSZa1IjWGSY7kHFLr2B_d6lpqAzvE/Genai Project/VLM/LLAVA_zip/LLaVA-main/wandb/run-20240430_211456-brx9yc7h\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mrural-flower-17\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/aj7cmu/huggingface\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/aj7cmu/huggingface/runs/brx9yc7h\u001b[0m\n",
            "  0% 0/10 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/deepspeed/runtime/zero/stage_1_and_2.py:1652: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)\n",
            "  total_norm_cuda = get_accelerator().FloatTensor([float(total_norm)])\n",
            "{'loss': 1.0659, 'learning_rate': 0.0002, 'epoch': 0.91}\n",
            "{'loss': 1.0596, 'learning_rate': 0.00019396926207859084, 'epoch': 1.83}\n",
            "{'loss': 0.9513, 'learning_rate': 0.0001766044443118978, 'epoch': 2.74}\n",
            "{'loss': 0.865, 'learning_rate': 0.00015000000000000001, 'epoch': 3.66}\n",
            "{'loss': 0.7976, 'learning_rate': 0.00011736481776669306, 'epoch': 4.57}\n",
            "{'loss': 0.7541, 'learning_rate': 8.263518223330697e-05, 'epoch': 5.49}\n",
            "{'loss': 0.7077, 'learning_rate': 5.000000000000002e-05, 'epoch': 6.4}\n",
            "{'loss': 0.6965, 'learning_rate': 2.339555568810221e-05, 'epoch': 7.31}\n",
            "{'loss': 0.6651, 'learning_rate': 6.030737921409169e-06, 'epoch': 8.23}\n",
            "{'loss': 0.6602, 'learning_rate': 0.0, 'epoch': 9.14}\n",
            "{'train_runtime': 2251.175, 'train_samples_per_second': 0.622, 'train_steps_per_second': 0.004, 'train_loss': 0.8222962617874146, 'epoch': 9.14}\n",
            "100% 10/10 [37:20<00:00, 224.06s/it]\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 4096}\n",
            "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch ▁▂▃▃▄▅▆▆▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step ▁▂▃▃▄▅▆▆▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate ██▇▆▅▄▃▂▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss ██▆▅▃▃▂▂▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch 9.14\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss 0.6602\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos 3.816302559258214e+16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss 0.8223\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime 2251.175\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second 0.622\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second 0.004\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mrural-flower-17\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/aj7cmu/huggingface/runs/brx9yc7h\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/aj7cmu/huggingface\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240430_211456-brx9yc7h/logs\u001b[0m\n",
            "[2024-04-30 21:52:28,216] [INFO] [launch.py:347:main] Process 5460 exits successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llava.model.builder import load_pretrained_model\n",
        "from llava.mm_utils import get_model_name_from_path\n",
        "from llava.eval.run_llava import eval_model\n",
        "\n",
        "# model_path = \"liuhaotian/llava-v1.5-7b\"\n",
        "\n",
        "# tokenizer, model, image_processor, context_len = load_pretrained_model(\n",
        "#     model_path=model_path,\n",
        "#     model_base=None,\n",
        "#     model_name=get_model_name_from_path(model_path)\n",
        "# )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcB0URRKvegF",
        "outputId": "47fceca4-f789-401f-9962-c18b27b72031"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-04-30 23:04:49,975] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Genai Project/VLM/LLAVA_zip/LLaVA-main/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nA_JNSI78ze",
        "outputId": "531ee57e-f7ce-41a8-dc35-0ed278a86009"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1euUzSZa1IjWGSY7kHFLr2B_d6lpqAzvE/Genai Project/VLM/LLAVA_zip/LLaVA-main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### VLM No object detector Zero shot HiLetgo GY-521 module\n",
        "\n",
        "model_path = \"liuhaotian/llava-v1.5-7b\"\n",
        "# prompt = \"What are the things I should be cautious about when I visit here?\"\n",
        "# image_file = \"https://llava-vl.github.io/static/images/view.jpg\"\n",
        "prompt = \"You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component. Give a description of the component having 3 sections as follows: \\n1) Description \\n2) Applications \\n3) Technical specifications\"\n",
        "# prompt = \"Can you make a short description about the part: HiLetgo GY-521 module.\\n It should be divided into 3 sections as follows: \\n1) Description \\n2) Applications \\n3) technical specification\"\n",
        "image_file = \"../../images_jpg/HiLetgo_GY-521_module.jpg\"\n",
        "\n",
        "\n",
        "args = type('Args', (), {\n",
        "    \"model_path\": model_path,\n",
        "    \"model_base\": None,\n",
        "    \"model_name\": get_model_name_from_path(model_path),\n",
        "    \"query\": prompt,\n",
        "    \"conv_mode\": None,\n",
        "    \"image_file\": image_file,\n",
        "    \"sep\": \",\",\n",
        "    \"temperature\": 0.1,\n",
        "    \"top_p\": None,\n",
        "    \"num_beams\": 1,\n",
        "    \"max_new_tokens\": 1000\n",
        "})()\n",
        "\n",
        "eval_model(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555,
          "referenced_widgets": [
            "7e3119baa3584b0a8a3d5a9aff2408bc",
            "13ef5c7e968d4b07b9887b5f84ac4cc9",
            "e1e40b865ab64cf29f2eaf8a9fbf8b9d",
            "f6cf4b3385854cada6e3debe2758920b",
            "f07005198c064aca8c9cdeee5d0d483c",
            "6ba1c185679544a2a95c0b20dc244e73",
            "511abc370cee48efa17687ba17889b54",
            "bc9c34d72bfc46ccb5dd41b8cd84efa8",
            "e369018cc9b2499e96f1610eb9546dda",
            "b7d7e0154f69440a9ce66927e904c825",
            "c511c089a81e42dab248a461898bd189"
          ]
        },
        "id": "__VkIyF-OSks",
        "outputId": "17cd7532-7579-4ec3-9aa2-c60a941f4572"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_name:  llava-v1.5-7b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7e3119baa3584b0a8a3d5a9aff2408bc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image files:  ['../../images_jpg/HiLetgo_GY-521_module.jpg']\n",
            "images:  [<PIL.Image.Image image mode=RGB size=4032x3024 at 0x7AC78D023B80>]\n",
            "image sizes:  [(4032, 3024)]\n",
            "Description:\n",
            "The component is a small electronic module with a microchip, which is a crucial component in IoT devices. It is designed to be a versatile and compact solution for various IoT applications. The microchip is responsible for processing data, controlling the device, and communicating with other devices or systems.\n",
            "\n",
            "Applications:\n",
            "This component can be used in a wide range of IoT applications, such as smart home automation, industrial control systems, wearable devices, and smart city infrastructure. Its versatility and compact size make it suitable for various IoT projects, from simple home automation systems to complex industrial control systems.\n",
            "\n",
            "Technical specifications:\n",
            "\n",
            "1. Microchip: The microchip used in this component is a powerful and efficient processor that can handle various tasks, such as data processing, communication, and control.\n",
            "2. Connectivity: The component supports various connectivity options, including Wi-Fi, Bluetooth, and cellular networks, allowing it to communicate with other devices or systems.\n",
            "3. Sensors: The component is equipped with various sensors, such as accelerometers, gyroscopes, and magnetometers, which enable it to detect motion, orientation, and other environmental factors.\n",
            "4. Memory: The component has a built-in memory system that can store data, applications, and configurations, making it a reliable and flexible solution for IoT projects.\n",
            "5. Power supply: The component can be powered by various sources, including batteries, solar panels, or even the mains, depending on the specific application requirements.\n",
            "\n",
            "Overall, this IoT kit component is a versatile and compact solution that can be used in a wide range of IoT applications, offering various connectivity options, sensors, memory, and power supply options to suit different project requirements.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### VLM Zero shot HiLetgo GY-521 module\n",
        "\n",
        "model_path = \"liuhaotian/llava-v1.5-7b\"\n",
        "# prompt = \"What are the things I should be cautious about when I visit here?\"\n",
        "# image_file = \"https://llava-vl.github.io/static/images/view.jpg\"\n",
        "prompt = \"You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: HiLetgo GY-521 module. Give a description of the component having 3 sections as follows: \\n1) Description \\n2) Applications \\n3) Technical specifications\"\n",
        "# prompt = \"Can you make a short description about the part: HiLetgo GY-521 module.\\n It should be divided into 3 sections as follows: \\n1) Description \\n2) Applications \\n3) technical specification\"\n",
        "image_file = \"../../images_jpg/HiLetgo_GY-521_module.jpg\"\n",
        "\n",
        "\n",
        "args = type('Args', (), {\n",
        "    \"model_path\": model_path,\n",
        "    \"model_base\": None,\n",
        "    \"model_name\": get_model_name_from_path(model_path),\n",
        "    \"query\": prompt,\n",
        "    \"conv_mode\": None,\n",
        "    \"image_file\": image_file,\n",
        "    \"sep\": \",\",\n",
        "    \"temperature\": 0.1,\n",
        "    \"top_p\": None,\n",
        "    \"num_beams\": 1,\n",
        "    \"max_new_tokens\": 1000\n",
        "})()\n",
        "\n",
        "eval_model(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520,
          "referenced_widgets": [
            "367f21e176564755b43ae0ea0218dab1",
            "c599d174e7d445ee851b6d17b9275ae2",
            "1bd0683af6394ad48ffc650e08b03f60",
            "b3a986b67f6a478285bfe3869ed33511",
            "d36b335fa0204ba38f9c690da2ee2dca",
            "6ad123b305cf4f11a4c40e85d185d33f",
            "935c54c2fbbf47b08682de3e482467a6",
            "4b6927fab93146bf83eeb1458cf4219c",
            "753989190a0c47ddb5b75d879fac9226",
            "9a3acf7ab6ba45b8814276053ed4e86d",
            "0ee7aebd00c64ea0b7018a8759b980f8"
          ]
        },
        "id": "IRdQ587QRO0-",
        "outputId": "c964f9ab-95e2-4d11-80f1-739dfabf7457"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_name:  llava-v1.5-7b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "367f21e176564755b43ae0ea0218dab1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image files:  ['../../images_jpg/HiLetgo_GY-521_module.jpg']\n",
            "images:  [<PIL.Image.Image image mode=RGB size=4032x3024 at 0x7FBE53BD3C40>]\n",
            "image sizes:  [(4032, 3024)]\n",
            "1. Description:\n",
            "The HiLetgo GY-521 module is an IoT development board that is designed for use with the Arduino platform. It is a compact and versatile device that can be used for various IoT projects, including temperature and humidity monitoring, home automation, and remote control. The module features a built-in Wi-Fi module, which allows it to connect to the internet and communicate with other devices. Additionally, it has a GY-521 module that supports GSM/GPRS communication, which enables it to send and receive SMS messages.\n",
            "\n",
            "2. Applications:\n",
            "The HiLetgo GY-521 module can be used for a wide range of IoT applications, including:\n",
            "\n",
            "* Smart home automation: The module can be used to control various devices in a home, such as lights, appliances, and security systems.\n",
            "* Environmental monitoring: The module can be used to monitor temperature and humidity levels in a room or building, which can be useful for applications such as greenhouse control, air quality monitoring, and energy management.\n",
            "* Industrial automation: The module can be used to control and monitor industrial equipment, such as pumps, motors, and sensors, which can help improve efficiency and reduce downtime.\n",
            "* Remote control: The module can be used to create remote control systems for various devices, such as cars, boats, and home appliances.\n",
            "\n",
            "3. Technical specifications:\n",
            "The HiLetgo GY-521 module is a compact and versatile device that features a built-in Wi-Fi module and GSM/GPRS communication module. It is compatible with the Arduino platform and can be easily integrated into various IoT projects. The module has a range of input/output pins, which can be used to connect sensors, actuators, and other devices. It also has a range of digital and analog inputs, which can be used to read and control various signals. Additionally, the module has a range of communication protocols, including HTTP, MQTT, and Modbus, which can be used to communicate with other devices.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### VLM One shot HiLetgo GY-521 module\n",
        "\n",
        "model_path = \"liuhaotian/llava-v1.5-7b\"\n",
        "# prompt = \"What are the things I should be cautious about when I visit here?\"\n",
        "# image_file = \"https://llava-vl.github.io/static/images/view.jpg\"\n",
        "prompt = \"You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: HiLetgo GY-521 module. Give a description of the component having 3 sections as follows: \\n1) Description \\n2) Applications \\n3) Technical specifications.\\n Here is an example for reference,\\nULN 2003 Stepper Motor Driver Module:\\nDescription:\\nThe ULN2003 Stepper Motor Driver Module is an integrated circuit module designed to control bipolar stepper motors conveniently. It utilizes the ULN2003A Darlington array as its core component. This module provides an easy interface for controlling stepper motors, offering both simplicity and efficiency in motor control applications.\\nApplications:\\nThe ULN2003 Stepper Motor Driver Module finds widespread use in various projects and applications, including:\\nRobotics: for precise control of robot movements.\\nCNC machines: for controlling the motion of axes.\\n3D printers: for controlling the position of the printing head.\\nAutomated systems: for controlling mechanisms like conveyor belts and automated doors.\\nDIY projects: for hobbyists and enthusiasts working on motion control projects.\\nTechnical Specifications:\\nOperating Voltage: 5V DC\\nOutput Current: up to 500mA per channel (with proper heat sinking)\\nDriver IC: ULN2003A Darlington Array\\nNumber of Channels: 7 (suitable for driving bipolar stepper motors)\\nCompatible Motors: Bipolar stepper motors with 4 or 6 wires\\nControl Interface: 4-phase, 5-wire interface (can be easily interfaced with microcontrollers like Arduino)\\nDimensions: Compact module size for easy integration into projects\\nProtection Features: Built-in transient suppression diodes for protecting the module and connected components against voltage spikes\\nMounting Holes: Provided for easy installation and integration into projects\"\n",
        "# prompt = \"Can you make a short description about the part: HiLetgo GY-521 module.\\n It should be divided into 3 sections as follows: \\n1) Description \\n2) Applications \\n3) technical specification\"\n",
        "image_file = \"../../images_jpg/HiLetgo_GY-521_module.jpg\"\n",
        "\n",
        "\n",
        "args = type('Args', (), {\n",
        "    \"model_path\": model_path,\n",
        "    \"model_base\": None,\n",
        "    \"model_name\": get_model_name_from_path(model_path),\n",
        "    \"query\": prompt,\n",
        "    \"conv_mode\": None,\n",
        "    \"image_file\": image_file,\n",
        "    \"sep\": \",\",\n",
        "    \"temperature\": 0.1,\n",
        "    \"top_p\": None,\n",
        "    \"num_beams\": 1,\n",
        "    \"max_new_tokens\": 1000\n",
        "})()\n",
        "\n",
        "eval_model(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625,
          "referenced_widgets": [
            "05b4bb36cd7c4f3da7986cb1fca0d6fc",
            "eeed9cb8a0df4bdaabe4aa8be54af9cb",
            "8b676329d5194430b963897cb6d7d052",
            "93e736f3a7894bbd9f8c3eff2c64ee8c",
            "db63b60c2668462c97af5ee9e8ac2aa0",
            "8edf1a38147e41518ce2152e167c14a1",
            "d1ecfdb87fcc4a3ba5ca4e148027f0a8",
            "5337ac765b86446ebd049a81d881d9d6",
            "2ee4671949d44b3da6b5d05ea585d7b5",
            "1d6c495c840b48dc885c2af611df13bd",
            "769d771691114da68dd275993af2e844"
          ]
        },
        "id": "RkuIYp64Nznm",
        "outputId": "ce8eb0c7-7f1a-4f25-aa34-6cc49e6bf0a2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_name:  llava-v1.5-7b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "05b4bb36cd7c4f3da7986cb1fca0d6fc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image files:  ['../../images_jpg/HiLetgo_GY-521_module.jpg']\n",
            "images:  [<PIL.Image.Image image mode=RGB size=4032x3024 at 0x799543D5FD30>]\n",
            "image sizes:  [(4032, 3024)]\n",
            "Description:\n",
            "The HiLetgo GY-521 module is an integrated circuit module designed for use in IoT projects. It is a low-cost, versatile module that can be used for various applications, including wireless communication, data transmission, and sensor interfacing.\n",
            "\n",
            "Applications:\n",
            "The GY-521 module can be used in a wide range of IoT projects, such as home automation, industrial control systems, and smart city applications. It can be used to transmit sensor data, control actuators, and communicate with other devices wirelessly.\n",
            "\n",
            "Technical specifications:\n",
            "\n",
            "* Operating Voltage: 3.3V to 5.5V DC\n",
            "* Data Rate: 250kbps\n",
            "* Transmission Range: 100m (line of sight)\n",
            "* Frequency Band: 2.4GHz\n",
            "* Channels: 1\n",
            "* Data Format: Modulated RF\n",
            "* Power Source: External power supply (5V DC)\n",
            "* Dimensions: 50mm x 30mm\n",
            "* Weight: 20g\n",
            "* Package: SOIC-8\n",
            "* Compatibility: Arduino, Raspberry Pi, and other microcontrollers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### VLM finetuning HiLetgo GY-521 module\n",
        "\n",
        "# model_path = \"llava/checkpoints/llava-v1.5-7b-task-lora-first\"\n",
        "model_path = \"llava/checkpoints/llava-v1.5-7b-lora\"\n",
        "model_basee = \"liuhaotian/llava-v1.5-7b\"\n",
        "# prompt = \"What are the things I should be cautious about when I visit here?\"\n",
        "# image_file = \"https://llava-vl.github.io/static/images/view.jpg\"\n",
        "prompt = \"You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: HiLetgo GY-521 module. Give a description of the component having 3 sections as follows: \\n1) Description \\n2) Applications \\n3) Technical specifications\"\n",
        "image_file = \"../../images_jpg/HiLetgo_GY-521_module.jpg\"\n",
        "\n",
        "\n",
        "args = type('Args', (), {\n",
        "    \"model_path\": model_path,\n",
        "    \"model_base\": model_basee,\n",
        "    \"model_name\": get_model_name_from_path(model_path),\n",
        "    \"query\": prompt,\n",
        "    \"conv_mode\": None,\n",
        "    \"image_file\": image_file,\n",
        "    \"sep\": \",\",\n",
        "    \"temperature\": 0.1,\n",
        "    \"top_p\": None,\n",
        "    \"num_beams\": 1,\n",
        "    \"max_new_tokens\": 512\n",
        "})()\n",
        "\n",
        "eval_model(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468,
          "referenced_widgets": [
            "d2efaf26f2c14450bc9f62eb0d4eb3a9",
            "91b2627c06c34d03b9b3600c1867926e",
            "685f588152654cf5a41c8cd36523cf15",
            "585418a07d89427d860e2562ec5a08e1",
            "4e19b80c469b4ef0b7124829ceea7ea3",
            "39c5fb962c314a61ba69910e0e090665",
            "9271487f667b4258909cd2231f24ddef",
            "cc0cdc0b567c4e2b8760b985f9677de3",
            "fdcd57690d5441d4b5db2ae1b9de9d4e",
            "e28e6638f8204199bf56012adf4e3288",
            "66a497a637784a33a889074e0dcb790b"
          ]
        },
        "id": "zverhk76Tum4",
        "outputId": "8c2409e1-dc37-4535-da0e-7ef2f29fac8c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_name:  llava-v1.5-7b-lora\n",
            "Loading LLaVA from base model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d2efaf26f2c14450bc9f62eb0d4eb3a9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading additional LLaVA weights...\n",
            "Loading LoRA weights...\n",
            "Merging LoRA weights...\n",
            "Model is loaded...\n",
            "image files:  ['../../images_jpg/HiLetgo_GY-521_module.jpg']\n",
            "images:  [<PIL.Image.Image image mode=RGB size=4032x3024 at 0x7A044948C910>]\n",
            "image sizes:  [(4032, 3024)]\n",
            "Description:\n",
            "The HiLetgo GY-521 module is a compact and versatile sensor module designed for use in Internet of Things (IoT) projects. It features a built-in accelerometer and magnetometer, which allows it to detect motion and orientation. The module also includes a temperature sensor, making it suitable for monitoring environmental conditions. Additionally, it has a digital interface for easy communication with microcontrollers or other devices.\n",
            "Applications:\n",
            "The GY-521 module finds applications in various fields, including robotics, unmanned aerial vehicles (UAVs), automotive, gaming, and wearable technology. It can be used to detect motion and orientation in robotic platforms, stabilize UAVs during flight, monitor vehicle movement, and provide motion-based input for gaming controllers. In wearable technology, it can be integrated into fitness trackers or smartwatches to track physical activity and orientation.\n",
            "Technical Specifications:\n",
            "Operating Voltage: 3.3V\n",
            "Accelerometer Range: ±2g to ±200g\n",
            "Magnetometer Range: ±250mT to ±2000mT\n",
            "Temperature Range: -40°C to 85°C\n",
            "Digital Interface: I2C\n",
            "Dimensions: 22mm x 17mm\n",
            "Weight: 10g\n",
            "Operating Temperature: -20°C to 70°C\n",
            "Operating Humidity: 0% to 90% RH (non-condensing)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Genai Project/VLM/LLAVA_zip/LLaVA-main/\n",
        "\n",
        "from llava.model.builder import load_pretrained_model\n",
        "from llava.mm_utils import get_model_name_from_path\n",
        "from llava.eval.run_llava import eval_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5-9oC__KVxO",
        "outputId": "75466991-0316-4f2e-e7f5-d1b371061cae"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1euUzSZa1IjWGSY7kHFLr2B_d6lpqAzvE/Genai Project/VLM/LLAVA_zip/LLaVA-main\n",
            "[2024-04-30 23:17:49,405] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### VLM No object detector Zero shot RC522 RFID Module\n",
        "\n",
        "model_path = \"liuhaotian/llava-v1.5-7b\"\n",
        "# prompt = \"What are the things I should be cautious about when I visit here?\"\n",
        "# image_file = \"https://llava-vl.github.io/static/images/view.jpg\"\n",
        "prompt = \"You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component. Give a description of the component having 3 sections as follows: \\n1) Description \\n2) Applications \\n3) Technical specifications\"\n",
        "image_file = \"../../images_jpg/RC522_RFID_Module.jpg\"\n",
        "\n",
        "\n",
        "args = type('Args', (), {\n",
        "    \"model_path\": model_path,\n",
        "    \"model_base\": None,\n",
        "    \"model_name\": get_model_name_from_path(model_path),\n",
        "    \"query\": prompt,\n",
        "    \"conv_mode\": None,\n",
        "    \"image_file\": image_file,\n",
        "    \"sep\": \",\",\n",
        "    \"temperature\": 0.1,\n",
        "    \"top_p\": None,\n",
        "    \"num_beams\": 1,\n",
        "    \"max_new_tokens\": 1000\n",
        "})()\n",
        "\n",
        "eval_model(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381,
          "referenced_widgets": [
            "694753b1a526465b92b97c0dba2fb175",
            "d56b048f3a834f14aa7da8e23ec305ba",
            "c487748be04e4491a550a7c53a8135d1",
            "ced6aa064d9047b5a672a066e774782c",
            "2498de1e5d514c789ca318ab50a9ea41",
            "aa923992f62d4b5fa60eed74a1e392a6",
            "4048bf73839c4382ae82c188b0ff4249",
            "1177935ee2a4401ca136a08a9fe0f78f",
            "e49a785df626458eb5fceee1bb2d64a6",
            "7aa12c00edee49699cc040374baa5025",
            "6333230e875c4f92b2530d495ea2690d"
          ]
        },
        "id": "F2kXXQcIRcie",
        "outputId": "933412d8-f071-4b6a-dabc-ee8afbcd64ef"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_name:  llava-v1.5-7b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "694753b1a526465b92b97c0dba2fb175"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image files:  ['../../images_jpg/RC522_RFID_Module.jpg']\n",
            "images:  [<PIL.Image.Image image mode=RGB size=4032x3024 at 0x7D8460017E80>]\n",
            "image sizes:  [(4032, 3024)]\n",
            "The IoT kit component is a small blue device with a white sticker on it, which appears to be a Wi-Fi module. It is designed to connect to Wi-Fi networks and enable wireless communication between devices. The device has a USB interface, which allows it to be connected to a computer or other devices for data transfer and power supply.\n",
            "\n",
            "1. Description: The Wi-Fi module is a small electronic component that enables wireless communication between devices. It is designed to connect to Wi-Fi networks and can be used to transmit data over the internet. The device has a USB interface, which allows it to be connected to a computer or other devices for data transfer and power supply.\n",
            "2. Applications: The Wi-Fi module can be used in various IoT applications, such as home automation, industrial control systems, and smart cities. It can be integrated into devices like smartphones, cameras, and sensors to enable wireless communication and data transfer.\n",
            "3. Technical specifications: The Wi-Fi module is a small electronic component that operates on Wi-Fi technology. It has a USB interface for data transfer and power supply. The device is designed to connect to Wi-Fi networks and can transmit data over the internet. The technical specifications of the Wi-Fi module may include information such as the frequency range, data rate, range, and compatibility with different Wi-Fi standards.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### VLM Zero shot RC522 RFID Module\n",
        "\n",
        "model_path = \"liuhaotian/llava-v1.5-7b\"\n",
        "# prompt = \"What are the things I should be cautious about when I visit here?\"\n",
        "# image_file = \"https://llava-vl.github.io/static/images/view.jpg\"\n",
        "prompt = \"You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: RC522 RFID Module. Give a description of the component having 3 sections as follows: \\n1) Description \\n2) Applications \\n3) Technical specifications\"\n",
        "\n",
        "image_file = \"../../images_jpg/RC522_RFID_Module.jpg\"\n",
        "\n",
        "\n",
        "args = type('Args', (), {\n",
        "    \"model_path\": model_path,\n",
        "    \"model_base\": None,\n",
        "    \"model_name\": get_model_name_from_path(model_path),\n",
        "    \"query\": prompt,\n",
        "    \"conv_mode\": None,\n",
        "    \"image_file\": image_file,\n",
        "    \"sep\": \",\",\n",
        "    \"temperature\": 0.1,\n",
        "    \"top_p\": None,\n",
        "    \"num_beams\": 1,\n",
        "    \"max_new_tokens\": 1000\n",
        "})()\n",
        "\n",
        "eval_model(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434,
          "referenced_widgets": [
            "d183549305b24d8e8a2102e48f41634a",
            "888507435b154d889d32cbb34cd3bfd1",
            "bf201068cfd949ee868a58a4b4a6e680",
            "a3770f78343743918c8f9e2decae1c29",
            "8d0ae06996ea4676b1119ae681576e35",
            "c86fcfe79973473ca97431699dd0c602",
            "f8f37abbe2f9414797d324bee4f16a14",
            "f22c4ecafd08496fb7391b2de773ee01",
            "fc43db2c082040dfbaa2bb12219fb0f2",
            "1238f62b6e0c4439bac7e05a1deb272f",
            "f85aa9e38c7f441fbe707f0934acf1d2"
          ]
        },
        "id": "nFSnO8QHSWoo",
        "outputId": "22d1e370-6326-4bc3-f7b7-21b1c9e44aab"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_name:  llava-v1.5-7b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d183549305b24d8e8a2102e48f41634a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image files:  ['../../images_jpg/RC522_RFID_Module.jpg']\n",
            "images:  [<PIL.Image.Image image mode=RGB size=4032x3024 at 0x796DE30EBE50>]\n",
            "image sizes:  [(4032, 3024)]\n",
            "1. Description:\n",
            "The RC522 RFID module is an RFID reader designed for use in IoT applications. It is a small, compact device that can be easily integrated into various projects. The module is equipped with an antenna and a microcontroller, which enables it to read RFID tags from a distance of up to 10 cm. The RC522 module can be used to read and write data on RFID tags, making it a versatile component for various IoT applications.\n",
            "\n",
            "2. Applications:\n",
            "The RC522 RFID module can be used in a wide range of applications, including access control, inventory management, asset tracking, and identification systems. It can be integrated into security systems, such as gates and doors, to allow authorized personnel to access restricted areas. In inventory management, the module can be used to track the movement of goods and materials in warehouses and distribution centers. In asset tracking, the RC522 module can be used to monitor the location and status of vehicles, equipment, and other valuable assets.\n",
            "\n",
            "3. Technical specifications:\n",
            "The RC522 RFID module operates at a frequency of 125 kHz and has a read range of up to 10 cm. It is compatible with various types of RFID tags, including ISO 14443 and ISO 15693. The module is equipped with a microcontroller that can be programmed using the Arduino IDE, making it easy to integrate into various IoT projects. The RC522 module also has a built-in LED that can be used to indicate the status of the device. The module is compatible with both 3.3V and 5V systems, making it suitable for a wide range of applications.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### VLM One shot RC522 RFID Module\n",
        "\n",
        "model_path = \"liuhaotian/llava-v1.5-7b\"\n",
        "# prompt = \"What are the things I should be cautious about when I visit here?\"\n",
        "# image_file = \"https://llava-vl.github.io/static/images/view.jpg\"\n",
        "prompt = \"You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: RC522 RFID Module. Give a description of the component having 3 sections as follows: \\n1) Description \\n2) Applications \\n3) Technical specifications.\\n Here is an example for reference,\\nULN 2003 Stepper Motor Driver Module:\\nDescription:\\nThe ULN2003 Stepper Motor Driver Module is an integrated circuit module designed to control bipolar stepper motors conveniently. It utilizes the ULN2003A Darlington array as its core component. This module provides an easy interface for controlling stepper motors, offering both simplicity and efficiency in motor control applications.\\nApplications:\\nThe ULN2003 Stepper Motor Driver Module finds widespread use in various projects and applications, including:\\nRobotics: for precise control of robot movements.\\nCNC machines: for controlling the motion of axes.\\n3D printers: for controlling the position of the printing head.\\nAutomated systems: for controlling mechanisms like conveyor belts and automated doors.\\nDIY projects: for hobbyists and enthusiasts working on motion control projects.\\nTechnical Specifications:\\nOperating Voltage: 5V DC\\nOutput Current: up to 500mA per channel (with proper heat sinking)\\nDriver IC: ULN2003A Darlington Array\\nNumber of Channels: 7 (suitable for driving bipolar stepper motors)\\nCompatible Motors: Bipolar stepper motors with 4 or 6 wires\\nControl Interface: 4-phase, 5-wire interface (can be easily interfaced with microcontrollers like Arduino)\\nDimensions: Compact module size for easy integration into projects\\nProtection Features: Built-in transient suppression diodes for protecting the module and connected components against voltage spikes\\nMounting Holes: Provided for easy installation and integration into projects\"\n",
        "# prompt = \"Can you make a short description about the part: HiLetgo GY-521 module.\\n It should be divided into 3 sections as follows: \\n1) Description \\n2) Applications \\n3) technical specification\"\n",
        "image_file = \"../../images_jpg/RC522_RFID_Module.jpg\"\n",
        "\n",
        "\n",
        "args = type('Args', (), {\n",
        "    \"model_path\": model_path,\n",
        "    \"model_base\": None,\n",
        "    \"model_name\": get_model_name_from_path(model_path),\n",
        "    \"query\": prompt,\n",
        "    \"conv_mode\": None,\n",
        "    \"image_file\": image_file,\n",
        "    \"sep\": \",\",\n",
        "    \"temperature\": 0.1,\n",
        "    \"top_p\": None,\n",
        "    \"num_beams\": 1,\n",
        "    \"max_new_tokens\": 1000\n",
        "})()\n",
        "\n",
        "eval_model(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607,
          "referenced_widgets": [
            "45a7dbec79d14b35af3fffee3fd9963b",
            "6cdbaf49edfc40449f784b1ebb28804c",
            "b339cf1ec20b4fc8a4d715ff3208bc19",
            "46f7bab2228843439c2663355f881001",
            "d615e36c928d41488838852d43b10135",
            "76f3461c799540a78686b94ad7d0d28f",
            "5cec799b16dc47bca79bac17cb945a5a",
            "30bf9882eb2246e5b601761de7963ff5",
            "f2b33eae2266495fa1ab8c9d0fdb7b54",
            "9c8e1bc2ba2f4677a558f99c53d228bf",
            "fc1f138e4f6a417588031ac920b35883"
          ]
        },
        "id": "rwVYi4DJSlRr",
        "outputId": "2cf6a9dd-3d86-4cac-9881-8cffd6a91774"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_name:  llava-v1.5-7b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "45a7dbec79d14b35af3fffee3fd9963b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image files:  ['../../images_jpg/RC522_RFID_Module.jpg']\n",
            "images:  [<PIL.Image.Image image mode=RGB size=4032x3024 at 0x7C19BD505660>]\n",
            "image sizes:  [(4032, 3024)]\n",
            "Description:\n",
            "The RC522 RFID module is an integrated circuit designed for reading and writing RFID tags. It is a compact and versatile module that can be easily integrated into various IoT projects. The RC522 module is compatible with both 125kHz and 13.56MHz RFID tags, making it suitable for a wide range of applications.\n",
            "\n",
            "Applications:\n",
            "The RC522 RFID module can be used in a variety of applications, including access control, inventory management, asset tracking, and payment systems. It can be integrated into security systems, such as gates and doors, to control access to restricted areas. In inventory management, it can be used to track the movement of goods and products in warehouses and retail stores. Additionally, it can be employed in asset tracking systems to monitor the movement and status of vehicles, equipment, and other valuable assets.\n",
            "\n",
            "Technical Specifications:\n",
            "\n",
            "1. Operating Voltage: 5V DC\n",
            "2. Frequency Range: 125kHz and 13.56MHz\n",
            "3. Tag Reading Range: 10cm (300mW) and 40cm (100mW)\n",
            "4. Tag Writing Range: 10cm (300mW)\n",
            "5. Data Transfer Rate: 200kbps\n",
            "6. Interface: I2C\n",
            "7. Dimensions: 30mm x 25mm\n",
            "8. Operating Temperature: -20°C to +70°C\n",
            "9. Storage Temperature: -40°C to +85°C\n",
            "10. Package: SOIC-8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### VLM finetuning RC522 RFID Module\n",
        "\n",
        "# model_path = \"llava/checkpoints/llava-v1.5-7b-task-lora-first\"\n",
        "model_path = \"llava/checkpoints/llava-v1.5-7b-lora\"\n",
        "model_basee = \"liuhaotian/llava-v1.5-7b\"\n",
        "# prompt = \"What are the things I should be cautious about when I visit here?\"\n",
        "# image_file = \"https://llava-vl.github.io/static/images/view.jpg\"\n",
        "prompt = \"You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: RC522 RFID Module. Give a description of the component having 3 sections as follows: \\n1) Description \\n2) Applications \\n3) Technical specifications\"\n",
        "image_file = \"../../images_jpg/RC522_RFID_Module.jpg\"\n",
        "\n",
        "\n",
        "args = type('Args', (), {\n",
        "    \"model_path\": model_path,\n",
        "    \"model_base\": model_basee,\n",
        "    \"model_name\": get_model_name_from_path(model_path),\n",
        "    \"query\": prompt,\n",
        "    \"conv_mode\": None,\n",
        "    \"image_file\": image_file,\n",
        "    \"sep\": \",\",\n",
        "    \"temperature\": 0.1,\n",
        "    \"top_p\": None,\n",
        "    \"num_beams\": 1,\n",
        "    \"max_new_tokens\": 512\n",
        "})()\n",
        "\n",
        "eval_model(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763,
          "referenced_widgets": [
            "44199e6077f340d8bb735e0faf41f422",
            "ceda22be829a4ea7bc8b0676f83afea3",
            "7a102e47f5d543749dbd5ce0e9871d6d",
            "ba64b5c256114b608186aa624d59c929",
            "c3cc230ad03446fba403378f12268de9",
            "04f04b2937844240916a110bf505492c",
            "5905d93b7c114ac5a8db0452532bb58c",
            "aa12eb71bd334d468959dbb15dd86ffb",
            "e799a17f09904e439cb337a445703eb9",
            "065201d7aab144838adc38a06415237b",
            "03abe832bffc4631a114026b35cdedfd"
          ]
        },
        "id": "5BGeFRSHS7cA",
        "outputId": "2e987dbd-a20a-47ab-8931-630fce4d9366"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_name:  llava-v1.5-7b-lora\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading LLaVA from base model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "44199e6077f340d8bb735e0faf41f422"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading additional LLaVA weights...\n",
            "Loading LoRA weights...\n",
            "Merging LoRA weights...\n",
            "Model is loaded...\n",
            "image files:  ['../../images_jpg/RC522_RFID_Module.jpg']\n",
            "images:  [<PIL.Image.Image image mode=RGB size=4032x3024 at 0x7C7C9937D7E0>]\n",
            "image sizes:  [(4032, 3024)]\n",
            "Description:\n",
            "The RC522 RFID (Radio Frequency Identification) Module is a compact and versatile electronic component designed for use in IoT (Internet of Things) projects. It utilizes RFID technology to identify and authenticate objects or individuals based on their unique RFID tags. The module typically consists of a reader antenna, a microcontroller, and a set of interfaces for communication and control.\n",
            "Applications:\n",
            "The RC522 RFID Module finds applications in various industries and sectors, including:\n",
            "Access control: Secure entry to buildings, offices, and restricted areas using RFID-enabled cards or fobs.\n",
            "Asset tracking: Track and manage assets such as vehicles, equipment, and inventory using RFID tags.\n",
            "Payment systems: Implement contactless payment solutions using RFID-enabled cards or mobile devices.\n",
            "Identification systems: Enhance security and authentication in identity cards, passports, and other identification documents.\n",
            "Inventory management: Streamline inventory management processes by tracking and monitoring stock levels using RFID tags.\n",
            "Technical Specifications:\n",
            "Operating Frequency: 13.56 MHz\n",
            "Interface: SPI (Serial Peripheral Interface)\n",
            "Communication Protocol: ISO/IEC 14443 Type A\n",
            "Operating Voltage: 3.3V\n",
            "Output Power: 10 dBm\n",
            "Read Range: Up to 3 cm (depending on environmental factors)\n",
            "Dimensions: Approximately 20 mm x 10 mm\n",
            "Operating Temperature: -20°C to +70°C\n",
            "Storage Temperature: -40°C to +85°C\n",
            "Operating Humidity: 5% to 95% (non-condensing)\n",
            "Power Consumption: Typically around 100 mA to 200 mA\n",
            "Compatibility: Compatible with popular microcontrollers such as Arduino, Raspberry Pi, and ESP8266/ESP32.\n",
            "Note: The specifications may vary depending on the manufacturer and model of the RC522 RFID Module.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Genai Project/VLM/LLAVA_zip/LLaVA-main/\n",
        "\n",
        "from llava.model.builder import load_pretrained_model\n",
        "from llava.mm_utils import get_model_name_from_path\n",
        "from llava.eval.run_llava import eval_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwRREvnYU7ix",
        "outputId": "bc77c3f7-64cd-4577-c53f-155ade74fcda"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1euUzSZa1IjWGSY7kHFLr2B_d6lpqAzvE/Genai Project/VLM/LLAVA_zip/LLaVA-main\n",
            "[2024-04-30 23:29:25,855] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### VLM No object detector Zero shot Servo Motor SG90\n",
        "\n",
        "model_path = \"liuhaotian/llava-v1.5-7b\"\n",
        "# prompt = \"What are the things I should be cautious about when I visit here?\"\n",
        "# image_file = \"https://llava-vl.github.io/static/images/view.jpg\"\n",
        "prompt = \"You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component. Give a description of the component having 3 sections as follows: \\n1) Description \\n2) Applications \\n3) Technical specifications\"\n",
        "image_file = \"../../images_jpg/Servo_Motor_SG90.jpg\"\n",
        "\n",
        "\n",
        "args = type('Args', (), {\n",
        "    \"model_path\": model_path,\n",
        "    \"model_base\": None,\n",
        "    \"model_name\": get_model_name_from_path(model_path),\n",
        "    \"query\": prompt,\n",
        "    \"conv_mode\": None,\n",
        "    \"image_file\": image_file,\n",
        "    \"sep\": \",\",\n",
        "    \"temperature\": 0.1,\n",
        "    \"top_p\": None,\n",
        "    \"num_beams\": 1,\n",
        "    \"max_new_tokens\": 1000\n",
        "})()\n",
        "\n",
        "eval_model(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434,
          "referenced_widgets": [
            "c43cf26f2cd8433088b2a585792b59f1",
            "3d91ae018c264622be1b031ba3ff5c16",
            "b2162355217a4397a63f85d6712b1626",
            "cae574b1db34450dbce803417c82af1d",
            "1b6d7e2d75a64e84a3a3a39a25645a74",
            "d1a0ed6884da4345a84257e875f23838",
            "a0aab0cece4141a5b680f5e73c39ec79",
            "8f5d7a004cba402b93a95fd855c6e211",
            "a98a393fc3c14f43baf31c982de3107c",
            "6004cb32aeb6424798d4008df2eab104",
            "c8085311a90441bbbaee7846e9dd2c95"
          ]
        },
        "id": "eLOkbrAPU-Pa",
        "outputId": "bded5b04-8528-4133-8a73-e0f6411ddadb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_name:  llava-v1.5-7b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c43cf26f2cd8433088b2a585792b59f1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image files:  ['../../images_jpg/Servo_Motor_SG90.jpg']\n",
            "images:  [<PIL.Image.Image image mode=RGB size=4032x3024 at 0x78B190D77F70>]\n",
            "image sizes:  [(4032, 3024)]\n",
            "Description:\n",
            "The component is a small electronic device, possibly a sensor or a microcontroller, with a blue casing. It is designed for use in IoT applications and is placed on a white surface. The device appears to be a small part of a larger IoT kit.\n",
            "\n",
            "Applications:\n",
            "This component can be used in various IoT applications, such as home automation, industrial monitoring, environmental monitoring, and more. Its small size and versatile design make it suitable for integration into different types of devices and systems.\n",
            "\n",
            "Technical specifications:\n",
            "The device is a small electronic component with a blue casing, and it is designed for use in IoT applications. It is likely to have a microcontroller or sensor functionality, and it may have a range of input/output options, such as digital or analog ports, and communication protocols like Wi-Fi, Bluetooth, or Zigbee. The exact specifications of the component would depend on the manufacturer and the intended use case.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### VLM Zero shot Servo Motor SG90\n",
        "\n",
        "model_path = \"liuhaotian/llava-v1.5-7b\"\n",
        "# prompt = \"What are the things I should be cautious about when I visit here?\"\n",
        "# image_file = \"https://llava-vl.github.io/static/images/view.jpg\"\n",
        "prompt = \"You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: Servo Motor SG90. Give a description of the component having 3 sections as follows: \\n1) Description \\n2) Applications \\n3) Technical specifications\"\n",
        "\n",
        "image_file = \"../../images_jpg/Servo_Motor_SG90.jpg\"\n",
        "\n",
        "\n",
        "args = type('Args', (), {\n",
        "    \"model_path\": model_path,\n",
        "    \"model_base\": None,\n",
        "    \"model_name\": get_model_name_from_path(model_path),\n",
        "    \"query\": prompt,\n",
        "    \"conv_mode\": None,\n",
        "    \"image_file\": image_file,\n",
        "    \"sep\": \",\",\n",
        "    \"temperature\": 0.1,\n",
        "    \"top_p\": None,\n",
        "    \"num_beams\": 1,\n",
        "    \"max_new_tokens\": 1000\n",
        "})()\n",
        "\n",
        "eval_model(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659,
          "referenced_widgets": [
            "6312d6a148454792923f3bf920500a74",
            "d49016de2dee4f83ae409e9adc06f4f0",
            "db13b7f11cd94336ab95a896bc6e98f2",
            "0caf6d8fbace4cc79d3aabf859c53604",
            "54c325c5102e45ffa9e01989767ad344",
            "518bd2f7afee47f8b4ed8345b6d4a876",
            "89171230da5e43708be54dc1bb52b905",
            "c6232de5414b4770ba9a7c1940081da4",
            "cad5707b8b104bb3998d47758d419740",
            "bd9b18a9e4f145209d3d3328787da053",
            "c8d7409fad2f4a7cb020bc6d4de21fd7"
          ]
        },
        "id": "DVRTHJWrVSt6",
        "outputId": "c1142a51-6dea-47f9-c2c0-c23d91e350a5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_name:  llava-v1.5-7b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6312d6a148454792923f3bf920500a74"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image files:  ['../../images_jpg/Servo_Motor_SG90.jpg']\n",
            "images:  [<PIL.Image.Image image mode=RGB size=4032x3024 at 0x792CAEAEBF10>]\n",
            "image sizes:  [(4032, 3024)]\n",
            "1. Description:\n",
            "The Servo Motor SG90 is a small, compact, and versatile motor that is commonly used in IoT devices and robotics projects. It is a brushless DC motor with a built-in gearbox, which allows for precise control of the motor's rotation speed and direction. The SG90 is designed to be easy to assemble and disassemble, making it a popular choice for DIY projects and educational purposes.\n",
            "\n",
            "2. Applications:\n",
            "The Servo Motor SG90 can be used in a wide range of applications, including robotics, automation, and IoT devices. Some common uses for this motor include:\n",
            "- Controlling the movement of robots or drones\n",
            "- Automating machines or equipment in factories or warehouses\n",
            "- Controlling the position of cameras or other sensors in IoT devices\n",
            "- Moving parts in 3D printers or CNC machines\n",
            "\n",
            "3. Technical specifications:\n",
            "The Servo Motor SG90 has the following technical specifications:\n",
            "- Voltage: 5V to 30V\n",
            "- Current: 0.3A to 1.5A\n",
            "- Speed: 0 to 180 degrees per second\n",
            "- Torque: 0.15Nm to 0.6Nm\n",
            "- Gear Ratio: 1:20 to 1:100\n",
            "- Dimensions: 40mm x 40mm x 40mm\n",
            "- Weight: 0.15kg\n",
            "- Operating temperature: -10 to 60 degrees Celsius\n",
            "- Mounting: Screw holes on the base plate.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### VLM One shot Servo Motor SG90\n",
        "\n",
        "model_path = \"liuhaotian/llava-v1.5-7b\"\n",
        "# prompt = \"What are the things I should be cautious about when I visit here?\"\n",
        "# image_file = \"https://llava-vl.github.io/static/images/view.jpg\"\n",
        "prompt = \"You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: Servo Motor SG90. Give a description of the component having 3 sections as follows: \\n1) Description \\n2) Applications \\n3) Technical specifications.\\n Here is an example for reference,\\nULN 2003 Stepper Motor Driver Module:\\nDescription:\\nThe ULN2003 Stepper Motor Driver Module is an integrated circuit module designed to control bipolar stepper motors conveniently. It utilizes the ULN2003A Darlington array as its core component. This module provides an easy interface for controlling stepper motors, offering both simplicity and efficiency in motor control applications.\\nApplications:\\nThe ULN2003 Stepper Motor Driver Module finds widespread use in various projects and applications, including:\\nRobotics: for precise control of robot movements.\\nCNC machines: for controlling the motion of axes.\\n3D printers: for controlling the position of the printing head.\\nAutomated systems: for controlling mechanisms like conveyor belts and automated doors.\\nDIY projects: for hobbyists and enthusiasts working on motion control projects.\\nTechnical Specifications:\\nOperating Voltage: 5V DC\\nOutput Current: up to 500mA per channel (with proper heat sinking)\\nDriver IC: ULN2003A Darlington Array\\nNumber of Channels: 7 (suitable for driving bipolar stepper motors)\\nCompatible Motors: Bipolar stepper motors with 4 or 6 wires\\nControl Interface: 4-phase, 5-wire interface (can be easily interfaced with microcontrollers like Arduino)\\nDimensions: Compact module size for easy integration into projects\\nProtection Features: Built-in transient suppression diodes for protecting the module and connected components against voltage spikes\\nMounting Holes: Provided for easy installation and integration into projects\"\n",
        "# prompt = \"Can you make a short description about the part: HiLetgo GY-521 module.\\n It should be divided into 3 sections as follows: \\n1) Description \\n2) Applications \\n3) technical specification\"\n",
        "image_file = \"../../images_jpg/Servo_Motor_SG90.jpg\"\n",
        "\n",
        "\n",
        "args = type('Args', (), {\n",
        "    \"model_path\": model_path,\n",
        "    \"model_base\": None,\n",
        "    \"model_name\": get_model_name_from_path(model_path),\n",
        "    \"query\": prompt,\n",
        "    \"conv_mode\": None,\n",
        "    \"image_file\": image_file,\n",
        "    \"sep\": \",\",\n",
        "    \"temperature\": 0.1,\n",
        "    \"top_p\": None,\n",
        "    \"num_beams\": 1,\n",
        "    \"max_new_tokens\": 1000\n",
        "})()\n",
        "\n",
        "eval_model(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590,
          "referenced_widgets": [
            "7403f297ee934881b7801839c63227a5",
            "de85b1538da24de4a0ae957fdc26f91e",
            "83c69baf7594438e8d2ba48fc284618c",
            "b149b269ad3b493c8690a592b46b3156",
            "76009e40c9c645abb18126e8ad51c978",
            "40300759e9ed433f9ea59021795ce2c9",
            "4b1f7249a6dd4a2db7dd9fc6ad78592f",
            "c834838d0ebc4e0fbbd90ed1c62ba333",
            "27147d3116734345aafec9d1d9f06533",
            "11e5406f915140d0b3e928b8282e62d1",
            "2911759612f14d878c9e3787b32ade9e"
          ]
        },
        "id": "sPpnYaFLVfsv",
        "outputId": "2c71e976-be7a-4ec0-9c3a-baa338c5f4d3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_name:  llava-v1.5-7b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7403f297ee934881b7801839c63227a5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image files:  ['../../images_jpg/Servo_Motor_SG90.jpg']\n",
            "images:  [<PIL.Image.Image image mode=RGB size=4032x3024 at 0x7B49B3617A60>]\n",
            "image sizes:  [(4032, 3024)]\n",
            "Description:\n",
            "The Servo Motor SG90 is a compact and versatile motor driver module designed for use with servo motors. It is a simple and cost-effective solution for controlling the rotation of servo motors in various applications.\n",
            "\n",
            "Applications:\n",
            "The Servo Motor SG90 is widely used in a variety of applications, including robotics, CNC machines, 3D printers, automated systems, and DIY projects. Its compact size and ease of use make it a popular choice for controlling the movement of mechanisms that require precise and smooth control.\n",
            "\n",
            "Technical Specifications:\n",
            "\n",
            "1. Operating Voltage: 5V DC\n",
            "2. Continuous Current: 1.5A\n",
            "3. Peak Current: 2.5A\n",
            "4. Driver IC: SG90\n",
            "5. Number of Channels: 1\n",
            "6. Compatible Motors: Servo motors with a torque of up to 10 kg-cm\n",
            "7. Control Interface: PWM signal (can be easily interfaced with microcontrollers like Arduino)\n",
            "8. Dimensions: Compact module size for easy integration into projects\n",
            "9. Protection Features: Over-current protection and thermal protection for safe operation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### VLM finetuning Servo Motor SG90\n",
        "\n",
        "# model_path = \"llava/checkpoints/llava-v1.5-7b-task-lora-first\"\n",
        "model_path = \"llava/checkpoints/llava-v1.5-7b-lora\"\n",
        "model_basee = \"liuhaotian/llava-v1.5-7b\"\n",
        "# prompt = \"What are the things I should be cautious about when I visit here?\"\n",
        "# image_file = \"https://llava-vl.github.io/static/images/view.jpg\"\n",
        "prompt = \"You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: Servo Motor SG90. Give a description of the component having 3 sections as follows: \\n1) Description \\n2) Applications \\n3) Technical specifications\"\n",
        "image_file = \"../../images_jpg/Servo_Motor_SG90.jpg\"\n",
        "\n",
        "\n",
        "args = type('Args', (), {\n",
        "    \"model_path\": model_path,\n",
        "    \"model_base\": model_basee,\n",
        "    \"model_name\": get_model_name_from_path(model_path),\n",
        "    \"query\": prompt,\n",
        "    \"conv_mode\": None,\n",
        "    \"image_file\": image_file,\n",
        "    \"sep\": \",\",\n",
        "    \"temperature\": 0.1,\n",
        "    \"top_p\": None,\n",
        "    \"num_beams\": 1,\n",
        "    \"max_new_tokens\": 512\n",
        "})()\n",
        "\n",
        "eval_model(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659,
          "referenced_widgets": [
            "01fcaabc3e2f401b9909fcc14bb05021",
            "4be8e6537e5d4e07bfffc17a37b84bf2",
            "900df2c3260c4b63b48b097c3351627d",
            "bd7e39f4468a45c49f70232c95520cb9",
            "4b1e94517b37421a900a7b563f8f0195",
            "c82dc08916594a8e81278b0c4f450186",
            "cef9420db0a14d3d954587a7ea7d0a03",
            "80b9cd6100054eba995491d3b0d89521",
            "5aac023bb5c3476cb43c89356f56c6c4",
            "a8d880f83c604351a2dbec5f6751fc49",
            "f8e92fe7ffc641b9b4f082bfa09b15ac"
          ]
        },
        "id": "5KGQz09pVszy",
        "outputId": "252db02f-6ee9-484f-a055-9890abec64e6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_name:  llava-v1.5-7b-lora\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading LLaVA from base model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "01fcaabc3e2f401b9909fcc14bb05021"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading additional LLaVA weights...\n",
            "Loading LoRA weights...\n",
            "Merging LoRA weights...\n",
            "Model is loaded...\n",
            "image files:  ['../../images_jpg/Servo_Motor_SG90.jpg']\n",
            "images:  [<PIL.Image.Image image mode=RGB size=4032x3024 at 0x79025A85FD00>]\n",
            "image sizes:  [(4032, 3024)]\n",
            "Description:\n",
            "The Servo Motor SG90 is a compact and versatile motor commonly used in robotics, automation, and IoT projects. It features a small form factor, making it ideal for space-constrained applications. The motor is equipped with a potentiometer for precise positioning and control. It typically consists of a motor, gearbox, potentiometer, and mounting brackets, all packed into a compact housing.\n",
            "Applications:\n",
            "Robotics: Servo motors are widely used in robotics for controlling movement and positioning of robotic arms, grippers, and other mechanical components.\n",
            "Automation: They find applications in automated systems for controlling valves, dampers, and other mechanical devices.\n",
            "IoT: Servo motors are employed in IoT projects for remote control of devices such as drones, surveillance cameras, and unmanned vehicles.\n",
            "Technical Specifications:\n",
            "Motor Type: Brushless DC\n",
            "Voltage: Typically operates at 4.8V to 6V\n",
            "Current: Typically draws around 1.5A to 2A\n",
            "Torque: Ranges from 10 oz-in to 18 oz-in, depending on the specific model\n",
            "Positioning Accuracy: Typically provides 10-20 degrees of rotation\n",
            "Control Interface: Uses a PWM (Pulse Width Modulation) signal for position control\n",
            "Communication: Can be controlled via serial interfaces such as UART or I2C\n",
            "Dimensions: Compact size, typically measuring around 30mm x 30mm x 40mm\n",
            "Operating Temperature: Typically operates within a temperature range of -20°C to 60°C\n",
            "Mounting: Comes with mounting brackets for easy integration into projects.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Genai Project/VLM/LLAVA_zip/LLaVA-main/\n",
        "\n",
        "from llava.model.builder import load_pretrained_model\n",
        "from llava.mm_utils import get_model_name_from_path\n",
        "from llava.eval.run_llava import eval_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNRXZaRDWMJg",
        "outputId": "1806f2aa-9c61-4090-c4df-0df2bb3668ba"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1euUzSZa1IjWGSY7kHFLr2B_d6lpqAzvE/Genai Project/VLM/LLAVA_zip/LLaVA-main\n",
            "[2024-04-30 23:35:59,420] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### VLM No object detector Zero shot Stepper Motor\n",
        "\n",
        "model_path = \"liuhaotian/llava-v1.5-7b\"\n",
        "# prompt = \"What are the things I should be cautious about when I visit here?\"\n",
        "# image_file = \"https://llava-vl.github.io/static/images/view.jpg\"\n",
        "prompt = \"You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component. Give a description of the component having 3 sections as follows: \\n1) Description \\n2) Applications \\n3) Technical specifications\"\n",
        "image_file = \"../../images_jpg/Stepper_Motor.jpg\"\n",
        "\n",
        "\n",
        "args = type('Args', (), {\n",
        "    \"model_path\": model_path,\n",
        "    \"model_base\": None,\n",
        "    \"model_name\": get_model_name_from_path(model_path),\n",
        "    \"query\": prompt,\n",
        "    \"conv_mode\": None,\n",
        "    \"image_file\": image_file,\n",
        "    \"sep\": \",\",\n",
        "    \"temperature\": 0.1,\n",
        "    \"top_p\": None,\n",
        "    \"num_beams\": 1,\n",
        "    \"max_new_tokens\": 1000\n",
        "})()\n",
        "\n",
        "eval_model(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434,
          "referenced_widgets": [
            "26b7e3efbb504a69a496a06a57cf33d5",
            "e2067030c0d14b96b15d6bdcbf7fb66e",
            "47c376349d7b4d8491bb478b67b67211",
            "4489f631d51641519f3df56492d3f971",
            "aaf0b86a53be4062a61dd4d988c925ee",
            "6137328df379470b96644ce9b5460bcb",
            "e318c9abcf4444af90be6ee2c22edeb0",
            "5bd04c7cdd794f018ef3b1388a3dd7ad",
            "7d78c03aa1ce4362b805f099c811818a",
            "e30d690d91b44f18b9f1b33d68c4908a",
            "39320e4c58474e7dad39033bf2cc7467"
          ]
        },
        "id": "brEWlvO-WO6E",
        "outputId": "2f1c7713-4f8c-4ef2-f299-835c28fa63c6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_name:  llava-v1.5-7b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "26b7e3efbb504a69a496a06a57cf33d5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image files:  ['../../images_jpg/Stepper_Motor.jpg']\n",
            "images:  [<PIL.Image.Image image mode=RGB size=4032x3024 at 0x7E14535CB760>]\n",
            "image sizes:  [(4032, 3024)]\n",
            "Description:\n",
            "The component is a small electronic device with a blue housing and an orange wire. It appears to be a power supply or a control module for an IoT device. The device is attached to a white wall, and it has a yellow light on the bottom.\n",
            "\n",
            "Applications:\n",
            "This component can be used in various IoT applications, such as home automation, industrial control systems, or smart city infrastructure. It can be used to power and control other devices, such as sensors, actuators, or communication modules, to enable remote monitoring and control of different systems.\n",
            "\n",
            "Technical specifications:\n",
            "The device has a blue housing, which is likely to be a protective casing for the electronic components inside. The orange wire is likely to be a power supply or a control signal wire, which can be connected to other devices or sensors. The yellow light on the bottom of the device could be an indicator for power status, signaling, or alerting. The exact technical specifications of the device would depend on the specific IoT kit it belongs to and the purpose it serves in the system.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### VLM Zero shot Stepper Motor\n",
        "\n",
        "model_path = \"liuhaotian/llava-v1.5-7b\"\n",
        "# prompt = \"What are the things I should be cautious about when I visit here?\"\n",
        "# image_file = \"https://llava-vl.github.io/static/images/view.jpg\"\n",
        "prompt = \"You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: Stepper Motor. Give a description of the component having 3 sections as follows: \\n1) Description \\n2) Applications \\n3) Technical specifications\"\n",
        "\n",
        "image_file = \"../../images_jpg/Stepper_Motor.jpg\"\n",
        "\n",
        "\n",
        "args = type('Args', (), {\n",
        "    \"model_path\": model_path,\n",
        "    \"model_base\": None,\n",
        "    \"model_name\": get_model_name_from_path(model_path),\n",
        "    \"query\": prompt,\n",
        "    \"conv_mode\": None,\n",
        "    \"image_file\": image_file,\n",
        "    \"sep\": \",\",\n",
        "    \"temperature\": 0.1,\n",
        "    \"top_p\": None,\n",
        "    \"num_beams\": 1,\n",
        "    \"max_new_tokens\": 1000\n",
        "})()\n",
        "\n",
        "eval_model(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659,
          "referenced_widgets": [
            "b9a46af7338942f884dbaf79c44e3755",
            "3450f3abbed343d389e1de078bed94bf",
            "b6a688fdaa62413cb7a0a71282136870",
            "029268b433724ac9bc00fe480c09937d",
            "3a3cad9dffdd44a1a7e82adc99ae41d6",
            "7208276659d54fe48b576163171d2f1d",
            "d0ef5804261d41eea9abdd97eb885b7b",
            "d2affc36abef488c903e97b55e97877d",
            "6a7cc46a9352463587f28598e0f73a44",
            "e6f0bc2e935848889806dcef6711abff",
            "5786825e1258403ebc5b196c9c5fbac6"
          ]
        },
        "id": "btp8Ab-gWg6f",
        "outputId": "c0562581-5d51-41f3-eac1-21f8b824dfdc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_name:  llava-v1.5-7b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b9a46af7338942f884dbaf79c44e3755"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image files:  ['../../images_jpg/Stepper_Motor.jpg']\n",
            "images:  [<PIL.Image.Image image mode=RGB size=4032x3024 at 0x7CA3A8E2FD30>]\n",
            "image sizes:  [(4032, 3024)]\n",
            "1. Description:\n",
            "A stepper motor is a type of electric motor that moves in discrete steps, rather than continuously like a regular motor. It is commonly used in IoT devices and hardware for precise positioning and control. Stepper motors are often found in applications such as robotics, CNC machines, and automation systems.\n",
            "\n",
            "2. Applications:\n",
            "Stepper motors are widely used in various IoT and hardware applications due to their precise and accurate movement. Some common applications include:\n",
            "- Robotics: Stepper motors are used in robots for precise positioning and movement control.\n",
            "- CNC machines: They are used in CNC machines for accurate positioning of cutting tools and other components.\n",
            "- Automation systems: Stepper motors are used in automation systems for precise control of mechanical components.\n",
            "- 3D printers: They are used in 3D printers for precise movement of the print head and accurate layering of materials.\n",
            "\n",
            "3. Technical specifications:\n",
            "- Type: Stepper motor\n",
            "- Power: 0.5V to 24V\n",
            "- Speed: 0.1 to 100 RPM\n",
            "- Torque: 0.05 to 0.5 Nm\n",
            "- Resolution: 0.1 to 100 steps per revolution\n",
            "- Step angle: 1.85 degrees per step\n",
            "- Mounting: Flat, round, or square base\n",
            "- Size: 25mm to 100mm in diameter\n",
            "- Material: Plastic or metal\n",
            "- Operating temperature: -10 to 85 degrees Celsius\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### VLM One shot Stepper Motor\n",
        "\n",
        "model_path = \"liuhaotian/llava-v1.5-7b\"\n",
        "# prompt = \"What are the things I should be cautious about when I visit here?\"\n",
        "# image_file = \"https://llava-vl.github.io/static/images/view.jpg\"\n",
        "prompt = \"You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: Stepper Motor. Give a description of the component having 3 sections as follows: \\n1) Description \\n2) Applications \\n3) Technical specifications.\\n Here is an example for reference,\\nULN 2003 Stepper Motor Driver Module:\\nDescription:\\nThe ULN2003 Stepper Motor Driver Module is an integrated circuit module designed to control bipolar stepper motors conveniently. It utilizes the ULN2003A Darlington array as its core component. This module provides an easy interface for controlling stepper motors, offering both simplicity and efficiency in motor control applications.\\nApplications:\\nThe ULN2003 Stepper Motor Driver Module finds widespread use in various projects and applications, including:\\nRobotics: for precise control of robot movements.\\nCNC machines: for controlling the motion of axes.\\n3D printers: for controlling the position of the printing head.\\nAutomated systems: for controlling mechanisms like conveyor belts and automated doors.\\nDIY projects: for hobbyists and enthusiasts working on motion control projects.\\nTechnical Specifications:\\nOperating Voltage: 5V DC\\nOutput Current: up to 500mA per channel (with proper heat sinking)\\nDriver IC: ULN2003A Darlington Array\\nNumber of Channels: 7 (suitable for driving bipolar stepper motors)\\nCompatible Motors: Bipolar stepper motors with 4 or 6 wires\\nControl Interface: 4-phase, 5-wire interface (can be easily interfaced with microcontrollers like Arduino)\\nDimensions: Compact module size for easy integration into projects\\nProtection Features: Built-in transient suppression diodes for protecting the module and connected components against voltage spikes\\nMounting Holes: Provided for easy installation and integration into projects\"\n",
        "# prompt = \"Can you make a short description about the part: HiLetgo GY-521 module.\\n It should be divided into 3 sections as follows: \\n1) Description \\n2) Applications \\n3) technical specification\"\n",
        "image_file = \"../../images_jpg/Stepper_Motor.jpg\"\n",
        "\n",
        "\n",
        "args = type('Args', (), {\n",
        "    \"model_path\": model_path,\n",
        "    \"model_base\": None,\n",
        "    \"model_name\": get_model_name_from_path(model_path),\n",
        "    \"query\": prompt,\n",
        "    \"conv_mode\": None,\n",
        "    \"image_file\": image_file,\n",
        "    \"sep\": \",\",\n",
        "    \"temperature\": 0.1,\n",
        "    \"top_p\": None,\n",
        "    \"num_beams\": 1,\n",
        "    \"max_new_tokens\": 1000\n",
        "})()\n",
        "\n",
        "eval_model(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729,
          "referenced_widgets": [
            "50ea6f6c644b4b3a87a30f548cc7797b",
            "23b6a8ab93744f1e905717e111fea839",
            "e8862d6ead4d4b8bb5dc379dfac4e813",
            "293ece75b7dd47ccba82641480c09893",
            "3d6be6eadcbf4c989a357f48ea4471c9",
            "409f141c34364dbe90489be455af3845",
            "cfe3c234607545c680bea721ffb95ec6",
            "8368502122b8432cb9c1826810268cf5",
            "8eab252bfcb2453f82b4788d8a04065e",
            "ebc26994c3914e42b2ae7deea15a9608",
            "e1f8c3f585d14765ad0dfb8a7668adba"
          ]
        },
        "id": "YqdCGyv8W0WS",
        "outputId": "32843a40-0524-4d5f-89c2-fe816d345149"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_name:  llava-v1.5-7b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "50ea6f6c644b4b3a87a30f548cc7797b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image files:  ['../../images_jpg/Stepper_Motor.jpg']\n",
            "images:  [<PIL.Image.Image image mode=RGB size=4032x3024 at 0x7F535143DC00>]\n",
            "image sizes:  [(4032, 3024)]\n",
            "Description:\n",
            "The stepper motor is a type of electric motor that is designed to rotate in small, precise steps. It is commonly used in various applications, including robotics, CNC machines, 3D printers, and automated systems. The stepper motor operates by moving a rotor with a fixed number of steps (usually 200 or 400) in response to a series of electrical pulses.\n",
            "\n",
            "Applications:\n",
            "Stepper motors are widely used in various applications due to their precise and accurate control, making them ideal for projects that require precise movement and positioning. Some common applications include:\n",
            "\n",
            "1. Robotics: Stepper motors are commonly used in robotics to control the movement of robotic arms, legs, and other components.\n",
            "2. CNC machines: Stepper motors are used to control the movement of machine tools, such as milling machines and lathes.\n",
            "3. 3D printers: Stepper motors are used to control the movement of the printing head in 3D printers.\n",
            "4. Automated systems: Stepper motors are used in automated systems, such as conveyor belts and automated doors.\n",
            "5. DIY projects: Stepper motors are popular among hobbyists and enthusiasts working on motion control projects.\n",
            "\n",
            "Technical Specifications:\n",
            "Stepper motors typically have the following technical specifications:\n",
            "\n",
            "1. Operating Voltage: Stepper motors require a specific operating voltage, which is usually between 5V and 24V DC.\n",
            "2. Output Current: Stepper motors have a maximum output current, which varies depending on the motor size and design.\n",
            "3. Driver IC: Stepper motors require a driver IC to control their operation. Common driver ICs include the ULN2003 and the TB67S2005.\n",
            "4. Number of Channels: Stepper motors come in various configurations, with the most common being 2-phase and 4-phase motors.\n",
            "5. Compatible Motors: Stepper motors are compatible with bipolar stepper motors, which have two sets of wires connected to the rotor and stator.\n",
            "6. Control Interface: Stepper motors use a 4-phase, 5-wire interface, which can be easily interfaced with microcontrollers like Arduino.\n",
            "7. Mounting Holes: Stepper motors have mounting holes for easy installation and integration into projects.\n",
            "8. Protection Features: Stepper motors often have built-in transient suppression diodes to protect the motor and connected components against voltage spikes.\n",
            "\n",
            "In summary, stepper motors are versatile and precise electric motors that are widely used in various applications, including robotics, CNC machines, and automated systems. They require a specific driver IC and have specific technical specifications, such as operating voltage, output current, and control interface.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### VLM finetuning Stepper Motor\n",
        "\n",
        "# model_path = \"llava/checkpoints/llava-v1.5-7b-task-lora-first\"\n",
        "model_path = \"llava/checkpoints/llava-v1.5-7b-lora\"\n",
        "model_basee = \"liuhaotian/llava-v1.5-7b\"\n",
        "# prompt = \"What are the things I should be cautious about when I visit here?\"\n",
        "# image_file = \"https://llava-vl.github.io/static/images/view.jpg\"\n",
        "prompt = \"You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: Stepper Motor. Give a description of the component having 3 sections as follows: \\n1) Description \\n2) Applications \\n3) Technical specifications\"\n",
        "image_file = \"../../images_jpg/Stepper_Motor.jpg\"\n",
        "\n",
        "\n",
        "args = type('Args', (), {\n",
        "    \"model_path\": model_path,\n",
        "    \"model_base\": model_basee,\n",
        "    \"model_name\": get_model_name_from_path(model_path),\n",
        "    \"query\": prompt,\n",
        "    \"conv_mode\": None,\n",
        "    \"image_file\": image_file,\n",
        "    \"sep\": \",\",\n",
        "    \"temperature\": 0.1,\n",
        "    \"top_p\": None,\n",
        "    \"num_beams\": 1,\n",
        "    \"max_new_tokens\": 512\n",
        "})()\n",
        "\n",
        "eval_model(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746,
          "referenced_widgets": [
            "8c60c8661aac42909d9da88fc8189a18",
            "7058c73bf49b4609b51f6699712d1195",
            "72d9a6fb2e9d4abb9145daeac34948e0",
            "eba45bf75d5d4891a2b001348cc1d076",
            "85b14f3a5c884bea92c993d3054c7300",
            "934d8531b84349599aa118b34716cef5",
            "d25f1a3c719243aaac2065639da792b9",
            "05d7732405f14dfc9284a4a8566e6ceb",
            "5e391f0284ec43e0bf0874424fafe335",
            "b4f43217147c49bc9110d8a955bbfad4",
            "a914677a8ba24f14962b121c39d68ff2"
          ]
        },
        "id": "UzUGo3KdXOvk",
        "outputId": "4bb4aad0-f198-4756-d846-fada93bdd76a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_name:  llava-v1.5-7b-lora\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading LLaVA from base model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c60c8661aac42909d9da88fc8189a18"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading additional LLaVA weights...\n",
            "Loading LoRA weights...\n",
            "Merging LoRA weights...\n",
            "Model is loaded...\n",
            "image files:  ['../../images_jpg/Stepper_Motor.jpg']\n",
            "images:  [<PIL.Image.Image image mode=RGB size=4032x3024 at 0x7A454168EB90>]\n",
            "image sizes:  [(4032, 3024)]\n",
            "Description:\n",
            "A stepper motor is a type of brushless DC electric motor that divides a full rotation into a number of equal steps. It is commonly used in IoT (Internet of Things) applications due to its precise control and ability to move in discrete increments. Stepper motors consist of a rotor and a stator, with the rotor typically having a series of permanent magnets arranged around its circumference. The stator contains a set of coils that are energized in a specific sequence to produce the rotational force.\n",
            "Applications:\n",
            "Stepper motors find wide applications in various IoT and hardware projects due to their precise control and ability to move in discrete increments. Some common applications include:\n",
            "Robotics: Stepper motors are commonly used in robotics for precise positioning and movement.\n",
            "3D printing: They are used in 3D printers to move the print head and control the extrusion of filament.\n",
            "CNC machines: Stepper motors are used in CNC (Computer Numerical Control) machines for precise positioning of cutting tools.\n",
            "Automation: They are used in automated systems for precise positioning and control of mechanical components.\n",
            "Technical Specifications:\n",
            "Rated Torque: The maximum torque that the motor can exert in one direction.\n",
            "Rated Speed: The maximum speed at which the motor can rotate continuously.\n",
            "Step Angle: The angle between each step of the motor's rotation.\n",
            "Holding Torque: The torque that the motor can maintain when stationary.\n",
            "Voltage: The voltage required to operate the motor.\n",
            "Current: The current required to operate the motor.\n",
            "Number of Steps: The number of discrete steps that the motor can move in one direction.\n",
            "Diameter: The diameter of the motor's shaft.\n",
            "Length: The length of the motor's shaft.\n",
            "Mounting: The type of mounting (e.g., shaft, flange, etc.) and the dimensions of the motor's mounting holes.\n",
            "Operating Environment: The operating temperature range and any environmental considerations (e.g., dust, moisture, etc.).\n",
            "Communication: The communication protocols (e.g., SPI, UART, etc.) and any required external components for communication.\n",
            "Control: The control interface (e.g., potentiometer, joyst\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Genai Project/VLM/LLAVA_zip/LLaVA-main/\n",
        "\n",
        "from llava.model.builder import load_pretrained_model\n",
        "from llava.mm_utils import get_model_name_from_path\n",
        "from llava.eval.run_llava import eval_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KqtOsttXMaf",
        "outputId": "ca8dd4ae-e84d-457e-c270-df84ebd8d26b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1euUzSZa1IjWGSY7kHFLr2B_d6lpqAzvE/Genai Project/VLM/LLAVA_zip/LLaVA-main\n",
            "[2024-04-30 23:41:38,183] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### VLM No object detector Zero shot Water Level Detection Sensor Module\n",
        "\n",
        "model_path = \"liuhaotian/llava-v1.5-7b\"\n",
        "# prompt = \"What are the things I should be cautious about when I visit here?\"\n",
        "# image_file = \"https://llava-vl.github.io/static/images/view.jpg\"\n",
        "prompt = \"You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component. Give a description of the component having 3 sections as follows: \\n1) Description \\n2) Applications \\n3) Technical specifications\"\n",
        "image_file = \"../../images_jpg/Water_Level_Detection_Sensor_Module.jpg\"\n",
        "\n",
        "\n",
        "args = type('Args', (), {\n",
        "    \"model_path\": model_path,\n",
        "    \"model_base\": None,\n",
        "    \"model_name\": get_model_name_from_path(model_path),\n",
        "    \"query\": prompt,\n",
        "    \"conv_mode\": None,\n",
        "    \"image_file\": image_file,\n",
        "    \"sep\": \",\",\n",
        "    \"temperature\": 0.1,\n",
        "    \"top_p\": None,\n",
        "    \"num_beams\": 1,\n",
        "    \"max_new_tokens\": 1000\n",
        "})()\n",
        "\n",
        "eval_model(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434,
          "referenced_widgets": [
            "8ddc989f96dc460da600ba332e523183",
            "2b49e422d8a54e8e9b390ce82c299ff2",
            "f3677bff29c64d49832984cf86f039ad",
            "bdcffe04a1134905a530634930925357",
            "2dc68791177a44608afeb40a8cb03f87",
            "a7782ab8e44641c2bdb0b0c1bf9398e6",
            "34ad3d0e19dc405ebdad651769ddf0c2",
            "5a497db51eba4be7b35ae2d1b585a85e",
            "b81f26e5376947d6889bf60bb79752df",
            "7aa45f22b37e4e70a5b41a77807b8094",
            "1f9aec43537348488a45a5e1259d035c"
          ]
        },
        "id": "HxjDWo2yXhn9",
        "outputId": "d0b5fbb9-d98e-4c8d-8944-87b6b77e849b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_name:  llava-v1.5-7b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8ddc989f96dc460da600ba332e523183"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image files:  ['../../images_jpg/Water_Level_Detection_Sensor_Module.jpg']\n",
            "images:  [<PIL.Image.Image image mode=RGB size=4032x3024 at 0x7FDF9645B880>]\n",
            "image sizes:  [(4032, 3024)]\n",
            "Description:\n",
            "The component is a small electronic device with a red casing, likely a microchip or a module. It has a few pins on the bottom, which are used for connecting to other components or devices. The device appears to be a part of an IoT kit, as it is designed to be used in IoT applications.\n",
            "\n",
            "Applications:\n",
            "This component can be used in various IoT applications, such as monitoring and controlling devices, data collection, and communication between different devices. It can be integrated into smart home systems, industrial automation, or any other IoT-based project that requires interconnectivity and data processing.\n",
            "\n",
            "Technical specifications:\n",
            "The component is a microchip or module with a red casing, and it has a few pins on the bottom. It is designed to be used in IoT applications, and its exact technical specifications would depend on the specific type of microchip or module it is. However, it is likely to have features such as communication protocols (e.g., Wi-Fi, Bluetooth, Zigbee), processing capabilities, memory, and power management.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### VLM Zero shot Water Level Detection Sensor Module\n",
        "\n",
        "model_path = \"liuhaotian/llava-v1.5-7b\"\n",
        "# prompt = \"What are the things I should be cautious about when I visit here?\"\n",
        "# image_file = \"https://llava-vl.github.io/static/images/view.jpg\"\n",
        "prompt = \"You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: Water Level Detection Sensor Module. Give a description of the component having 3 sections as follows: \\n1) Description \\n2) Applications \\n3) Technical specifications\"\n",
        "\n",
        "image_file = \"../../images_jpg/Water_Level_Detection_Sensor_Module.jpg\"\n",
        "\n",
        "\n",
        "args = type('Args', (), {\n",
        "    \"model_path\": model_path,\n",
        "    \"model_base\": None,\n",
        "    \"model_name\": get_model_name_from_path(model_path),\n",
        "    \"query\": prompt,\n",
        "    \"conv_mode\": None,\n",
        "    \"image_file\": image_file,\n",
        "    \"sep\": \",\",\n",
        "    \"temperature\": 0.1,\n",
        "    \"top_p\": None,\n",
        "    \"num_beams\": 1,\n",
        "    \"max_new_tokens\": 1000\n",
        "})()\n",
        "\n",
        "eval_model(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590,
          "referenced_widgets": [
            "07838cf616de42ada51bee105f6854da",
            "1adf1293f6e74534be8567e78d2466bb",
            "335a3d9142804faca0e68f2b789a96e0",
            "88e37ba5b24a4e409aa43d0fb13835ae",
            "6c6b056482b2436bb35d531c0528f709",
            "11104f8d642640fdacae367084907adc",
            "289df14d43354206ba8d8aa685b09606",
            "bcc5e31de77b495991538bc83ae5d56f",
            "351c6072d012456aa06c0084fc0a7225",
            "25cbc3bd9fed4659ad6d803bf1bb733c",
            "9173dc91e2d744d995b1c348a8a54c8e"
          ]
        },
        "id": "6bwBU3bhX2pm",
        "outputId": "2e8eee91-bbb5-4c13-cb07-cd588f8da94e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_name:  llava-v1.5-7b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "07838cf616de42ada51bee105f6854da"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image files:  ['../../images_jpg/Water_Level_Detection_Sensor_Module.jpg']\n",
            "images:  [<PIL.Image.Image image mode=RGB size=4032x3024 at 0x7A7E820F7B20>]\n",
            "image sizes:  [(4032, 3024)]\n",
            "1. Description:\n",
            "The Water Level Detection Sensor Module is an IoT component designed to measure the water level in a tank or container. It consists of a sensor that detects the water level and an electronic circuit that converts the sensor's output into a digital signal. The module can be easily integrated into various IoT applications, such as monitoring water levels in a swimming pool, a water tank, or a water reservoir.\n",
            "\n",
            "2. Applications:\n",
            "The Water Level Detection Sensor Module can be used in a variety of applications, including:\n",
            "- Monitoring water levels in swimming pools, ensuring that the water level remains within a safe range for swimming and reducing the risk of accidents.\n",
            "- Tracking water levels in water tanks, such as those in residential or commercial buildings, to prevent overflows and water damage.\n",
            "- Monitoring water levels in water reservoirs, such as those in dams or water treatment plants, to ensure proper water management and prevent overfilling or depletion of water resources.\n",
            "\n",
            "3. Technical specifications:\n",
            "The Water Level Detection Sensor Module typically includes the following technical specifications:\n",
            "- Sensor type: The module uses a water-resistant sensor to detect the water level, which can be a float or a pressure sensor.\n",
            "- Sensor range: The module can detect water levels within a specific range, such as 0-100mm or 0-500mm, depending on the sensor type and configuration.\n",
            "- Digital output: The module provides a digital output signal, such as a pulse or an analog voltage, that can be easily integrated into an IoT system.\n",
            "- Power supply: The module typically requires a power supply, such as a battery or an AC/DC converter, to operate.\n",
            "- Connectivity: The module may include connectivity options, such as Wi-Fi or Bluetooth, to enable communication with an IoT gateway or other devices.\n",
            "- Compatibility: The module may be compatible with various IoT platforms, such as Arduino, Raspberry Pi, or other microcontrollers, to facilitate integration into different IoT applications.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### VLM One shot Water Level Detection Sensor Module\n",
        "\n",
        "model_path = \"liuhaotian/llava-v1.5-7b\"\n",
        "# prompt = \"What are the things I should be cautious about when I visit here?\"\n",
        "# image_file = \"https://llava-vl.github.io/static/images/view.jpg\"\n",
        "prompt = \"You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: Water Level Detection Sensor Module. Give a description of the component having 3 sections as follows: \\n1) Description \\n2) Applications \\n3) Technical specifications.\\n Here is an example for reference,\\nULN 2003 Stepper Motor Driver Module:\\nDescription:\\nThe ULN2003 Stepper Motor Driver Module is an integrated circuit module designed to control bipolar stepper motors conveniently. It utilizes the ULN2003A Darlington array as its core component. This module provides an easy interface for controlling stepper motors, offering both simplicity and efficiency in motor control applications.\\nApplications:\\nThe ULN2003 Stepper Motor Driver Module finds widespread use in various projects and applications, including:\\nRobotics: for precise control of robot movements.\\nCNC machines: for controlling the motion of axes.\\n3D printers: for controlling the position of the printing head.\\nAutomated systems: for controlling mechanisms like conveyor belts and automated doors.\\nDIY projects: for hobbyists and enthusiasts working on motion control projects.\\nTechnical Specifications:\\nOperating Voltage: 5V DC\\nOutput Current: up to 500mA per channel (with proper heat sinking)\\nDriver IC: ULN2003A Darlington Array\\nNumber of Channels: 7 (suitable for driving bipolar stepper motors)\\nCompatible Motors: Bipolar stepper motors with 4 or 6 wires\\nControl Interface: 4-phase, 5-wire interface (can be easily interfaced with microcontrollers like Arduino)\\nDimensions: Compact module size for easy integration into projects\\nProtection Features: Built-in transient suppression diodes for protecting the module and connected components against voltage spikes\\nMounting Holes: Provided for easy installation and integration into projects\"\n",
        "# prompt = \"Can you make a short description about the part: HiLetgo GY-521 module.\\n It should be divided into 3 sections as follows: \\n1) Description \\n2) Applications \\n3) technical specification\"\n",
        "image_file = \"../../images_jpg/Water_Level_Detection_Sensor_Module.jpg\"\n",
        "\n",
        "\n",
        "args = type('Args', (), {\n",
        "    \"model_path\": model_path,\n",
        "    \"model_base\": None,\n",
        "    \"model_name\": get_model_name_from_path(model_path),\n",
        "    \"query\": prompt,\n",
        "    \"conv_mode\": None,\n",
        "    \"image_file\": image_file,\n",
        "    \"sep\": \",\",\n",
        "    \"temperature\": 0.1,\n",
        "    \"top_p\": None,\n",
        "    \"num_beams\": 1,\n",
        "    \"max_new_tokens\": 1000\n",
        "})()\n",
        "\n",
        "eval_model(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729,
          "referenced_widgets": [
            "8a421f3007e5442d88b9be8c6f60e75d",
            "81d03c8badc0462ba05df14fb65480ea",
            "4510cf2269504dddb33b21a1fc38bb7d",
            "2b3f10b3904141f2ba13de3af1f371c9",
            "e525423f2a774480a34d55bd64d548a5",
            "9138f064f49542e3978152a2e6980c7d",
            "040bf773d3df4a9786403dcf961b1039",
            "c6c4f10407004000a8d47d3c03a38282",
            "b059be3bf7e84fdeae02e3c83e626a7c",
            "9cc453ae6f2d4993b44a72ce752a3ed9",
            "0d74d33778764d5893b6d4c7001aa07d"
          ]
        },
        "id": "-2rKD4QSYOgE",
        "outputId": "0eed292f-4c61-4107-c37c-c7e372701bea"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_name:  llava-v1.5-7b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8a421f3007e5442d88b9be8c6f60e75d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image files:  ['../../images_jpg/Water_Level_Detection_Sensor_Module.jpg']\n",
            "images:  [<PIL.Image.Image image mode=RGB size=4032x3024 at 0x782204C3FA00>]\n",
            "image sizes:  [(4032, 3024)]\n",
            "Water Level Detection Sensor Module:\n",
            "\n",
            "Description:\n",
            "The Water Level Detection Sensor Module is an electronic component designed to detect changes in water levels. It consists of a water-resistant sensor that measures the water level and an integrated circuit that converts the sensor's output into a digital signal. This module is commonly used in various applications, such as monitoring water levels in tanks, ponds, or aquariums.\n",
            "\n",
            "Applications:\n",
            "The Water Level Detection Sensor Module can be used in a wide range of applications, including:\n",
            "\n",
            "1. Automated irrigation systems: To ensure that plants receive the appropriate amount of water and to prevent overwatering or underwatering.\n",
            "2. Aquariums: To monitor water levels and prevent the fish from being exposed to too much or too little water.\n",
            "3. Water storage tanks: To detect when the water level is low and alert users or initiate a refilling process.\n",
            "4. Industrial processes: To monitor water levels in industrial equipment and prevent damage or malfunction.\n",
            "5. Sewage systems: To monitor water levels in sewage systems and detect potential issues.\n",
            "\n",
            "Technical Specifications:\n",
            "\n",
            "1. Sensor Type: Water-resistant sensor that measures water levels\n",
            "2. Sensor Range: Detects water levels from 0 to 100% (adjustable)\n",
            "3. Resolution: 0.1% of the full-scale range\n",
            "4. Input Voltage: 5V DC\n",
            "5. Output Type: Digital signal (TTL or CMOS compatible)\n",
            "6. Output Pull-up/Pull-down: Included on the integrated circuit\n",
            "7. Operating Temperature: 0°C to 60°C\n",
            "8. Dimensions: Compact module size for easy integration into projects\n",
            "9. Mounting: Screw holes for easy installation and integration into projects.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### VLM finetuning Water Level Detection Sensor Module\n",
        "\n",
        "# model_path = \"llava/checkpoints/llava-v1.5-7b-task-lora-first\"\n",
        "model_path = \"llava/checkpoints/llava-v1.5-7b-lora\"\n",
        "model_basee = \"liuhaotian/llava-v1.5-7b\"\n",
        "# prompt = \"What are the things I should be cautious about when I visit here?\"\n",
        "# image_file = \"https://llava-vl.github.io/static/images/view.jpg\"\n",
        "prompt = \"You are an expert in IoT and hardware with extensive experience. You have been given an IoT kit component: Water Level Detection Sensor Module. Give a description of the component having 3 sections as follows: \\n1) Description \\n2) Applications \\n3) Technical specifications\"\n",
        "image_file = \"../../images_jpg/Water_Level_Detection_Sensor_Module.jpg\"\n",
        "\n",
        "\n",
        "args = type('Args', (), {\n",
        "    \"model_path\": model_path,\n",
        "    \"model_base\": model_basee,\n",
        "    \"model_name\": get_model_name_from_path(model_path),\n",
        "    \"query\": prompt,\n",
        "    \"conv_mode\": None,\n",
        "    \"image_file\": image_file,\n",
        "    \"sep\": \",\",\n",
        "    \"temperature\": 0.1,\n",
        "    \"top_p\": None,\n",
        "    \"num_beams\": 1,\n",
        "    \"max_new_tokens\": 512\n",
        "})()\n",
        "\n",
        "eval_model(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694,
          "referenced_widgets": [
            "c84713de63e04176aa66dfeba1e4ada8",
            "e96e14cda0784b188b15445bde1ee9c7",
            "65e6f957819742e0aee41f1585d7ea3b",
            "acfdb3a5cee64c37a6e2913b23f09160",
            "d447e452c7e744d5841163c4e7f8699f",
            "c857c014832a4d8bac771b44fc9668f8",
            "9cf20a796ff14ad2bf30a601cc23514e",
            "eb4f9a356a5540acb75f59408b800ae0",
            "697624615c3d4a6e87489429528b8ac4",
            "126e7382c3ff469ba57e4c6fd244681a",
            "d34b188f1db34a77b471ad53a066d817"
          ]
        },
        "id": "332G5QGVYe-w",
        "outputId": "da2347f3-df84-42ce-a388-0e0d55b40ef9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_name:  llava-v1.5-7b-lora\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading LLaVA from base model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c84713de63e04176aa66dfeba1e4ada8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading additional LLaVA weights...\n",
            "Loading LoRA weights...\n",
            "Merging LoRA weights...\n",
            "Model is loaded...\n",
            "image files:  ['../../images_jpg/Water_Level_Detection_Sensor_Module.jpg']\n",
            "images:  [<PIL.Image.Image image mode=RGB size=4032x3024 at 0x7EA4B3047BE0>]\n",
            "image sizes:  [(4032, 3024)]\n",
            "Description:\n",
            "The Water Level Detection Sensor Module is a compact and versatile electronic device designed to detect changes in water levels. It typically consists of a float arm, a conductive material, and a microcontroller or sensor chip. The float arm is connected to the conductive material, which is in turn connected to the microcontroller or sensor chip. When the water level rises, the conductive material comes into contact with the water, completing an electrical circuit and triggering an output signal.\n",
            "Applications:\n",
            "The Water Level Detection Sensor Module finds applications in various industries and scenarios where monitoring water levels is critical. Some common applications include:\n",
            "Industrial Process Control: In manufacturing plants, water level detection is essential for monitoring processes such as chemical reactions, cooling systems, and wastewater treatment.\n",
            "Agriculture: Farmers use water level detection sensors to monitor irrigation systems, ensuring optimal water distribution and preventing over- or under-watering of crops.\n",
            "Environmental Monitoring: Water level detection sensors are used in environmental monitoring to track changes in water levels in rivers, lakes, and reservoirs.\n",
            "Home Automation: Homeowners can use water level detection sensors to monitor basement flooding, pool levels, and sump pump performance.\n",
            "Technical Specifications:\n",
            "Operating Voltage: Typically operates within a range of 3.3V to 5V DC.\n",
            "Output Signal: Generates an electrical signal (usually a digital output) when the water level reaches a certain threshold.\n",
            "Detection Range: Can detect water levels within a specific range, typically from a few centimeters to several meters.\n",
            "Accuracy: Offers a high degree of accuracy in measuring water levels.\n",
            "Durability: Designed to withstand harsh environmental conditions and long-term use.\n",
            "Dimensions: Compact size for easy integration into various applications.\n",
            "Interface: May include digital or analog interfaces for easy integration into microcontrollers or other electronic systems.\n",
            "Material: Typically made of corrosion-resistant materials for durability and reliability.\n",
            "Operating Temperature: Can operate within a specific temperature range, typically -20°C to 70°C.\n",
            "Environmental Protection: May include features such as IP ratings for protection against dust, moisture, and other\n"
          ]
        }
      ]
    }
  ]
}